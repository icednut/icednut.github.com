{"meta":{"title":"Icednut's Note","subtitle":"IT Dev experience note","description":null,"author":"Icednut","url":"http://icednut.github.io"},"pages":[{"title":"Search","date":"2018-09-29T06:07:17.000Z","updated":"2018-11-27T06:40:43.378Z","comments":true,"path":"Search/index.html","permalink":"http://icednut.github.io/Search/index.html","excerpt":"","text":""},{"title":"about","date":"2018-09-30T10:25:43.000Z","updated":"2018-11-27T06:40:43.302Z","comments":true,"path":"about/index.html","permalink":"http://icednut.github.io/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2018-12-14T08:53:32.000Z","updated":"2018-12-14T08:53:32.154Z","comments":true,"path":"categories/index.html","permalink":"http://icednut.github.io/categories/index.html","excerpt":"","text":""},{"title":"posts","date":"2018-09-29T06:14:09.000Z","updated":"2018-11-27T06:40:43.162Z","comments":true,"path":"posts/index.html","permalink":"http://icednut.github.io/posts/index.html","excerpt":"","text":""},{"title":"Project","date":"2018-11-27T06:40:43.379Z","updated":"2018-11-27T06:40:43.379Z","comments":true,"path":"project/index.html","permalink":"http://icednut.github.io/project/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-12-14T08:53:22.000Z","updated":"2018-12-14T08:53:22.710Z","comments":true,"path":"tags/index.html","permalink":"http://icednut.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"스칼라 스터디 Day07 - 속성 기반 검사","slug":"20190129-scala-and-functional-programming-day07","date":"2019-01-29T10:59:59.000Z","updated":"2019-01-30T06:29:44.550Z","comments":true,"path":"2019/01/29/20190129-scala-and-functional-programming-day07/","link":"","permalink":"http://icednut.github.io/2019/01/29/20190129-scala-and-functional-programming-day07/","excerpt":"","text":"출처: 스칼라로 배우는 함수형 프로그래밍 8장 Chpater 08. 프로퍼티 기반 테스트이번 챕터에서 다룰 내용 ScalaCheck라는 프로퍼티 기반 테스트 라이브러리를 개발해보자. 7장에서 배운 결과물을 프로퍼티 기반 테스트해보기. ScalaCheck: https://github.com/rickynils/scalacheck/blob/master/doc/UserGuide.md 프로퍼티 기반 테스트(property-based test)가 뭘까?프로퍼티 기반 테스트와 전통적인 유닛 테스트의 차이만약 타입이 List[Int]인 list1과 list2가 있다고 하자. 이에 대해 list1의 사이즈와 list2 사이즈를 더한 값은 list1, list2 들을 합한 리스트의 사이즈와 같다 라는 테스트 문제를 코딩한다고 하면 어떻게 하겠는가? - 임의의 list1과 list2를 만든다. - list1.size + list2.size == (list1 ::: list2).size 라고 코딩하고 돌려본다. - 성공한다. 위와 같이 테스트 유닛을 개발할 것이다. 하지만 만약 list1.size + list2.size == (list1 ::: list2).size 라는 predicate 구문을 만족하지 않는 데이터셋이 존재한다고 가정했을 때 이를 어떻게 증명할 것인가? 아마도 list1, list2라는 임의의 리스트를 만드는 것을 또 코딩해야 할텐데 좀 번거롭지 않은가? 난 단지 predicate 구문만 맞는지 증명하고 싶을 뿐인데… 프로퍼티 기반 검사를 적용하면 임의의 테스트 데이터를 생성하는 부분은 누군가에게 위임하고 개발자는 predicate 구문에만 집중하면 된다. 프로퍼티 기반 테스트란 뭔지 정리하자면, 특정 메소드나 클래스에 대해 자동으로 테스트 기반 데이터를 랜덤으로 생성하고, 그 데이터로 테스트하는 테스트 기법을 말한다. 책에서는 프로그램 행동 방식의 서술(Predicate)과 그런 행동 방식을 검사하는 Test Case의 생성을 분리하는 테스트 기법이라고 설명한다. 스칼라에서 property-based testing의 구현체로는 ScalaCheck가 있으며 이 라이브러리를 사용하면 프로퍼티 기반의 테스트를 손쉽게 진행할 수 있다. import org.scalacheck.Prop.forAll import org.scalacheck.{Gen, Properties} object ScalaCheckExercise extends Properties(\"ScalaCheck Exercise\") { val intList = Gen.listOf(Gen.choose(0, 100)) val prop = forAll(intList)(ns => ns.reverse.reverse == ns) &amp;&amp; forAll(intList)(ns => ns.headOption == ns.reverse.lastOption) val failingProp = forAll(intList)(ns => ns.reverse == ns) prop.check failingProp.check } 첫 느낌은 Java의 Cucumber와 비슷하지만 뭔가 더 세부적이고 테스트 데이터셋을 무작위로 생성(Gen.list, Gen.choose)하는 것이 닮은듯 닮지 않았다. 프로퍼티 기반 테스트의 특징 property-based testing에서 property는 테스트 데이터셋과 테스트할 predicate 구문을 통해 만든 테스트 대상을 말한다. ex: forAll(intList)(ns =&gt; ns.reverse.reverse == ns) forAll이라는 커링을 실행하면 property 인스턴스를 반환한다. 정확하진 않지만 일단 위의 코드를 바탕으로 property 객체라고 추측하자. 이 property 인스턴스에는 check라는 메소드를 갖고 있다. check 메소드가 호출되면 테스트 데이터 생성기(Gen)에서 랜덤으로 생성한 데이터셋(intList)을 바탕으로 predicate 람다를 실행하여 그것이 모두 참인지를 판단한다. 만약 거짓이 발생하면 바로 테스트 종료하고 결과를 출력한다. 위 특징을 염두하여 예제코드를 실행하면 다음과 같은 결과가 나온다. // prop.check + OK, passed 100 tests. // failingProp.check ! Falsified after 5 passed tests. > ARG_0: List(\"0\", \"1\") > ARG_0_ORIGINAL: List(\"93\", \"12\", \"4\", \"70\", \"0\") 앞에서 개발한 비동기 합산 함수인 sum: List[Int]에 프로퍼티 기반 테스트를 적용하면 어떨까? // 목록을 뒤집어서 합해도 결과는 같아야 한다. val intList1 = Gen.listOf(Gen.choose(0, 100)) val prop1 = forAll(intList1)(ns => sum(ns.reverse) == sum(ns)) // 목록의 모든 요소가 같아도 원하는 합산 결과가 나와야 한다. val intList2 = Gen.listOf(1, 1, 1, 1, 1) val prop2 = forAll(intList2)(ns => sum(ns) == 5) 이번 챕터에서는 ScalaCheck을 직접 개발해보자. ScalaCheck을 쓰는 방법을 알아가는게 아니라 실제로 ScalaCheck을 개발한다. 처음부터 개발하라고 하면 막막하니깐 위에 적은 ScalaCheckExercise 라는 실행 코드 예제를 기반으로 ScalaCheck을 개발하자. ScalaCheck 개발 시작!앞의 예제코드를 하나하나씩 뜯어서 살펴보면서 영감을 얻도록 하자! val intList = Gen.listOf(Gen.choose(0, 100)) val prop = forAll(intList)(ns => ns.reverse.reverse == ns) &amp;&amp; forAll(intList)(ns => ns.headOption == ns.reverse.lastOption) Gen 시그니처 작성첫 번째 줄을 가만히 살펴보면 Gen.listOf() 와 Gen.choose()는 뭔가를 반환하고 있다는 것을 짐작할 수 있다. val intList = Gen.listOf(Gen.choose(0, 100)) 추측컨데 세 번째 줄에서 forAll 함수 호출부분을 보면 Gen.listOf로 만든 리스트를 가지고 predicate를 평가하고 있는 것을 보면 아마도 Gen.listOf의 결과물은 테스트 데이터(여기서는 List[Int])를 생성하는 생성기 인스턴스임을 짐작할 수 있다. def listOf[Int](???): Gen[List[Int]] 그런데 listOf의 파라미터로 Gen.choose(0, 100)의 결과를 전달하는 것으로 보아 Gen.choose(0, 100)도 뭔가 데이터 생성기를 반환한다고 짐작할 수 있다. 아마도 Gen[List[Int]]이라는 리스트를 생성하기 위해서 List[Int] 리스트에 들어갈 데이터를 임의로 생성하기 위한 시드 데이터 생성기를 반환하지 않을까 짐작해본다. 고로 Gen.choose()가 반환하는 데이터 생성기는 Gen[Int]가 아닐까? def listOf(a: Gen[Int]): Gen[List[Int]] // 일반화하면 def listOf[A](a: Gen[A]): Gen[List[A]] 잠깐 생각해볼 문제 위의 테스트 데이터 생성기 함수 listOf는 리스트의 크기를 정하지는 않았다. 왜 그럴까? 만약 리스트의 크기를 정하게 된다면 그 크기만큼의 리스트로 predicate를 평가하게 될텐데 문제 되진 않을까? 책에서는 Gen[List[A]]의 크기를 정하게 된다면 유연한 테스트 검사가 될 수 없다고 한다. 왜 그럴까? (p.162) forAll 시그니처 작성그 다음으로 넘어가서 forAll 함수 사용 코드를 살펴보자. val prop = forAll(intList)(ns => ns.reverse.reverse == ns) &amp;&amp; forAll(intList)(ns => ns.headOption == ns.reverse.lastOption) forAll 함수가 Gen[List[Int]]를 받아서 함수를 반환했는데 이 함수에는 predicate를 평가하는 함수이다. 추측한 내용을 바탕으로 forAll 시그니처를 작성하면 다음과 같다. def forAll(a: Gen[List[Int]])(f: List[Int] => Boolean): Prop // 일반화하면 def forAll[A](a: Gen[A])(f: A => Boolean): Prop Property 시그니처 작성위의 forAll 함수의 반환 결과물을 보면 뭔가 인스턴스를 반환하고 있는 것을 볼 수 있다. val prop = forAll(intList)(ns => ns.reverse.reverse == ns) &amp;&amp; forAll(intList)(ns => ns.headOption == ns.reverse.lastOption) prop.check --- // prop.check의 테스트 결과 출력 + OK, passed 100 tests. 그런데 &amp;&amp;라는 함수와 check라는 함수를 호출하는 것으로 보아 prop 인스턴스의 클래스는 &amp;&amp;와 check 함수를 멤버로 갖고 있을 것 같다. 일단 클래스 보다는 나중에 확장성을 위해서 trait으로 선언하자. trait Prop { def &amp;&amp;(p: Prop): Prop = ??? def check: Unit } 여지껏 해왔던 방식대로 제일 나중에 실행하는 함수부터 작성해보자. 이렇게 하는 이유는 그 함수를 작성하려고 했을 때 어떻게 구현해야 할지를 고민하면서 뭐가 필요한지를 고민하게 된다. 말이 쉽지 처음엔 엄청 막막할 것이다. 막막함을 없애기 위해 생각하는 힘을 길러야 할 것 같다. Prop의 멤버 함수 구현 고민해보기Prop.checkprop.check`을 호출하면 콘솔에 테스트 결과를 출력하고 있다. 이것은 부수효과이다. 일단 부수효과가 있다는 것을 염두해두자. Prop.&amp;&amp;&amp;&amp; 함수는 또다른 prop을 합성하여 새로운 합성 결과물 Prop을 내놓는 함수이다. 그 근거는 아래 함수 실행코드이다. val prop1 = forAll(intList)(ns => ns.reverse.reverse == ns) val prop2 = forAll(intList)(ns => ns.headOption == ns.reverse.lastOption) val prop = prop1 &amp;&amp; prop2 prop.check forAll이 내놓은 prop을 &amp;&amp;로 합성하면 prop들, 즉 합성한 prop이 모두 참인지를 check 함수를 호출하면 검사하게 될 것이다. 사실 여기서 갈림길이 나오는데 책과 내 생각은 이렇다. 책: 다시 Prop.check 구현 생각해보기 나: forAll 구현 생각해보기 내 생각엔 forAll 구현을 생각해봄으로써 &amp;&amp;의 구현을 이끌어내고 더 나아가 check까지 진행할 수 있지 않을까? 하는 기대가 있다. (하지만 여기서는 책을 따라가자 ㅜㅜ) 다시 Prop.check으로Q1: 만약 prop.check 호출 시 &amp;&amp;로 합성한 모든 prop들( prop1, prop2)을 따로따로 테스트 실행한다면? prop.check (prop1 &amp;&amp; prop2).check prop1.check &amp;&amp; prop2.check 잠깐!! 우선 위와 같은 질문을 하기 전에 전제조건이 있다. Prop.&amp;&amp;은 check 함수의 조합이라는 전제조건이 있어야 한다. trait Prop { def check: Boolean def &amp;&amp;(p: Prop): Prop = this.check &amp;&amp; p.check } A: check 함수는 부수효과가 있기 때문에 합성할 수 없다. (그리고 부수효과 때문에 결과물을 리턴하지도 않았다.) A: 그리고 prop1.check과 prop2.check 테스트 결과를 따로따로 실행하면 &amp;&amp;를 통해 두 결과가 다 통과되었는지도 파악이 안된다. Q2: 그럼 &amp;&amp;로 합성하면 합성한 prop에 대해서만 prop.check을 호출하면 되는거 아닌가? A: 고민해봤는데 prop1은 prop1만의 predicate가 있을 것이고 prop2는 prop2만의 predicate가 있을 것이다. prop1과 prop2를 합성한다는 것은 이 predicate들도 &amp;&amp;로 합성해야 한다는 것을 의미한다. 고로 우리가 고민해야될 것은 &amp;&amp;를 통해 어떻게 합성할 것인지, 그리고 그 합성한 것의 predicate는 어떻게 유연하게 평가(예를 들어 prop을 &amp;&amp;로 합성할 때는 predicate도 &amp;&amp;로 합성, prop을 ||로 합성할 때는 predicate도 ||로 합성)할 것인지를 고민하면 prop.check은 check 함수가 부수효과가 있던 말던 합성된 prop 하나만 신경쓰면 되지 않을까? 여기서 잠깐!! Q1에서 말한 전제조건\u001c만 없으면 check 함수는 부수효과가 있는채로 냅두고 &amp;&amp;로 합성하는 코드만 잘 작성하면 되는거 아닐까? 그런데 책에서는 Q1의 전제조건을 깔고 check 함수의 부수효과를 없애는 방법을 택했다. 일단 책은 따라가되 전제조건이 없을 때 &amp;&amp;의 구현이 어떻게 될지 살펴봐야겠다. 그렇게 되면 책이 택한 방법에 대한 이유가 좀 더 명확해지지 않을까.. Prop.check에서 부수효과 없애기일단 check 함수의 부수효과를 없애기 위해서 반환값을 추가하자. 이 반환값은 테스트한 결과 몇 건 성공하고 몇 건 실패했는지를 반환하자. 그러기 위해서는 Either를 택해야 할 것이다. 일단 left(실패)는 나중에 생각하자. trait Prop { def check: Either[???, SuccessCount] } object Prop { type SuccessCount = Int } 실패는 실패한 이유와 실패하기 전 성공한 테스트 개수를 추가해보자. trait Prop { def check: Either[(FailedCase, SuccessCount), SuccessCount] } object Prop { type SuccessCount = Int type FailedCase = String } 다시 Prop.forAll으로check의 반환을 Unit에서 Either로 바꾸긴 했지만 그 구현을 생각하기엔 아직도 막막하다. 이 때 좀 거슬러 올라가서 prop과 이 prop을 생성하는 forAll을 생각해보자. def forAll[A](a: Gen[A])(f: A => Boolean): Prop 일단 책의 내용대로 따라가기가 어려우니 내 머릿속에 떠오르는 생각을 적어보자. forAll(a: Gen[A])을 통해 뭔가 임의의 테스트 데이터를 생성하는 로직이 담긴 함수를 반환할 것이다. 이 함수를 g라고 하자. (임의의 테스트 데이터 생성을 위해 난수 발생기가 아마 필요할듯 하다.) g(f: A =&gt; Boolean)를 통해 임의로 생성된 데이터를 f 함수에 넘겨서 평가할 수 있는 prop 객체 혹은 함수가 또 반환될 것이다. 이 반환물을 prop이라고 하자. prop.check을 호출하면 트리거를 당긴 것과 같이 순차적으로 임의의 테스트 데이터셋 생성 및 predicate 수행, 테스트 결과 반환이 일어날 것이다. 일단 위에 떠오르는 생각은 나중에 구현해보기로 하고, 시간 관계상 책에 있는 해답을 추가한다. object Prop { def forAll[A](as: Gen[A])(f: A => Boolean): Prop = Prop { (n, rng) => randomStream(as)(rng).zip(Stream.from(0)).take(n).map { case (a, i) => try { if (f(a)) Passed else Falsified(a.toString, i) } catch { case e: Exception => Falsified(buildMsg(a, e), i) } }.find(_.isFalsified).getOrElse(Passed) } def randomStream[A](g: Gen[A])(rng: RNG): Stream[A] = Stream.unfold(rng)(rng => Some(g.sample.run(rng))) def buildMsg[A](s: A, e: Exception): String = s\"\"\" test case: $s generated an exception: ${e.getMessage} stack trace: ${e.getStackTrace.mkString(\"\\n\")} \"\"\".stripMargin def check(): Result = ??? } sealed trait Result { def isFalsified: Boolean } case object Passed extends Result { def isFalsified = false } case class Falsified(failure: FailedCase, success: SuccessCount) extends Result { def isFalsified = true } type TestCases = Int type Result = Option[(FailedCase, SuccessCount)] case class Prop(run: TestCases => Result)","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"http://icednut.github.io/tags/scala/"},{"name":"functional programming","slug":"functional-programming","permalink":"http://icednut.github.io/tags/functional-programming/"}]},{"title":"스칼라 스터디 Day06 - 순수 함수적 병렬성","slug":"20190107-scala-and-functional-programming-day06","date":"2019-01-06T16:00:23.000Z","updated":"2019-01-16T07:01:34.237Z","comments":true,"path":"2019/01/07/20190107-scala-and-functional-programming-day06/","link":"","permalink":"http://icednut.github.io/2019/01/07/20190107-scala-and-functional-programming-day06/","excerpt":"","text":"출처: 스칼라로 배우는 함수형 프로그래밍 7장 Chapter 07. 순수 함수적 병렬성이번 챕터에서 다룰 내용 숫자 목록 합산하는 함수 만들기 숫자 합산을 병렬적으로 풀기 풀이 진행 중 일반화 진행 이번 챕터에서 특히 어려움을 많이 느꼈는데, 중간중간 불쑥 튀어나오는 함수 조합기와 그 조합기 구현을 어떻게 그렇게 생각해낼수 있을지 조금은 경외심도 느꼈다. 나로써는 도저히 그렇게 한 방에 그런 구현이 나와야 된다는 생각이 안들던데 그래서 그런지 연습문제도 딱히 어떻게 풀어야 겠다는 생각이 안들어서 어렵다고 느끼는 것 같다. 각설하고 공부한 내용을 정리하자. 숫자 목록 합산하는 함수 만들기이번 챕터에서는 목록에 있는 정수(Int)들의 합을 구하는 함수를 구하는 것으로 시작해보자. 1. foldLeft를 이용한 숫자 목록의 합 구하기def sum(ints: Seq[Int]): Int = ints.foldLeft(0)((a, b) => a + b) 위 구현 방식은 Seq 중 왼쪽에서 오른쪽으로 숫자 두 개씩 접으면서 수행하는 코드 동작 방식으로 진행한다. sum(Seq(1, 2, 3, 4, 5)) Seq(1, 2, 3, 4, 5).foldLeft(0)((a, b) => a + b) Seq(2, 3, 4, 5).foldLeft(0 + 1)((a, b) => a + b) Seq(3, 4, 5).foldLeft(1 + 2)((a, b) => a + b) Seq(4, 5).foldLeft(3 + 3)((a, b) => a + b) Seq(5).foldLeft(6 + 4)((a, b) => a + b) 15 2. Divide-and-conquer 알고리즘을 이용한 숫자 목록의 합 구하기순차적으로 접으면서 계산하는 것도 좋지만 합(sum)을 병렬로 돌리게 하고 싶을 경우 어떻게 할까? 추후 병렬로 하기 위해 계산 작업을 쪼개서 실행하는 분할정복 (divide-and-conquer) 알고리즘을 적용해보자. def sum(ints: IndexedSeq[Int]): Int = if (ints.size &lt;= 1) ints.headOption().getOrElse(0) else { val (l, r) = ints.splitAt(ints.length / 2) sum(l) + sum(r) } 이는 ints를 splitAt 함수를 이용하여 절반으로 나누고 재귀적으로 두 절반을 각각 합해서 결과들을 합치는 방식(sum(l) + sum(r))이다. 이렇게 합치는 계산(sum)을 재귀적으로 쪼개서 실행하는 방식이므로 foldLeft와는 다르게 병렬화할 수 있다. (두 절반을 병렬로 합할 수 있다) 숫자 합산을 병렬적으로 풀기1. 숫자 계산 부분만 병렬(쓰레드)로 처리하기2번의 구현 내용을 병렬적으로 풀기 위해서는 sum(l)과 sum(r)을 각각 개별 스레드에서 실행(평가)할 수 있도록 구조를 변경한다. 이렇게 개별적으로 계산 및 결과를 담을 Par[A]라는 자료형을 만들자(여기서 A는 계산 결과의 타입을 의미). Par[A]를 사용한 숫자 목록 합산 함수는 다음과 같다. def sum(ints: IndexedSeq[Int]): Int = if (ints.size &lt;= 1) ints headOption getOrElse 0 else { val (l, r) = ints.splitAt(ints.length / 2) val sumL: Par[Int] = Par.unit(sum(l)) val sumR: Par[Int] = Par.unit(sum(r)) Par.get(sumL) + Par.get(sumR) } 위의 Par.unit과 Par.get 사용한 것을 보고 함수의 시그니처를 생각해보면 다음과 같다. object Par { def unit[A](a: => A): Par[A] // 숫자 계산(a 썽크)을 병렬(스레드)로 처리 def get[A](a: Par[A]): A // Par에서 숫자 계산 결과값을 꺼냄 } 여기서 Par.unit은 썽크를 받아서 병렬로 처리한 뒤 결과 값을 상태로 갖고 있는 것이고, Par.get은 Par에 담긴 결과값을 추출하는 함수이다. 여기서 잠깐! Par.unit 함수를 어떻게 구현할까? unit 함수 인자로 받은 썽크를 unit 호출 시 바로 병렬로 처리하여 결과를 갖고 있다가 Par.get이 호출되면 그 결과를 반환한다. (위에서 한 얘기) unit 함수 인자로 받은 썽크를 unit 호출 시 바로 실행하지 않고 Par.get이 호출되면 해당 썽크를 비동기로 호출하여 결과를 반환한다. 여기서는 1번의 방법으로 진행하는 것이 병렬성에 이점을 취할 수 있는데, 그 이유는 2번 방법으로 실행하면 get 함수를 호출하면 계산 결과가 나올 때까지 기다리기 때문에 병렬적으로 실행되지 않게 되기 때문이다. 아래 코드를 보자. Par.get(sumL) + Par.get(sumR) 위 코드를 2번 방식으로 진행된다면 Par.get(sumL)에서 계산이 끝나야지 Par.get(sumR)이 호출되기 때문이다. (스칼라에서는 구문을 왼쪽에서 오른쪽으로 실행) 그렇기 때문의 우리의 Divide-and-conquer 코드에서는 1번 방식으로 해결하는 것이 좋다. 이슈 발생: 참조 투명성이 깨짐1번 방식으로 진행한다고 해도 참조 투명성이 깨진다. 왜 그럴까? 참조 투명성을 증명하기 위해 sumL과 sumR을 아래와 같이 치환한다. Par.get(Par.unit(sumL))) + Par.get(Par.unit(sum(r))) 이렇게 보면 또다시 병렬로 실행되지 않는 문제가 나타날 뿐만아니라, unit의 결과값(상태)를 갖고 있는 형식이 되기 때문에 부수효과가 존재하게 된다. 이런 부수 효과 때문에 Par.get이 영향을 받는다. 구체적으로 무슨 영향을 받는 것일까? Par.get 메소드는 Par.unit에서 계산된 결과값에 따라 결과 값을 반환하도록 의존하게 된다. 즉 Par.unit의 병렬 계산이 끝나기 전까지는 Par.get 호출의 결과 반환은 Blocking 된다. Par.get(Par.unit(sumL)))이 끝나야지 Par.get(Par.unit(sum(r))) 이 실행되는 이슈가 여전히 드러난다. 우리의 목표는 숫자 합산이 병렬로 처리되어야 하는데 Par.unit에서 아무리 병렬로 합을 계산한다고 해도 Par.get에서 블로킹되어 버리니 궁극적인 병렬처리는 아니다. 그럼 이걸 어떻게 해결할까? 2. 병렬계산을 조합하기Par.get에서 블로킹이 되는거 때문에 병렬처리가 안된다면 Par.get을 걷어내자. Par.get을 걷어내면 Par.unit 에서 처리된 병렬처리 계산 결과는 어떻게 추출할 것인가? 관점을 변경해서 Par.unit이 하나의 계산 병렬처리라면 이 병렬처리 여러 개를 모아서 한꺼번에 그 결과를 반환하게 하면 어떨까? 즉 병렬처리 함수들을 하나로 조합하여 결과 추출(Par.get)을 한 번만 하게 하는 것이다. 이렇게 병렬처리를 조합하는 아이디어를 반영한 sum 코드는 다음과 같다. def sum(ints: IndexedSeq[Int]): Par[Int] = if (ints.size &lt;= 1) Par.unit(ints.headOption getOrElse 0) else { val (l, r) = ints.splitAt(ints.length / 2) Par.map2(sum(l), sum(r))(_ + _) } 그럼 Par.map2 라는 조합기 함수의 시그니처를 살펴보자. object Par { ... def map2(ap: Par[A], bp: Par[B])(f: (A, B) => C): Par[C] } map2를 좀 더 살펴보자. map2는 ap와 bp가 각각 병렬로 실행되어야 한다. 즉 ap와 bp가 인수로 전달 되자마자 병렬 실행이 되어야 하며 이는 map2가 엄격한 함수이어야 한다는 의미이다. 과연 그럴까? sum 코드 실행을 한 번 추적해보자. 1: sum(IndexedSeq(1,2,3,4)) 2: Par.map2( sum(IndexedSeq(1,2)), sum(IndexedSeq(3,4)) )(_ + _) 3: Par.map2( map2(sum(IndexedSeq(1)), sum(IndexedSeq(2)))(_ + _), sum(IndexedSeq(3,4)) )(_ + _) 4: Par.map2( map2(Par.unit(1), Par.unit(2))(_ + _), sum(IndexedSeq(3,4)) )(_ + _) 5: Par.map2( map2(Par.unit(1), Par.unit(2))(_ + _), map2(sum(IndexedSeq(3)), sum(IndexedSeq(4)))(_ + _) )(_ + _) 6: Par.map2( map2(Par.unit(1), Par.unit(2))(_ + _), map2(Par.unit(3), Par.unit(4))(_ + _) )(_ + _) 이슈 발생: 병렬처리 실행이 한꺼번에 실행되지 않음위 코드 추적 과정을 통해 밝혀진 문제점은 무엇일까? 4번 과정에서 나타난 것과 같이 아직 IndexedSeq(3,4)에 대한 병렬처리가 시작되기도 전에 Par.unit(1)과 Par.unit(2) 라는 병렬처리가 시작되는 이슈가 발생하기 시작한다. 즉, 오른쪽 인수가 모두 평가되기도 전에 왼쪽 인수의 병렬처리가 실행되버리는 형태가 나타나게 된다. 이는 곧 완전하지 않은 병렬처리라고 볼 수 있다. 그럼 위 이슈를 어떻게 해결할까? 3. Par.map2 사용에 따른 명시적 병렬처리 실행코드 추가위 이슈를 해결하기 위해 Par.map2의 인수를 게으르게 평가하도록 바꾸려고 생각할 것이다. (인수의 게으른 혹은 엄격한 평가는 6장을 참조) 하지만 좀 더 근본적인 문제 해결을 생각해보자. 굳이 Par.map2는 꼭 인수들을 엄격하게 병렬로 평가할 필요가 있을까? 여기서 잠깐? fork의 등장문제: sum(IndexedSeq(1,2)) 처리하자고 스레드 2개나 만들어서 처리해야할까? (Par.unit(1)용 스레드 하나, Par.unit(2)용 스레드 하나) 굳이 스레드까지 쓸 필요 없이 1 + 2는 눈 깜짝할 사이에 끝날 것이 자명하다. 여기서 우리는 Par.map2는 병렬처리라는 인수를 엄격하게 평가하되 개발자가 해당 인수는 병렬 처리라는 것을 명시해주는 장치가 필요하다. 왜냐면 아까와 같이 병렬처리가 필요없는 곳에서는 병렬처리를 안하도록 명시하는 것을 프로그래머가 명시할 수 있게 되는 것이다. 즉 아래와 같이 Par를 개별 스레드에서 처리하게 하는 fork 함수를 선언하고 더 이상 Par.unit에서는 병렬처리 코드를 걷어내는 것이 바람직하다. (병렬처리를 개발자가 fork를 통해 명시적으로 표시하게 함) def fork[A](a: => Par[A]): Par[A] 앞에서 말한 것처럼 병렬 실행을 프로그래머가 결정하게 하기 위해 fork를 적용해보자. def sum(ints: IndexedSeq[Int]): Par[Int] = if (ints.length &lt;= 1) Par.unit(ints.headOption getOrElse 0) else { val (l, r) = ints.splitAt(ints.length / 2) Par.map2(Par.fork(sum(l)), Par.fork(sum(r)))(_ + _) } fork에게 병렬 실행을 위임하였으니 정말 문제가 없을까? 앞에서 했던 것처럼 실행 과정을 추적해보자. 1: sum(IndexedSeq(1,2,3,4)) 2: Par.map2( Par.fork(sum(IndexedSeq(1,2))), // sum(IndexedSeq(1,2))를 병렬 실행 Par.fork(sum(IndexedSeq(3,4))) // sum(IndexedSeq(3,4))를 병렬 실행 )(_ + _) 3: //sum(IndexedSeq(1,2)) Par.map2( Par.fork(sum(IndexedSeq(1))), // sum(IndexedSeq(1))를 병렬 실행 Par.fork(sum(IndexedSeq(2))) // sum(IndexedSeq(2))를 병렬 실행 )(_ + _) + //sum(IndexedSeq(3,4)) Par.map2( Par.fork(sum(IndexedSeq(3))), // sum(IndexedSeq(3))를 병렬 실행 Par.fork(sum(IndexedSeq(4))) // sum(IndexedSeq(4))를 병렬 실행 )(_ + _) 4: // sum(IndexedSeq(1))의 병렬 실행 Par.unit(1) // sum(IndexedSeq(2))의 병렬 실행 Par.unit(2) // sum(IndexedSeq(3))의 병렬 실행 Par.unit(3) // sum(IndexedSeq(4))의 병렬 실행 Par.unit(4) 위의 Par.unit들을 +로 묶은 Par를 반환함 완전히 맞지는 않지만 일단 병렬실행이 언제 실행되는지를 표시하는데에 중점을 두었다. 위의 실행 과정으로 미루어봤을 때 map2의 두 인자가 동시에 병렬적으로 실행하게 되었다. 즉, Par.fork를 쓰면 Par.map2는 엄격하게 해도 병렬적으로 실행되며, Par.unit은 엄격하게 해도 병렬실행에 문제가 생기지 않는다. 끄읕~ 과연 이대로 끝일까? 병렬처리의 평가sum 함수가 이제 Par.map2로 Par.fork들로 묶인 병렬처리들을 조합하여 Par를 반환하는 것으로 탈바꿈하였다. 그럼 sum 함수의 결과는 Par[A]로 Par.get을 호출하면 결과를 얻을 수 있을 것이다. 그럼 Par.fork를 호출하는 즉시 내부적으로 병렬 실행을 평가하게 하는게 좋을까? 아니면 Par.get을 호출할 때 Par.fork로 조합한 Par.unit들을 병렬 실행을 평가하게 하는게 좋을까? 나는 솔직히 둘 다 괜찮다고 생각했다. 그러나 책에서는 후자가 더 좋은 선택이라고 소개하며, 전자가 나쁜 이유를 설명하는데 솔직히 이해를 못하겠다. p.129 만일 fork가 자신의 인수를 즉시 병렬로 평가하기 시작한다면, 그 구현은 스레드를 생성하는 방법이나 과제를 일종의 스레드 플에 제출하는 방법을 직접적으로든 간접적으로든 알고 있어야 한다. 더 나아가서, 이는 스레드 풀(또는 병렬성을 구현하는 데 사용하는 어떤 자원)이 반드시 접근 가능한(전역적으로) 자원이어야 하며, fork를 호출하는 시점에서 이미 적절히 초기화되어 있어야 함을 의미한다. 그런 조건을 만족하려면 프로그램의 여러 부분에서 쓰이는 병렬성 전략을 프로그래머가 임의로 제어할 수 있는 능력을 포기해야 한다. 병렬 과제들의 실행을 위해 전역 자원을 두는 것이 근본적으로 잘못된 일은 아니지만, 구현이 무엇을 언제 사용할 것인지를 프로그래머가 좀 더 세밀하게 제어할 수 있다면 더 좋은 것임을 상상이 가능하다(예를 들어 큰 응용 프로그램의 각 하위 시스템이 각자 다른 매개변수들로 설정된 스레드 풀을 유지하는 등). 따라서 스레드 생성과 실행 과제 제출의 책임을 get에 부여하는 것이 훨씬 적합하겠다. … fork가 그냥 인수의 평가를 뒤로 미루게 한다면, fork는 병렬성 구현을 위한 메커니즘에 접근할 필요가 없다. 그냥 평가되지 않은 Par 인수를 받고 그 인수에 동시적 평가가 필요하다는 점을 ‘표시’만 해 두면 된다. 이것이 바로 fork의 의미라고 가정하자. 이러한 모형에서, Par 자체는 병렬성의 구체적인 구현 방법을 알 필요가 없다. Par는 나중에 get 함수 같은 무언가에 의해 해석될 병렬 계산에 관한 서술에 가깝다. 이는, Par를 나중에 준비되었을 때 조회(get)할 어떤 값을 담은 컨테이너라고 생각했던 것과는 다른 발생이다. 이제는 실행이 가능한 일급 프로그램에 좀 더 가까워졌다. 그런 취지에서 get 함수의 이름을 run으로 바꾸고, 병렬성이 실제로 구현되는 지점이 바로 이 run 함수임을 천명하기로 하자. def run[A](a: Par[A]): A 위 내용을 요약하자면 Par.fork는 인자로 받은 썽크를 병렬처리 장치로 감싼(책에서는 이걸 서술이라고 표현) 자료구조를 반환하게 되고, 이 병렬 자료구조를 실행하는 것은 Par.run에서 하게 한다. (병렬 자료구조를 스레드 풀에 위임하거나 아니면 다른 방법을 쓰는 것은 그 다음 얘기) 4. 여태까지 정리한거를 코드로 선언해보자!object Par { def unit[A](a: A): Par[A] = (es: ExecutorService) => UnitFuture(a) def lazyUnit[A](a: => A): Par[A] = fork(unit(a)) private case class UnitFuture[A](get: A) extends Future[A] { def isDone = true def get(timeout: Long, units: TimeUnit) = get def isCancelled = false def cancel(evenIfRunning: Boolean): Boolean = false } def map2[A,B,C](a: Par[A], b: Par[B])(f: (A,B) => C): Par[C] = (es: ExecutorService) => { val af = a(es) val bf = b(es) UnitFuture(f(af.get, bf.get)) } def map[A,B](pa: Par[A])(f: A => B): Par[B] = map2(pa, unit(()))((a, _) => f(a)) def fork[A](a: => Par[A]): Par[A] = es => es.submit(new Callable[A] { def call = a(es).get }) // asyncF는 A => B의 결과를 비동기로 평가되는 함수로 변환하는 함수 // lazyUnit을 이용해서 작성하면 된다. def asyncF[A, B](f: A => B): A => Par[B] = { a => lazyUnit(f(a)) } } UnitFuture는 병렬 실행 자료구조일 뿐 병렬처리 실행 로직은 들어있지 않다. fork 함수의 구조를 할펴보면 이슈가 있는 것을 발견할 수 있다. (Deadlock 위험 내제) class ExecutorService { def submit[A](a: Callable[A]): Future[A] } trait Callable[A] { def call: A } trait Future[A] { def get: A def get(timeout: Long, unit: TimeUnit): A def cancel(evenIfRunning: Boolean): Boolean def isDone: Boolean def isCancelled: Boolean } type Par[A] = ExecutorService => Future[A] def run[A](es: ExecutorService)(a: Par[A]): Future[A] = a(es) def equal[A](es: ExecutorService)(p: Par[A], p2: Par[A]): Boolean = p(e).get == p2(e).get 코드를 구현했으면 아래와 같은 궁금증이 생길 것이다. (난 안생기던데..) 위에 구현된 조합기(map2, map)들로 어떤 것을 표현할 수 있을까? fork 함수에서 쓰는 ExecutorService에서 발생할 수 있는 문제는 무엇일까? 1번은 생략하고 2번을 살펴보자. 5. Par.fork: 스레드 풀과 교착상태 그리고 해결ExecutorService.submit 는 병렬로 평가할 행위(Callable)을 스레드 풀에게 병렬처리를 위임하는 방향으로 구현하는 것을 대부분 생각할 것이다. 그러나 고정된 크기의 스레드 풀을 사용하는 ExecutorService 구현은 Deadlock에 빠질 수 있다. 만약 스레드 풀의 최대 스레드 개수가 1이라고 할 때, 아래와 같은 코드는 잘 동작할까? val a = lazyUnit(42 + 1) val S = Executors.newFixedThreadPool(1) println( Par.equal(S)(a, fork(a)) ) 문제는 fork를 호출할 때 발생한다. def fork[A](a: => Par[A]): Par[A] = es => es.submit(new Callable[A] { def call = a(es).get }) fork(a)를 호출하면 es =&gt; es.submit(new Callable[A] {...}) 를 호출하게 될 것이다. (1) 그런데 new Callable[A] { ... } 의 구현을 살펴보면 a(es) 를 호출하여 ExecutorService 를 넘겨서 만들어진 UnitFutre(a) 를 또 fork()에 인자로 넘겨서 실행하게 된다. (2) object Par { def unit[A](a: A): Par[A] = (es: ExecutorService) => UnitFuture(a) def lazyUnit[A](a: => A): Par[A] = fork(unit(a)) ... } 즉 fork가 두 번 호출되게 되며, 스레드 풀에게 (1)의 Callable을 실행하라고 전달하여 스레드를 선점하였는데 (2)를 또 실행하라고 Callable을 만들어서 스레드 플에게 전달하면 스레드가 이미 없기 때문에 실행이 안되는 상황이 발생한다. 즉 (1)은 병렬 실행 중이지만 끝날 때까지 기다리게 되고, (2)는 스레드가 이미 모두 선점되어 있기 때문에 시작조차 못해서 끝날 수도 없게 된다. 이걸 바로 교착상태에 빠졌다고 말한다. 이걸 어떻게 해결할까? 6. Actor 등장: non-blocking 형태의 Par 구현하기위 문제의 근본적인 문제는 Par.get 이 호출되면 끝날 때까지 기다리게 된다는게 문제이다. (Par.get 함수가 blocking 함수이다) 다시 말하면 Par.get 의 호출이 일어나게 되면 병렬처리의 결과가 나올 때까지 기다리게 되며, 그 다음으로 넘어갈 수가 없다. 따라서 해결은 Non-blocking 으로만 동작하는 Par을 구현하면 된다. (정말 그럴까? 조금 의심스럽지만 도무지 상상이 안간다…) 그리고 fork와 map2에서 Blocking 함수(ex: Par.get 등등)를 호출하지 않게 하면 된다. fork, map2에서 블로킹 함수 Par.get을 호출하는 것을 피하기 위해서는 데이터를 가져오는 행위를 콜백으로 감싸서 fork와 map2에서 호출하게 하자. 그러기 위해서는 Par.unit 부터 콜백 함수를 호출하는 방식으로 변경되어야 한다. fork()AS-ISobject Par { def unit[A](a: A): Par[A] = (es: ExecutorService) => UnitFuture(a) private case class UnitFuture[A](get: A) extends Future[A] { def isDone = true def get(timeout: Long, units: TimeUnit) = get def isCancelled = false def cancel(evenIfRunning: Boolean): Boolean = false } } TO-BEobject Par { def unit[A](a: A): Par[A] = (es: ExecutorService) => new Future[A] { def apply(cb: A => Unit): Unit = cb(a) } } map2()AS-ISobject Par { ... def map2[A,B,C](a: Par[A], b: Par[B])(f: (A,B) => C): Par[C] = (es: ExecutorService) => { val af = a(es) val bf = b(es) UnitFuture(f(af.get, bf.get)) } } TO-BEobject Par { ... def map2[A, B, C](a: Par[A], b: Par[B])(f: (A, B) => C): Par[C] } package fpinscala.parallelism import java.util.concurrent.atomic.{AtomicInteger, AtomicReference} import java.util.concurrent.{Callable,ExecutorService} import annotation.tailrec /* * Implementation is taken from `scalaz` library, with only minor changes. See: * * https://github.com/scalaz/scalaz/blob/scalaz-seven/concurrent/src/main/scala/scalaz/concurrent/Actor.scala * * This code is copyright Andriy Plokhotnyuk, Runar Bjarnason, and other contributors, * and is licensed using 3-clause BSD, see LICENSE file at: * * https://github.com/scalaz/scalaz/blob/scalaz-seven/etc/LICENCE */ /** * Processes messages of type `A`, one at a time. Messages are submitted to * the actor with the method `!`. Processing is typically performed asynchronously, * this is controlled by the provided `strategy`. * * Memory consistency guarantee: when each message is processed by the `handler`, any memory that it * mutates is guaranteed to be visible by the `handler` when it processes the next message, even if * the `strategy` runs the invocations of `handler` on separate threads. This is achieved because * the `Actor` reads a volatile memory location before entering its event loop, and writes to the same * location before suspending. * * Implementation based on non-intrusive MPSC node-based queue, described by Dmitriy Vyukov: * [[http://www.1024cores.net/home/lock-free-algorithms/queues/non-intrusive-mpsc-node-based-queue]] * * @see scalaz.concurrent.Promise for a use case. * * @param handler The message handler * @param onError Exception handler, called if the message handler throws any `Throwable`. * @param strategy Execution strategy, for example, a strategy that is backed by an `ExecutorService` * @tparam A The type of messages accepted by this actor. */ final class Actor[A](strategy: Strategy)(handler: A => Unit, onError: Throwable => Unit = throw(_)) { self => private val tail = new AtomicReference(new Node[A]()) private val suspended = new AtomicInteger(1) private val head = new AtomicReference(tail.get) /** Alias for `apply` */ def !(a: A) { val n = new Node(a) head.getAndSet(n).lazySet(n) trySchedule() } /** Pass the message `a` to the mailbox of this actor */ def apply(a: A) { this ! a } def contramap[B](f: B => A): Actor[B] = new Actor[B](strategy)((b: B) => (this ! f(b)), onError) private def trySchedule() { if (suspended.compareAndSet(1, 0)) schedule() } private def schedule() { strategy(act()) } private def act() { val t = tail.get val n = batchHandle(t, 1024) if (n ne t) { n.a = null.asInstanceOf[A] tail.lazySet(n) schedule() } else { suspended.set(1) if (n.get ne null) trySchedule() } } @tailrec private def batchHandle(t: Node[A], i: Int): Node[A] = { val n = t.get if (n ne null) { try { handler(n.a) } catch { case ex: Throwable => onError(ex) } if (i > 0) batchHandle(n, i - 1) else n } else t } } private class Node[A](var a: A = null.asInstanceOf[A]) extends AtomicReference[Node[A]] object Actor { /** Create an `Actor` backed by the given `ExecutorService`. */ def apply[A](es: ExecutorService)(handler: A => Unit, onError: Throwable => Unit = throw(_)): Actor[A] = new Actor(Strategy.fromExecutorService(es))(handler, onError) } /** * Provides a function for evaluating expressions, possibly asynchronously. * The `apply` function should typically begin evaluating its argument * immediately. The returned thunk can be used to block until the resulting `A` * is available. */ trait Strategy { def apply[A](a: => A): () => A } object Strategy { /** * We can create a `Strategy` from any `ExecutorService`. It's a little more * convenient than submitting `Callable` objects directly. */ def fromExecutorService(es: ExecutorService): Strategy = new Strategy { def apply[A](a: => A): () => A = { val f = es.submit { new Callable[A] { def call = a} } () => f.get } } /** * A `Strategy` which begins executing its argument immediately in the calling thread. */ def sequential: Strategy = new Strategy { def apply[A](a: => A): () => A = { val r = a () => r } } }","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"http://icednut.github.io/tags/scala/"},{"name":"functional programming","slug":"functional-programming","permalink":"http://icednut.github.io/tags/functional-programming/"}]},{"title":"스칼라 스터디 Day05 - 순수 함수적 상태","slug":"20181226-scala-and-functional-programming-day05","date":"2018-12-25T06:43:51.000Z","updated":"2019-01-07T11:12:26.640Z","comments":true,"path":"2018/12/25/20181226-scala-and-functional-programming-day05/","link":"","permalink":"http://icednut.github.io/2018/12/25/20181226-scala-and-functional-programming-day05/","excerpt":"","text":"출처: 스칼라로 배우는 함수형 프로그래밍 6장 Chapter 06. 순수 함수적 상태이번 챕터에서 다룰 내용 난수 발생(scala.util.Random)의 문제점 순수 함수적으로 난수 발생하기 상태가 있는 함수를 순수하게 하기 난수 발생기 일반화하기 순수 상태 함수 일반화하기 난수 발생(scala.util.Random)의 문제점스칼라의 난수 발생기 클래스(scala.util.Random)은 부수 효과에 의존하는 메소드를 제공한다. 왜 이렇게 말하는걸까? scala> val rng = new scala.util.Random rng: scala.util.Random = scala.util.Random@74fab04a scala> rng.nextDouble res0: Double = 0.8020301517138297 scala> rng.nextDouble res1: Double = 0.169106827118352 scala> rng.nextInt res2: Int = -968884305 scala> rng.nextInt(10) res3: Int = 1 scala.util.Random.nextDouble, scala.util.Random.nextInt 메소드를 보면 호출할 때마다 다른 값(난수)이 나오는 것을 볼 수 있다. 이것은 해당 메소드들이 호출될 때마다 갱신되는 어떤 내부 상태가 존재한다고 가정할 수 있다 (즉 부수효과가 있는 메소드라는 의미). 상태 갱신은 부수효과로서 수행되므로 이 메소드들은 참조에 투명하지 않다고 볼 수 있다. 부수효과가 있으면 뭐가 안좋다고? 검사, 합성, 모듈화가 어려워진다. 병렬화가 쉽지 않다. 과연 그럴까? 부수효과가 있는 함수의 검사성을 살펴보자. 문제)주사위 메소드를 구현해보자. 이 메소드는 반드시 1 이상 6 이하의 정수를 돌려주어야 한다. def rollDie: Int = { val rng = new scala.util.Random rng.nextInt(6) // * } 그런데 rng.nextInt(6)은 0 이상 5 이하의 난수를 돌려준다. 그러므로 1 이상 6 이하의 값을 준다는 검사에서 여섯 번 중 다섯 번은 실패하게 되는데 이는 랜덤하게 발생된다. 이 버그를 문제라고 말한다. 왜 이 버그가 이슈일까? 이슈: 버그가 명백하지만 재현하기가 어렵다. 이슈: 만약 프로그램이 복잡해지고 버그가 그에 비례하여 복잡해진다면 이를 재현하기가 점점 더 어려워지고 이를 재현하기 위해 프로그래머의 능력이 훨씬 중요해진다. 해결1)해결책으로는 난수 발생기 rng 를 인수로 전달하는 것이다. 왜 이렇게 할까? 답: 실패한 검사를 재현할 때 당시에 인수로 쓰인 rng를 재사용하기 위해 def rollDie(rng: scala.util.Random): Int = rng.nextInt(6) 그러나 여기에도 이슈가 있다. 이슈: rng를 인수로 받았다고 해도 여전히 rng.nextInt 를 호출하면 rng 내부의 상태가 변한다. 이슈: 검사를 재현할 때 당시에 인수로 쓰인 rng의 상태가 동일하게 하기 위해서는 nextInt 메소드 호출을 추적해야 되는 메커니즘을 따로 개발해야 된다. 결국 해결하기 위해서는 부수효과를 피해야 한다. 순수 함수적으로 난수 발생하기앞의 문제를 어떻게 해결할까? 상태 갱신을 명시적으로 드러내는 방법으로 난수 생성 함수 호출 시 난수와 상태를 담고 있는 난수생성기를 함께 반환하는 것이다. trait RNG { def nextInt: (Int, RNG) // (난수, 난수 생성에 사용된 난수 생성기) } 이 트레이트를 사용해서 간단한 난수 생성기를 구현하면 다음과 같다. case class SimpleRNG(seed: Long) extends RNG { def nextInt: (Int, RNG) = { val newSeed = (seed * 0x5DEECE66DL + 0xBL) &amp; 0xFFFFFFFFFFFFL val nextRNG = SimpleRNG(newSeed) val n = (newSeed >>> 16).toInt (n, nextRNG) } } nextInt 메소드를 살펴보면 newSeed(상태)가 담긴 새로운 SimpleRNG 인스턴스를 생성하여 난수를 생성하고 있다. 그렇기 때문에 동일한 객체의 nextInt 함수를 아무리 많이 호출해도 동일한 newSeed를 사용하여 난수를 생성하기 때문에 이 함수는 순수하다. scala> val rng = SimpleRNG(42) rng: SimpleRNG = SimpleRNG(42) scala> val (n1, rng2) = rng.nextInt // 1 n1: Int = 16159453 rng2: RNG = SimpleRNG(1059025964525) scala> val (n2, rng3) = rng2.nextInt // 2 n2: Int = -1281479697 rng3: RNG = SimpleRNG(197491923327988) scala> val (n3, rng4) = rng2.nextInt // 3 n3: Int = -1281479697 rng4: RNG = SimpleRNG(197491923327988) scala> val (n4, rng5) = rng.nextInt // 4 n4: Int = 16159453 rng5: RNG = SimpleRNG(1059025964525) 위 예제에서 보면 rng.nextInt1과 4 두 번 실행했음에도 불구하고 동일한 난수를 얻었다. 마찬가지로 2와 3에서도 동일한 난수 생성기로 난수 생성 호출 rng2.nextInt 을 했음에도 불구하고 동일한 난수를 얻었다. 따라서 nextInt 함수는 이제 순수해졌다. (상태가 사라짐) 이 난수 생성기를 사용하면 다음과 같이 동일한 랜덤값을 갖는 튜플을 만들수도 있다. def randomPair(rng: RNG): (Int, Int) = { val (i1, _) = rng.nextInt val (i2, _) = rng.nextInt (i1, i2) } 더 발전하여 서로 다른 두 수와 이를 만들 때 사용한 난수 생성기를 반환하는 함수도 만들 수 있다. def randomPair(rng: RNG): ((Int, Int), RNG) = { val (i1, rng2) = rng.nextInt val (i2, rng3) = rng2.nextInt // i1과 i2가 다르게 하기 위해 rng2 난수 생성기를 사용 ((i1, i2), rng3) // 최종 상태가 담긴 rng3을 함께 반환한다. // 왜 이렇게 할까? 호출자는 이 rng3을 이용해서 다른 난수를 생성하게 하기 위해 } 상태가 있는 함수를 순수하게 하기class Foo { private var s: FooState = ... def bar: Bar def baz: Int } trait Foo { def bar: (Bar, Foo) def baz: (Int, Foo) } bar 과 baz 가 상태 s를 변이한다고 하자. 이 함수들을 순수 함수적으로 만들려면 앞의 난수 생성기와 같이 새로운 상태가 담긴 Foo 객체를 반환하는 패턴을 사용하면 된다. 이 패턴을 적용한다는 것은 계산된 다음 상태를 프로그램의 나머지 부분에 전달하는 책임을 호출자에게 넘기는 것과 같다. 앞의 난수 생성의 순수함수 패턴을 일반화가 필요한 시점이다. 잠깐 연습문제를 풀고 넘어가자. 연습문제 6.1// 0 이상, Int.MaxValue 이하의 난수 Int를 반환하는 함수 만들기 // Int.MinValue도 대응하기 (Math.abs(Int.MinValue) == -2147483648) def nonNegativeInt(rng: RNG): (Int, RNG) = { val (i, newRng) = rng.nextInt val result = if (i == Int.MinValue) i + 1 else i val t = result >> 31 ((result ^ t) + (t &amp; 1), newRng) } // 참고: 조건문 없는 절대값 함수 구하기 (http://alloc.tistory.com/137) 결과 scala> val (i, rng2) = nonNegativeInt(rng) i: Int = 16159453 rng2: RNG = SimpleRNG(1059025964525) scala> val (i2, rng3) = nonNegativeInt(rng2) i2: Int = 1281479697 rng3: RNG = SimpleRNG(197491923327988) scala> val (i3, rng4) = nonNegativeInt(rng3) i3: Int = 340305902 rng4: RNG = SimpleRNG(259172689157871) 연습문제 6.2// 0 이상, 1 미만의 Double 난수 구하기 def double(rng: RNG): (Double, RNG) = { val (i, r) = nonNegativeInt(rng) (i / (Int.MaxValue.toDouble + 1), r) } 결과 scala> val (d, rng1) = double(rng) d: Double = 0.007524831686168909 rng1: RNG = SimpleRNG(1059025964525) scala> val (d, rng2) = double(rng1) d: Double = 0.5967354853637516 rng2: RNG = SimpleRNG(197491923327988) scala> val (d, rng3) = double(rng2) d: Double = 0.15846728440374136 rng3: RNG = SimpleRNG(259172689157871) 연습문제 6.3 def intDouble(rng: RNG): ((Int, Double), RNG) = { val (i, rng2) = nonNegativeInt(rng) val (d, rng3) = double(rng2) ((i, d), rng3) } intDouble: (rng: RNG)((Int, Double), RNG) def doubleInt(rng: RNG): ((Double, Int), RNG) = { val (d, rng2) = double(rng) val (i, rng3) = nonNegativeInt(rng2) ((d, i), rng3) } doubleInt: (rng: RNG)((Double, Int), RNG) def double3(rng: RNG): ((Double, Double, Double), RNG) = { val (d1, rng2) = double(rng) val (d2, rng3) = double(rng2) val (d3, rng4) = double(rng3) ((d1, d2, d3), rng4) } double3: (rng: RNG)((Double, Double, Double), RNG) 결과 scala> intDouble(rng) res35: ((Int, Double), RNG) = ((16159453,0.5967354853637516),SimpleRNG(197491923327988)) scala> doubleInt(rng) res36: ((Double, Int), RNG) = ((0.007524831686168909,1281479697),SimpleRNG(197491923327988)) scala> double3(rng) res37: ((Double, Double, Double), RNG) = ((0.007524831686168909,0.5967354853637516,0.15846728440374136),SimpleRNG(259172689157871)) 연습문제 6.4 def ints(count: Int)(rng: RNG): (List[Int], RNG) = { def loop(c: Int, result: List[Int], pastRng: RNG): (List[Int], RNG) = if (c > 0) { val (i, newRng) = nonNegativeInt(pastRng) loop(c - 1, i :: result, newRng) } else { (result, pastRng) } loop(count, List[Int](), rng) } 결과 scala> ints(10)(rng) res41: (List[Int], RNG) = (List(1837487774, 94901159, 1163632441, 1015914512, 1934589059, 1770001318, 2015756020, 340305902, 1281479697, 16159453),SimpleRNG(120421598792892)) scala> ints(5)(rng) res42: (List[Int], RNG) = (List(1770001318, 2015756020, 340305902, 1281479697, 16159453),SimpleRNG(115998806404289)) scala> ints(20)(rng) res43: (List[Int], RNG) = (List(994512970, 1835563077, 1166376033, 384268462, 250029321, 1911657181, 1660936491, 1571634817, 141607732, 122709694, 1837487774, 94901159, 1163632441, 1015914512, 1934589059, 1770001318, 2015756020, 340305902, 1281479697, 16159453),SimpleRNG(65176402051806)) 난수 발생기 일반화하기앞의 구현 패턴들을 살펴보면 RNG =&gt; (A, RNG)의 형태를 따른다. RNG에 대해 새로운 상태를 담은 RNG로 변환한다고 해서 이런 함수를 상태 동작(state action) or 상태 전이(state transition)이라고 부른다. 위 함수에 대해 앨리어스를 만들자. type Rand[+A] = RNG => (A, RNG) // +A == A 일수도 있고 A의 상위일 수도 있다. 이를 사용하면 좀 더 간단하게 표시할 수 있다. def int: Rand[Int] = _.nextInt def unit[A](a: A): Rand[A] = rng => (a, rng) 자 이제 난수 생성기는 건들지 않고 난수 값을 변환하는 map 함수를 만들어보자. (잉? 갑자기 쌩뚱맞게…) def map[A, B](s: Rand[A])(f: A => B): Rand[B] = rng => { val (a, rng2) = s(rng) (f(a), rng2) } 위 map 함수를 사용하면 0 이상이면서 2로 나누어지는 Int를 발생하는 함수를 쉽게 만들 수 있다. def nonNegativeEven: Rand[Int] = map(nonNegativeInt)(i => i - i % 2) 연습문제 6.5// double 함수를 map 함수를 이용해서 다시 만들어라. // 0 이상, 1 미만의 Double 난수 구하기 def double(rng: RNG): Rand[Double] = map(nonNegativeInt)(_ / (Int.MaxValue.toDouble + 1)) 결과 scala> double(rng) res45: Rand[Double] = $$Lambda$1497/760675871@6882c069 연습문제 6.6// ra, rb라는 난수 결과와 이 결과들을 조합하는 함수 f를 조합한 함수를 만들어라 def map2[A,B,C](ra: Rand[A], rb: Rand[B])(f: A, B) => C): Rand[C] = { } 지금까지의 구현에서 보면 RNG 값을 명시적으로 언급하거나 전달하지 않았다. 특히 map, map2라는 변환 함수에서는 RNG를 명시적으로 다루지 않아도 되어서 개발자가 실수할 일이 줄어들었다. 그러나 map, map2로 커버할 수 없는 함수들도 있다. 바로 nonNegativeLessThan 이다. def nonNegativeLessThan(n: Int): Rand[Int] = map(nonNegativeInt){ _ % n } 이게 왜 문제일까? Int.MaxValue가 n으로 나누어떨어지지 않을 수도 있으므로 전체적으로 난수들이 치우치게 된다. Int.MaxValue == 2147483647 이므로 n으로 나누어 떨어지지 않는 수가 발생하므로 0이 나오지 않고 0 이상의 값들이 좀 더 자주 나오게 된다. 어떻게 해결해야 될까? n을 통해 나올 수 있는 최대 배수보다 더 큰 난수가 발생하면 난수를 다시 발생하게 한다. 왜? 난수가 균등하게 나오게 하기 위해 def nonNegativeLessThan(n: Int): Rand[Int] = map(nonNegativeInt) { i => val mod = i % n if (i + (n - 1) - mod >= 0) mod else nonNegativeLessThan(n)(???) // 난수(i)가 32비트 Int를 벗어나지 않는 n의 최대 배수보다 크면 난수를 다시 발생한다. } nonNegativeLessThan 함수는 애초에 커링이 안되는 함수인데 난수를 새로 만들려면 새로운 상태의 rng가 필요하다. 그런데 우리는 Rand[Int] 를 쓰기 때문에 rng를 명시적으로 넘길 수 없다. 어떻게 해결할까? 답은 map 함수를 쓰지 않고 명시적으로 (result, RNG) 을 반환하는 식으로 코딩한다. def nonNegativeLessThan(n: Int): Rand[Int] = { rng => val (i, rng2) = nonNegativeInt(rng) val mod = i % n if (i + (n - 1) - mod >= 0) (mod, rng2) else nonNegativeLessThan(n)(rng2) } 이걸 쓰면 맨 앞에 나왔던 주사위의 버그를 손쉽게 해결할 수 있다. (주사위 함수가 0 ~ 5 까지 밖에 안나왔던 이슈) def rollDie: Rand[Int] = map(nonNegativeLessThan(6))(_ + 1) nonNegativeLessThan 함수에서 쓸 map 함수와 같은 조합기가 필요한 시점이다. 우리는 이걸 flatMap이라 부른다. 연습문제6.8def flatMap[A, B](f: Rand[A])(g: A => Rand[B]): Rand[B] 연습문제6.9map과 map2를 flatMap을 이용해서 다시 구현하라. 순수 상태 함수 일반화하기def map[S,A,B](a: S => (A, S))(f: A => B): S => (B, S) 이제 임의이 상태를 처리할 수 있는 Rand보다 더 일반적인 형식을 고려해보자. type State[S, +A] = S => (A,S) case class State[S, +A](run: S => (A, S)) 이제 Rand는 그냥 State로도 표현할 수 있게 된다. type Rand[A] = State[RNG, A] 또 flatMap 함수를 명령식으로도 작성할 수 있다. val ns: Rand[List[Int]] = int.flatMap(x => int.flatMap(y => ints(x).map(xs => xs.map(_ % y) ) ) ) val ns: Rand[List[Int]] = for { x &lt;- int y &lt;- int xs &lt;- ints(x) } yield xs.map(_ % y)","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"http://icednut.github.io/tags/scala/"},{"name":"functional programming","slug":"functional-programming","permalink":"http://icednut.github.io/tags/functional-programming/"}]},{"title":"스칼라 스터디 Day04 - 엄격성과 나태성","slug":"20181218-scala-and-functional-programming-day04","date":"2018-12-17T14:20:52.000Z","updated":"2019-01-07T11:12:26.639Z","comments":true,"path":"2018/12/17/20181218-scala-and-functional-programming-day04/","link":"","permalink":"http://icednut.github.io/2018/12/17/20181218-scala-and-functional-programming-day04/","excerpt":"","text":"출처: 스칼라로 배우는 함수형 프로그래밍 5장 Chapter 05. 엄격성과 나태성이번 챕터에서 다룰 내용 List의 한계 Stream (Lazy List) 스트림 순회의 비엄격성과 나태성 List의 한계스칼라에서 다음 코드는 어떻게 수행될까? List(1,2,3,4).map(_ + 10).filter(_ % 2 == 0).map(_ * 3) 스칼라 List의 map과 filter 함수는 임시적인 목록을 만들어서 그 결과를 반환한다. 즉 List(1,2,3,4).map(_ + 10)을 수행하면 List(11,12,13,14)를 반환하고 List(11,12,13,14).filter(_ % 2 == 0)을 수행하면 List(12,14)를 반환한다. 위 코드의 추적 과정은 다음과 같다. List(1,2,3,4).map(_ + 10).filter(_ % 2 == 0).map(_ * 3) List(11,12,13,14).filter(_ % 2 == 0).map(_ * 3) List(12, 14).map(_ * 3) List(36, 42) 위 방법은 마치 포커 카드에서 홀수 카드를 모두 제거하고 모든 퀸 카드를 뒤집는 놀이가 있다면, 루프를 한 번만 돌게하여 홀수 카드를 제거한 다음 퀸 카드를 찾는 것이아니라, 루프 한 번에 홀수카드를 제거하고 루프를 또 한 번 돌아서 퀸 카드를 찾는 것과 같은 코드이다. 위 행동을 요약하자면 아래와 같다. 루프 1 변환 작업(map) 임시 결과 목록 1 루프 2 필터링 작업(filter) 임시 결과 목록 2 루프 3 변환 작업(map) 결과 목록 3 좀 더 나은 방법은 없을까? 아래와 같은 방법을 생각할 것이다. 그럼 임시 자료구조를 생성하는 방식보다는 한 번의 루프로 변환 작업을 합성하여 실행하는 것이 어떨까? 변환 작업을 하나의 패스로 융합(fusion)해서 루프를 한 번만 돌 때 변환 작업을 수행하는 방식을 택하여 임시 자료구조의 생성을 피하는 것이다. 쉽게 말하자면 다음과 같다. 루프 1 변환 작업(map) 필터링 작업(filter) 변환 작업(map) 결과 목록 1 루프 1이 한 번 돌 때 map, filter, map을 수행하는 것이다. 어떻게 이걸 할까? 스칼라에는 이걸 하기 위해 Stream이라는 목록 자료형이 있다. Stream (Lazy List)스트림에는 이런 일련의 변환 작업을 나태성(laziness)을 이용하여 하나의 패스로 융합하는 방법이 담겨 있다. 따라서 List보다 경제적이다. 위에서 List로 풀었던 문제를 Stream을 사용해보자. Stream(1,2,3,4).map(_ + 10).filter(_ % 2 == 0).toList Stream을 사용하여 map과 filter를 합성하여 리스트를 만들려면 Stream을 어떻게 만들어야 할까? 앞 장에서 본 List와 마찬가지로 빈 Stream인 Empty와 값이 들어있는 Stream인 Cons를 선언한다. 그리고 마찬가지로 Stream 컴패니언 오브젝트를 만든다. (관례) sealed trait Stream[+A] case object Empty extends Stream[Nothing] case class Cons[+A](h: () => A, t: () => Stream[A]) extends Stream[A] object Stream { // TODO } 앞의 리스트의 Cons에서는 head와 tail이 명시적인 평가된 파라미터 였다. sealed trait List[+A] case object Nil extends List[Nothing] case class Cons[+A](head: A, tail: List[A]) extends List[A] object List { def apply[A](as: A*): List[A] = if (as.isEmpty) Nil else Cons(as.head, apply(as.tail: _*)) } 왜 Stream에서는 head와 tail이 함수 타입일까? 추후 설명이 나오겠지만 Stream 컴패니언 오브젝트에서 apply 메소드를 구현할 때 h와 t를 필요할 때만 평가하여 값을 가져와야 하기 때문이다. (왜냐고? Stream은 나태성을 갖는 리스트, 즉 여러 개의 변환 작업을 나태성을 이용하여 한번의 변환 작업으로 합쳐서 수행하는 자료 나열이기 때문이다) 여기서 잠깐?! Thunk와 비엄격한 함수이와 같이 값이 필요할 때만 함수를 호출하여 가져오는 즉 평가되지 않은 채 전달될 인수 타입인 () =&gt; A와 같은 자료형은 성크(thunk)라고 부른다. 이 성크는 연산이 필요할 때만 강제로 평가(인수를 호출)하여 값을 가져올 수 있다. 다음은 성크의 예시이다. def if2[A](cond: Boolean, onTrue: () => A, onFalse: () => A): A = if (cond) onTrue() else onFalse() 위 if2 함수를 보면 cond의 조건 true일 때는 onTrue를 강제로 평가(onTrue 인수를 호출)하고 cond의 조건이 false일 때는 onFalse를 강제로 평가한다.즉 cond의 조건을 if로 체크하기 전까지는 onTrue나 onFalse가 호출되지 않는다. onTrue나 onFalse와 같이 조건에 따라 평가가 될 수도 있고 안될 수도 있기 때문에 if2와 같은 함수를 비엄격한 함수다 라고 부른다. 스칼라에서는 성크를 다음과 같이 ()를 생략해서 표현할 수도 있다. def if2[A](cond: Boolean, onTrue: => A, onFalse: => A): A = if (cond) onTrue else onFalse 스칼라에서는 인자에 값을 넘기듯이 if2를 호출하면 표현식을 알아서 감싸준다. if2(false, sys.error(\"fail\"), 3) 스칼라 말고도 다른 언어에서도 비엄격성을 표현할 수 있다. 바로 부울 함수 &amp;&amp;와 ||의 단축 평가는 엄격하지 않다. false &amp;&amp; { println(\"!!\"); true } // print문이 실행되질 않는다. // &amp;&amp;의 특성상 앞의 조건이 false가 되면 &amp;&amp; 뒤의 조건이 평가되지 않기 때문이다. true || { println(\"!!\"); true } // ||도 마찬가지로 앞의 조건이 true이면 || 뒤의 조건이 평가되지 않기 때문에 print 문이 실행되질 않는다. 이와 같이 &amp;&amp;와 ||는 비엄격성을 띄고 있다. 따라서 List.apply 메소드를 참조하여 Stream.apply 메소드를 만들면 다음과 같다. object Stream { def apply[A](as: A*): Stream[A] = if (as.isEmpty) Empty else Cons(as.head, apply(as.tail: _*)) // * 컴파일 오류 * } List.apply와 거의 동일한 모습이지만, Stream의 Cons를 위와 같이 사용하면 안된다. 왜냐면 Cons의 생성자 인수는 성크이지만, call by name으로 인수의 평가 값을 가져올 수 없기 때문이다. 따라서 인수에 값을 함수로 감싸는 것이 자동으로 되질 않는다. scala> case class Cons[+A](h: () => A, t: () => Stream[A]) extends Stream[A] defined class Cons scala> case class Cons[+A](h: => A, t: => Stream[A]) extends Stream[A] &lt;console>:1: error: `val' parameters may not be call-by-name case class Cons[+A](h: => A, t: => Stream[A]) extends Stream[A] ^ &lt;console>:1: error: `val' parameters may not be call-by-name case class Cons[+A](h: => A, t: => Stream[A]) extends Stream[A] ^ scala> object Stream { | def apply[A](as: A*): Stream[A] = | if (as.isEmpty) Empty | else Cons(as.head, apply(as.tail: _*)) | } &lt;console>:18: error: type mismatch; found : A required: () => A else Cons(as.head, apply(as.tail: _*)) ^ &lt;console>:18: error: type mismatch; found : Stream[A] required: () => Stream[A] else Cons(as.head, apply(as.tail: _*)) ^ 이에 대한 해결 방법은 Cons와 Empty의 성크를 갖는 스마트 생성자를 Stream 컴패니언 오브젝트에 추가하면 된다. object Stream { def cons[A](hd: => A, tl: Stream[A]): Stream[A] = Cons(() => hd, () => tl) def empty[A]: Stream[A] = Empty def apply[A](as: A*): Stream[A] = if (as.isEmpty) empty else cons(as.head, apply(as.tail: _*)) } 그러나 여기에도 문제가 있다. Cons에 숨어 있는 재계산일단 Cons는 인자로 받은 성크를 계속 실행시키기 때문에 인자로 넘긴 함수가 퍼포먼스를 많이 잡아먹는 함수라면 그 함수가 두 번 호출되는 이슈가 생긴다. object Stream { ... def headOption: Option[A] = this match { case Empty => None case Cons(h, t) => Some(h()) } } val x = Cons(() => expensive(x), tl) val h1 = x.headOption val h2 = x.headOption 이건 뭘 의미할까? 위에 cons 스마트 생성자에서 hd와 tl 성크를 Cons로 넘겼는데 Cons의 head와 tail이 참조될 때마다 hd, tl성크가 평가된다는 의미이다. 이는 굉장히 비효율적이다. (hd, tl 성크의 값을 한 번만 평가하고 캐싱하는게 좋지 않을까?) 이렇게 성크의 값을 캐싱하기 위해서는 lazy val을 이용한다. 이를 이용한 cons 메소드는 다음과 같다. sealed trait Stream[+A] case object Empty extends Stream[Nothing] case class Cons[+A](h: () => A, t: () => Stream[A]) extends Stream[A] object Stream { def cons[A](hd: => A, tl: Stream[A]): Stream[A] = { lazy val head = hd lazy val tail = tl Cons(() => head, () => tail) } def empty[A]: Stream[A] = Empty def apply[A](as: A*): Stream[A] = if (as.isEmpty) empty else cons(as.head, apply(as.tail: _*)) } 다시 본론으로 돌아와서 아래 코드를 수행해보자. Stream(1,2,3,4).map(_ + 10).filter(_ % 2 == 0).toList 일단 먼저 Stream(1,2,3,4)는 Stream.apply 메소드에 의해 cons 메소드를 통해 다음과 같이 변환된다. cons(1, Stream(2,3,4)).map(_ + 10).filter(_ % 2 == 0).toList (1 :: Stream(2,3,4)).map(_ + 10).filter(_ % 2 == 0).toList (11 :: Stream(2,3,4).map(_ + 10)).filter(_ % 2 == 0).toList cons(11, Stream(2,3,4).map(_ + 10)).filter(_ % 2 == 0).toList 그 다음 cons의 head와 tail에 filter를 적용하게 된다. cons(11, Stream(2,3,4).map(_ + 10)).filter(_ % 2 == 0).toList (11 :: Stream(2,3,4).map(_ + 10)).filter(_ % 2 == 0)).toList Stream(2,3,4).map(_ + 10).filter(_ % 2 == 0).toList 마찬가지로 Stream(2,3,4)에 대해서도 cons와 map과 filter를 차례로 수행한다. cons(12, Stream(3,4).map(_ + 10)).filter(_ % 2 == 0).toList() (12 :: Stream(3,4).map(_ + 10)).filter(_ % 2 == 0).toList() 12 :: Stream(3,4).map(_ + 10).filter(_ % 2 == 0).toList() 12 :: cons(3, Stream(4)).map(_ + 10).filter(_ % 2 == 0).toList() 12 :: cons(13, Stream(4).map(_ + 10)).filter(_ % 2 == 0).toList() 12 :: Stream(4).map(_ + 10).filter(_ % 2 == 0).toList() 12 :: Stream(14).filter(_ % 2 == 0).toList() 12 :: 24 :: Stream().map(_ + 10).filter(_ % 2 == 0).toList() 12 :: 24 :: List() 이제 그럼 toList() 과 takeWhile()를 구현해보자. 연습문제 5.1 ~ 3trait Stream[+A] { def toList: List[A] = ??? def drop(n): Stream[A] = ??? def takeWhile(p: A => Boolean): Stream[A] = ??? } 연습문제 5.4 ~ 7trait Stream[+A] { def forAll(p: A => Boolean): Boolean = ??? // TODO: 아래 메소드들은 foldRight를 이용할 것 def takeWhile2(p: A => Boolean): Stream[A] = ??? def headOption = ??? def map = ??? def filter = ??? def append = ??? // 인자에 대해 비엄격해야 한다. def flatMap = ??? }","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"http://icednut.github.io/tags/scala/"},{"name":"functional programming","slug":"functional-programming","permalink":"http://icednut.github.io/tags/functional-programming/"}]},{"title":"스칼라 스터디 Day03 - 예외를 이용하지 않은 오류 처리","slug":"20181210-scala-and-functional-programming-day03","date":"2018-12-10T14:47:36.000Z","updated":"2019-01-07T11:12:26.638Z","comments":true,"path":"2018/12/10/20181210-scala-and-functional-programming-day03/","link":"","permalink":"http://icednut.github.io/2018/12/10/20181210-scala-and-functional-programming-day03/","excerpt":"","text":"출처: 스칼라로 배우는 함수형 프로그래밍 4장 Chapter 04. 예외를 이용하지 않은 오류 처리이번 챕터에서 다룰 내용 예외를 던지는 기존의 방식 살펴보기 예외를 던지는게 왜 어때서? 예외를 안던지고 반환하면 뭐가 좋을까? 예외를 던지지 않고 예외 처리를 미루는 방법 Option 예외를 미루지 말고 예외를 반환하기 Either 예외를 던지는 기존 방식1장에서 예외(exception)을 던지는 것이 하나의 부수 효과라고 말했다. (함수형 프로그래밍에서는 부수 효과가 쥐약인데…) 여기서 잠깐?!Q: 그럼 예외를 던지지 않는다면 어떻게 처리할까? A: 예외를 값으로 돌려주기를 하면 부수효과 없는 함수를 만들 수 있게 된다. Q: 예외를 값으로 돌려주면 뭐가 좋을까? A: 참조 투명성을 유지할 수 있게 된다. (참조 투명성을 유지하는 것이 왜 중요한지는 생략) 오류(유효하지 않은 출력)에 대한 처리를 컴파일 타임에 명시할 수 있게 된다. 예외를 명시적으로 처리하게 하거나 예외를 값으로 반환하기 위해서는 Option과 Either를 사용해야 한다. 이번 장에서는 Option과 Either를 직접 만들어보면서 이해와 사용 방법을 익혀보자. 예외가 왜 참조 투명성을 해칠까?def failingFn1(i: Int): Int = { val y: Int = throw new Exception(\"fail!\") try { val x = 42 + 5 x + y } catch { case e: Exception => 43 } } def failingFn2(i: Int): Int = { try { val x = 42 + 5 x + ((throw new Exception(\"fail!\")): Int) } catch { case e: Exception => 43 } } 위 함수들을 실행하면 failingFn1을 실행하면 예외가 발생하고 failingFn2를 실행하면 43이 반환된다. 이 결과가 시사하는 바가 뭘까? 참조에 투명한 문맥이라면 y를 값으로 치환해도 항상 동일한 결과를 반환해야 한다. 하지만 위 예외 발생코드는 문맥의 위치에 따라서 결과값이 달라지는 현상이 발생하고 있다.(try 안에 있느냐 밖에 있느냐..) 즉 문맥(Context)에 의존적이라는 의미다. 따라서 예외의 문제점은 다음과 같다. 예외는 참조 투명성을 위반하고 문맥 의존성을 갖게 만든다. 예외가 있는 함수는 리턴에 대해 예측 불가능하다. failingFn 함수형식인 Int =&gt; Int 만 보고도 예외가 발생할지 알 수 있는가? 그럼 참조 투명성 있는 예외를 다루는 함수를 만들려면?이거 한 가지만 기억하자. 예외를 던지지 말고, 예외적인 조건이 발생했음을 뜻하는 값을 돌려주자. 그렇게 하면 예외적인 조건에 대한 처리를 받는 쪽에서 처리해야만 컴파일 통과하게 된다. 참조 투명성도 지키고 예외 처리를 빼먹는 실수도 미연에 방지할 수 있게 된다. 여기서 잠깐?!Q: Java의 Checked Exception은 예외를 던지면서 동시에 예외 처리를 컴파일 타임에 강제하지 않는가? 이거랑 뭐가 다른건지? A: Checked Exception은 고차함수에는 통하지 않는 단점이 있다. 예를 들어 List.map과 같은 고차함수에는 익명 함수에서 Checked Exception이 발생한다면 그 모든 Checked Exception 마다 List.map에 처리를 추가할 것인가? (그야말로 이건 미친짓이다..) 그럼 또 다른 예외를 반환하는 부수효과가 있는 함수를 살펴보고 부수효과를 없애보는 과정을 살펴보자. def mean(xs: Seq[Double]): Double = if (xs.isEmpty) throw new ArithmeticException(\"mean of empty list!\") else xs.sum / xs.length 위 mean 함수는 xs 파라미터에 따라 예외를 발생할 수도 있고 계산된 결과 값을 반환할 수도 있다. 즉 일부 입력에 대해서는 값을 반환하지 않는 부분함수(partial function)이다. 해결1: 예외 대신 null을 반환한다.null을 반환하면 또 다른 문제만 만들뿐이다. null 처리를 빼먹을 수 있는 실수를 발생하게 만든다. (게다가 이건 컴파일 타임에 잡히지도 않는다.) 혹은 null을 검사하는 로직을 넣어야 한다. (if문으로 null을 체크하는 판에 박힌 코드가 생긴다.) 지금은 반환 가능한 Double이지만 커링에서는 어떻게 할 것인가? 이때는 null로도 반환할 수 없다. def max[A](xs: Seq[A])(greater: (A, A) =&gt; Boolean): A 위와 같은 함수 형식에서 xs.isEmpty일 때 null을 반환한다고? null 반환 못한다고!! 해결2: 예외적인 상황에 처했을 때 반환할 값을 인자로 전달한다.def mean_1(xs: IndexedSeq[Double], onEmpty: Double): Double = if (xs.isEmpty) onEmpty else xs.sum / xs.length 이렇게 되면 모든 입력 값에 대해 모든 반환 값을 받으므로 완전 함수(total function)이 되지만, 여기에도 문제가 있다. onEmpty를 넘기지 않고도 mean_1 호출하는 것 자체를 취소하고 싶으면 어떻게 할까? (또 if라는 틀에 박힌 코드가 생기겠지..) 아니면 예외적인 상황에서 완전히 다른 분기로 넘기려면? (역시 중복코드와 실수를 유발할 수 있음) 결국 해결1, 2는 진정한 해결이 아니라는 의미다. 해결3: 예외 처리를 호출하는 곳으로 미루자.바로 다음과 같이 말이다. def mean(xs: Seq[Double]): Option[Double] = if (xs.isEmpty) None else Some(xs.sum / xs.length) 이렇게 되면 mean을 호출하면 항상 Option을 받기 때문에 완전 함수(total function)이 된다. (야호!) 또한 유효하지 않은 값(None)에 대한 처리를 호출하는 곳에서 명시를 해야하기 때문에 컴파일 타임에서 오류를 미연에 방지하는 코드를 작성하게 된다. 예외를 던지지 않고 예외 처리를 미루는 방법 Option그럼 Option의 정의를 살펴보고 직접 구현해보자. 연습문제 4.1 여기서 잠깐?! default: =&gt; B는 타입은 B이지만 default가 실제로 쓰이기 전까지는 평가(실행 혹은 참조)하지 않는다. B &gt;: A는 B가 A와 같거나 A의 상위 형식(Supertype)이어야 함을 뜻한다. Option을 쓰게 되면 값이 없다거나라는 점검 코드를 작성하지 않고도 그냥 코드를 작성하면 된다. case class Employee(name: String, department: String) def lookupByName(name: String): Option[Employee] = ??? def joeDepartment: Option[String] = lookupByName(\"Joe\").map(_.department) // lookupByName(\"Joe\")의 결과가 없으면 None을 반환하기 때문에 .map 호출이 유효하다. 위 코드를 보면 None일 때 점검하는 코드를 작성했는가? 전혀 아니다. 또 예외처리에 대해 호출자에서 일관된 처리를 하게 만들 수 있고 문맥에 의존적인 오류로직 따위는 저멀리 사라지게 된다. 그렇다면 Option을 사용하지 않는 기존의 함수들에 대해서 Option을 적용하고 싶다면 어떻게 할까? def insuranceRateQuote(age: Int, numberOfSpeedingTickets: Int): Double 예를 들어 위 함수를 호출하는 함수를 만든다고 해보자. 이 때 인자에 문자열에서 숫자로 파싱하여 전달한다고 할 때 제대로 파싱되면 호출하고 아니라면 호출하지 않게 하려면 어떻게 할까? def parseInsuranceRateQuote(age: String, numberOfSpeedingTickets: String): Option[Double] = { val optAge: Option[Int] = Try(age.toInt) val optNumberOfSpeedingTickets: Option[Int] = Try(numberOfSpeedingTickets.toInt) insuranceRateQuote(optAge, optNumberOfSpeeedingTickets) } def Try[A](a: => A): Option[A] = try Some(a) catch { case e: Exception => None } 여기서 age.toInt와 numberOfSpeedingTickets.toInt는 충분히 예외가 발생할 수 있는 로직이다. 그러나 Try라는 함수 덕분에 Option으로 감쌀 수 있다. 그러나 문제는 insuranceRateQuote 함수의 인자는 Option을 받을 수 없고 Int만 받을 수 있다. 이걸 어떻게 해결할까? insuranceRateQuote 함수의 인자를 고쳐야 하는 것일까? 답은 커링을 써서 값이 있으면 insuranceRateQuote 함수를 호출하고 아니라면 None을 반환하는 고차함수(map2)를 작성한다. 그 고차함수 호출은 다음과 같은 형태가 된다. def parseInsuranceRateQuote(age: String, numberOfSpeedingTickets: String): Option[Double] = { val optAge: Option[Int] = Try { age.toInt } val optTickets: Option[Int] = Try { numberOfSpeedingTickets.toInt } map2(optAge, optTickets)(insuranceRateQuote) } 그럼 map2를 구현해보자. 연습문제 4.3 그럼 map2 함수에서 좀 더 발전하여 인수 2개 뿐만 아니라 목록으로 받는 고차함수를 작성해보자. 연습문제 4.4 parseInts 함수를 보면 문제점이 하나 있다. a map (i =&gt; MyTry(i.toInt)) 때문에 리스트를 한 번 훑어서 Option[Int]로 변환한 뒤 sequence()의 함수 내부에서 한 번 또 훑는 작업(for-comprehension)을 타서 총 2번의 루프를 타게 된다. 이걸 해결하기 위해 traverse라는 고차함수를 만들어보자. def traverse[A, B](a: List[A])(f: A => Option[B]): Option[List[B]] 연습문제 4.5 예외를 미루지 말고 예외를 반환하기 EitherOption은 무엇이 잘못 되었는지는 생략되고 그냥 None이 반환될 뿐이다. 그러나 아래와 같이 하고 싶을 때도 있을 것이다. 예외적인 상황에 마주했을 때 예외적인 상황에 대한 자세한 정보를 담은 String을 받고 싶다. 예외가 발생한 경우 실제 그 예외를 알고 싶다. (Option일 경우는 무슨 예외인지 알 수 없고 그냥 None이기 때문) 위 문제를 해결하기 위해 실패의 원인을 담고 있는 Either라는 자료 형식을 만들어보자. sealed trait Either[+E, +A] case class Left[+E](value: E) extends Either[E, Nothing] case class Right[+A](value: A) extends Either[Nothing, A] Either와 같은 자료 형식을 서로 소 합집합 즉 분리합집합이라고 한다. (왜? 값과 예외라는 서로 공통점이 없는 값들을 하나의 합집합으로 묶은 자료형이기 때문) Either의 사용방법은 다음과 같다. def mean(xs: IndexedSeq[Double]): Either[String, Double] = if (xs.isEmpty) Left(\"mean of empty list!\") else Right(xs.sum / xs.length) def Try[A](a: => A): Either[Exception, A] = try Right(a) catch { case e: Exception => Left(e) } 연습문제 4.6 Either의 사용 예시를 살펴보자. def parseInsuranceRateQuote(age: String, numberOfSpeedingTickets: String): Either[Exception, Double] = for { a &lt;- Try { age.toInt } tickets &lt;- Try { numberOfSpeedingTickets.toInt } } yield insuranceRateQuote(a, tickets) case class Person(name: Name, age: Age) sealed class Name(val value: String) sealed class Age(val value: Int) def mkName(name: String): Either[String, Name] = if (name == \"\" || name == null) Left(\"Name is empty.\") else Right(new Name(name)) def mkAge(age: Int): Either[String, Age] = if (age &lt; 0) Left(\"Age is out of range.\") else Right(new Age(age)) def mkPerson(name: String, age: Int): Either[String, Person] = mkName(name).map2(mkAge(age))(Person(_, _))","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"http://icednut.github.io/tags/scala/"},{"name":"functional programming","slug":"functional-programming","permalink":"http://icednut.github.io/tags/functional-programming/"}]},{"title":"스칼라 스터디 Day02 - 함수적 자료구조","slug":"20181204-scala-and-functional-programming-day02","date":"2018-12-04T12:31:10.000Z","updated":"2019-01-07T11:12:26.637Z","comments":true,"path":"2018/12/04/20181204-scala-and-functional-programming-day02/","link":"","permalink":"http://icednut.github.io/2018/12/04/20181204-scala-and-functional-programming-day02/","excerpt":"","text":"출처: 스칼라로 배우는 함수형 프로그래밍 3장 Chapter 03. 함수적 자료구조이번 챕터에서 다룰 내용 함수형 프로그래밍 스타일 작성된 Single Linked List 살펴보기 (함수적 자료구조) Pattern Matching 함수형 자료구조에서의 Data Sharing 고차함수와 타입추론, 그리고 고차함수 일반화 함수형 프로그래밍 스타일로 Binary Tree 구현하기 함수적 자료구조먼저 함수적 자료구조의 정의부터 살펴보자. 함수적 자료구조란 무엇일까? 순수한 함수만으로 조작되는 자료구조 함수적 자료구조는 조작이 일어나도 그 원본은 영원히 불변이다. 예를 들어 List()와 같은 빈 리스트는 정수 값 3이나 4처럼 영원히 불변이(Immutable) 값이다. 3 + 4를 수행하면 새로운 정수 값 7이 나오는 것처럼 두 리스트를 합쳐도 입력으로 받은 두 리스트는 변경되지 않는다. 스칼라에서는 List가 불변이라니 어떻게 그럴수가 있을까? 여기 스칼라로 작성된 불변 싱글 링크드 리스트 구현을 살펴보자. sealed trait List[+A] case object Nil extends List[Nothing] case class Cons[+A](head: A, tail: List[A]) extends List[A] object List { def apply[A](as: A*): List[A] = if (as.isEmpty) Nil else Cons(as.head, apply(as.tail: _*)) } 위 코드를 사용하여 List를 생성해보자. (여기서는 List 동반객체companion object를 사용하면 된다.) xs와 ys 자료 구조 형태 Cons(&quot;a&quot;, tail) ㄴㅡㅡ Cons(&quot;b&quot;, tail) ㄴㅡㅡ Nil 여기서 List 트레이트와 Cons 케이스 클래스의 타입 파라미터에 왜 +A라고 붙였을까? 이유는 다음과 같다. Cons의 구성 요소로는 타입 A가 될 수도 있고 A의 하위 형식이 올 수도 있기 때문 (여기서 A의 하위 형식은 Nothing이 되고 Nothing은 모든 타입의 서브타입이다.) 여기서는 +A 는 공변(Covariant)를 뜻한다. 만약 리스트의 타입 파라미터가 공변이 아니라면 어떻게 될까? 그럼 Cons와 같이 리스트에 데이터를 추가하는 행위를 할 수 없게 된다. (이유: List[Nothing] 타입인 Nil을 다룰 수 없기 때문) 공변(Covariant)과 불변(Invariant)예를 들어, 만일 Dog가 Animal의 서브타입이면 List[Dog]가 List[Animal]의 하위 형식으로 간주되도록 하고 싶을 경우 trait List[+A]라고 타입 파라미터에 +를 붙여주면 공변 타입 파라미터가 된다. 반면, 만약 A 앞에 +가 없다면 List[Dog]와 List[Animal]은 하위 형식 관계가 아닌 서로 다른 타입이 된다. 여기서 타입 파라미터를 불변(invariant)이라고 표현한다. Pattern Matching먼저 패턴 매칭을 쓴 메소드를 먼저 살펴보자. def sum(ints: List[Int]): Int = ints match { case Nil => 0 case Cons(x, xs) => x + sum(xs) } def product(ds: List[Double]): Double = ds match { case Nil => 1.0 case Cons(0.0, _) => 0.0 case Cons(x, xs) => x * product(xs) } sum 메소드부터 살펴보면, 파라미터로 받은 ints가 빈 배열일 경우(case Nil) 0을 반환하고, 첫 번째 요소가 있고 꼬리로 다음 리스트가 있을 경우(case Cons(x, xs)) 재귀적으로 요소를 더하는 과정을 거친다. 이렇게 패턴 매칭은 자료구조의 내용이 매칭되는지를 판단할 때 쓰인다. 또한 책에 따르면 재귀호출과 결합하여 쓰는 경우도 많다고 한다. 다음 패턴 매칭은 어떤 값을 반환할까? List(1,2,3) match { case _ =&gt; 42 } List(1,2,3) match { case Cons(h, _) =&gt; h } List(1,2,3) match { case Cons(_, t) =&gt; t } List(1,2,3) match { case Nil =&gt; 42 } 는 읽는 사람의 상상에.. 참고로 스칼라 표준 라이브러리의 List를 써서 패턴 매칭을 할 경우 case Cons(h, t)로 쓰기보다는 case h :: t라고 쓴다. 즉 더 많은 요소를 추출하기 위해 괄호를 중첩할 필요 없이 case h :: h2 :: t 같이 간편하게 쓸 수 있다. 함수적 자료구조에서의 Data Sharing앞에서 작성한 List가 불변이라면 해당 리스트에 요소를 추가하거나 요소를 제거하는 함수는 어떻게 작성할까? 답은 요소를 추가한 리스트를 반환하거나 요소를 제거한 리스트를 반환하는 함수를 만들면 된다. 연습문제3.2)List의 첫 요소를 제거하는 함수 tail 구현하기 연습문제3.3)List의 첫 요소를 다른 값으로 대체하는 함수 setHead 구현하기 Data Sharing을 사용하면 리스트의 끝에 다른 리스트를 붙이는 것을 할 수 있다. def append[A](a1: String[A], a2: List[A]): List[A] = a1 match { case Nil => a2 case Cons(h, t) => Cons(h, append(t, a2)) } 고차함수와 타입추론, 그리고 고차함수 일반화아래와 같이 고차함수가 있을 경우 이 고차함수를 호출할 때 넘기는 익명함수에는 익명함수의 파라미터를 명시해야 한다고 한다. def dropWhile[A](l: List[A], f: A => Boolean): List[A] = ??? val xs: List[Int] = List(1,2,3,4,5) val ex1 = dropWhile(xs, (x: Int) => x &lt; 4) 그러나 아래와 같이 커링을 사용하면 익명함수의 파라미터 타입이 고정되어 버린다. def dropWhile[A](as: List[A])(f: A => Boolean): List[A] = as match { case Cons(h, t) if f(h) => dropWhile(t)(f) case _ => as } val xs: List[Int] = List(1,2,3,4,5) val ex1 = dropWhile(xs)(x => x &lt; 4) 위와 같은 경우 커링되는 결과의 파라미터가 A로 고정되기 때문에 Int가 된다. 인수들을 이런 식으로 묶는 것은 스칼라의 타입 추론을 돕기 위한 행위라고 볼 수 있다. 위에서 본 sum과 product 코드를 보면 핵심 연산만 다를 뿐 패턴 매칭하는 과정이 비슷하다. def sum(ints: List[Int]): Int = ints match { case Nil => 0 case Cons(x, xs) => x + sum(xs) } def product(ds: List[Double]): Double = ds match { case Nil => 1.0 case Cons(x, xs) => x * product(xs) } 이 경우 부분 표현식들을 추출해서 커링의 인수로 대체하는 것으로 일반화하는 것이 가능하다. def foldRight[A, B](as: List[A], z: B)(f: (A, B) => B): B = as match { case Nil => z case Cons(x, xs) => f(x, foldRight(xs, z)(f)) } def sum(ns: List[Int]) = foldRight(ns, 0)(_ + _) def product(ns: List[Double]) = foldRight(ns, 1.0)(_ * _) 위 sum 메소드를 사용하면 다음과 같이 치환된다. foldRight(Cons(1, Cons(2, Cons(3, Nil))), 0)(_ + _) 1 + foldRight(Cons(2, Cons(3, Nil)), 0)(_ + _) 1 + (2 + foldRight(Cons(3, Nil), 0)(_ + _)) 1 + (2 + (3 + foldRight(Cons(Nil), 0)(_ + _))) 1 + (2 + (3 + (0))) 6 함수형 프로그래밍 스타일로 Binary Tree 구현하기sealed trait Tree[+A] case class Leaf[A](value: A) extends Tree[A] case class Branch[A](left: Tree[A], right: Tree[A]) extends Tree[A] 나중에 size, maximum, depth, map 함수를 작성해보자. 그리고 이 4개의 함수를 일반화한 fold도 작성해보자.","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"http://icednut.github.io/tags/scala/"},{"name":"functional programming","slug":"functional-programming","permalink":"http://icednut.github.io/tags/functional-programming/"}]},{"title":"스칼라 스터디 Day01 - 함수형 프로그래밍이란?","slug":"20181125-scala-and-functional-programming-day01","date":"2018-11-24T17:20:10.000Z","updated":"2019-01-07T11:12:26.636Z","comments":true,"path":"2018/11/25/20181125-scala-and-functional-programming-day01/","link":"","permalink":"http://icednut.github.io/2018/11/25/20181125-scala-and-functional-programming-day01/","excerpt":"","text":"출처: 스칼라로 배우는 함수형 프로그래밍 1장, 2장 CHAPTER 01. 함수형 프로그래밍이란 무엇인가?함수형 프로그래밍이란 부수 효과(Side Effect)가 없는 순수 함수(Pure Function)으로만 프로그램을 구축한다는 것을 의미한다. 그럼 부수효과란 무엇일까? 결과를 돌려주는 것 이외에 어떤 일을 수행하는 함수를 카리켜 부수효과가 있는 함수 라고 칭한다. 부수효과가 있는 함수 예시 파라미터 변수를 수정한다. 자료구조를 제자리에서 수정한다. 객체의 필드를 설정한다. 에외(exception)을 던지거나 오류를 내면서 실행을 중단한다. 콘솔에 출력하거나 사용자의 입력을 읽어들인다. 파일에 기록하거나 파일에서 읽어들인다. 화면에 그린다. 이 책은 모든 종류의 프로그램을 부수 효과 없이 표현하는 방법을 설명한다. 부수 효과 없는 함수들로만 프로그램을 개발하면 뭐가 좋을까? 순수 함수들로만 프로그램을 작성하면 모듈성(modularity)이 증가하게 됨 모듈성 덕분에 test, 재사용, 병렬화, 일반화, 분석이 쉬워 진다. 순수 함수는 버그가 생길 여지가 훨씬 적다 (부수 효과가 없기 때문) 그럼 부수 효과가 있는 간단한 함수 예시를 바탕으로 부수 효과를 제거해가면서 FP의 이점을 살펴보자. Step1. 부수 효과가 있는 프로그램커피숍에서 사용하는 커피구매 프로그램을 구현해보자. class Cafe { def buyCoffee(cc: CreditCard): Coffee = { val cup = new Coffee() cc.charge(cup.price) cup } } buyCoffee 메소드는 부수 효과가 있는 메소드다. 왜? 여기서 buyCoffee 메소드의 목적은 단지 하나. Coffee 객체를 돌려주는 것이다. Coffee를 돌려주는 것 말고 그 외의 모든 동작은 부수 효과이다. 정확히 말하자면cc.charge(cup.price)가 부수 효과이다. 왜? 여기서 청구(charge)는 외부 세계와의 일정한 상호 작용이기 때문이다. 부수 효과가 있으면 왜 안좋을까? 테스트 코드를 작성하기 어려워 진다. buyCoffee() 메소드의 테스트 코드를 작성하기 위해 실제로 신용카드 회사와 연결해서 카드 이용 대금을 청구하고 싶지는 않을 것이다. 그러므로 신용카드 연동 방법에 관한 지식을 CreditCard에 집어넣는 것은 좋지 않다. 그럼 어떻게 고칠까? Step2. 커피 결제를 Payments로 분리하기커피 대금 지급을 위한 Payments 객체를 buyCoffee에 전달하면 코드의 모듈성(Modularity)과 검사성(Testability)을 좀 더 높일 수 있다. class Cafe { def buyCoffee(cc: CreditCard, p: Payments): Coffee = { val cup = new Coffee() p.charge(cc, cup.price) cup } } p: Payments 파라미터 부분에 Mock 객체를 전달하여 결제에 대한 행동을 목킹할 수 있게 되었다. (검사성이 조금 높아짐) 그러나 이상적인 방법은 아니다. 왜? Payments를 인터페이스로 만들어야 한다. (Mock 구현을 넘겨주기 위해) Payment를 목킹한다고 해도 charge 메소드 동작에 대한 상태 변이가 잘 되었는지 확인하는 코드가 필요 Mock Framework를 써서 처리할 수 있지만 프레임워크를 사용하지 않고 해결할 수 있는 방법이 있다. buyCoffee 메소드는 재사용이 어렵다. 만약 손님이 커피 열두 잔을 주문한다고 하자. buyCoffee 메소드를 루프를 돌아서 12번 호출하면 문제가 발생한다. 신용카드를 12번 청구되기 때문에 수수료도 12번 지불된다. (수수료에 대해 중복 결제 발생) Step3. 부수 효과가 제거된 buyCoffee위 문제를 해결하기 위해 buyCoffee를 새로 만들어야 한다. 함수적 해법은 부수 효과(creditCard.charge 혹은 payment.charge)를 제거하고 buyCoffee가 Coffee 뿐만 아니라 청구건을 하나의 값으로 돌려주는 것이다. class Cafe { def buyCoffee(cc: CreditCard): (Coffee, Charge) = { val cup = new Coffee() (cup, Charge(cc, cup.price)) } } 무슨 차이일까? 청구건의 생성 문제(creditCard.charge 혹은 payment.charge)가 청구건의 처리 또는 연동 문제와 분리 되었다. (charge 메소드를 직접 호출하지 않아도 되기 때문에 연동을 신경쓰지 않아도 됨) Charge에 결제 정보를 담아서 반환하기 때문에 여러 잔의 커피 구매에도 결제 정보 변경이 쉬워졌다. 어떻게 그럴까? case class Charge(cc: CreditCard, amount: Double) { def combine(other: Charge): Charge = if (cc == other.cc) Charge(cc, amount + other.amount) else throw new Exception(\"다른 종류의 카드끼리는 결제 정보를 결합할 수 없습니다.\") } 커피를 n잔 구매는 어떻게 할까? class Cafe { def buyCoffee(cc: CreditCard): (Coffee, Charge) = { /* 이전과 같음 */ } def buyCoffees(cc: CreditCard, n: Int): (List[Coffee], Charge) = { val purchases: List[(Coffee, Charge)] = List.fill(n)(buyCoffee(cc)) // List.fill(n)(x)는 x의 복사본 n개로 이루어진 List를 생성한다. val (coffees, charges) = purchases.unzip (coffees, charges.reduce((c1, c2) => c1.combine(c2))) } } 뭐가 좋아진걸까? buyCoffee를 직접 재사용해서 여러번 구매가 가능해졌다. (buyCoffees 메소드) 두 메소드 모두 Payments 인터페이스를 추출해서 Mock 구현을 하지 않아도 되었다. Cafe는 Charge의 대금이 어떻게 처리되는지 알 수 없게 되었기 때문에, 결제 연동을 신경쓸 필요가 없다. 순수 함수란 구체적으로 무엇인가?A => B 위 표현식이 순수 함수라는 가정을 한다면, 타입이 A인 모든 값 a를 각각 타입이 B인 하나의 값 b에 연관시키되, b가 오직 a에 의해서만 결정되어야 한다. 내부 또는 외부 공정의 상태 변경은 f(a)의 결과를 계산하는 데 어떠한 영향도 주지 않는다. 예를 들어 Int =&gt; String함수는 모든 정수를 그에 대응되는 문자열로 반환할 뿐, 그 이외의 일은 전혀 하지 않아야 한다. 또 다른 특성으로는 정수 값을 두 개 받고 정수 값 하나를 반환하는 함수가 있다고 하자. 주어진 임의의 두 정수에 대해 항상 같은 값을 돌려준다. 그런 의미에서 String.length 메소드도 순수 함수다. (주어진 임의의 문자열에 대해 항상 같은 길이를 돌려주기만 하고 그 외의 일은 전혀 일어나지 않음) 위와 같은 속성을 참조 투명성이라고 한다. 만일 어떤 표현식을 그 평가 결과로 바꾸어도 프로그램의 의미가 변하지 않는다면, 그 표현식은 참조에 투명한 것이다. 2 + 3은 하나의 표현식이고 그에 대한 결과는 5다. 여기서 2 + 3을 5로 바꾸어도 프로그램의 의미는 바뀌지 않는다. 참조 투명성과 순수성만일 모든 프로그램 p에 대해 표현식 e의 모든 출현(occurrence)을 e의 평가 결과로 치환해도 p의 의미에 아무 영향이 미치지 않는다면, 그 표현식 e는 참조에 투명하다(referentially transparent). 만일 ㅍ현식 f(x)가 참조에 투명한 모든 x에 대해 참조에 투명하면, 함수 f는 순수하다(pure). Step1에서 봤던 buyCoffee 메소드는 참조 투명할까? 임의의 p라는 함수가 커피를 받는다고 가정하자. p(buyCoffee(aliceCreditCard))가 p(new Coffee())와 동일하게 작동해야 한다. new Coffee()는 커피만 전달할 뿐 아무 일도 일어나지 않지만 buyCoffee(aliceCreditCard)는 커피를 전달하는 것 뿐만 아니라 신용카드 회사에 연결하여 대금을 청구한다. 따라서 참조 투명하지 않다. 또 다른 예를 살펴보자. java.lang.StringBuilder는 참조 투명하지 않다.왜 그럴까? 다음 예제 코드를 보자. scala> val x = new StringBuilder(\"Hello\") x: StringBuilder = Hello scala> val y = x.append(\", world\") y: StringBuilder = Hello, world val r1 = y.toString // \"Hello, world\" val r2 = y.toString // \"Hello, world\" r1과 r2는 같다. 여기서 y의 모든 출현을 append 호출로 치환하면 어떻게 될까? scala&gt; val x = new StringBuilder(&quot;Hello&quot;) x: StringBuilder = Hello scala&gt; val y = x.append(&quot;, world&quot;) y: StringBuilder = Hello, world val r1 = x.append(&quot;, world&quot;).toString val r2 = x.append(&quot;, world&quot;).toString r1과 r2의 결과는 같지 않다. (r1은 “Hello, world” r2는 “Hello, world, world”) Chapter 02. 스칼라로 함수형 프로그래밍 시작하기이번 챕터에서 다루는 내용 스칼라 언어의 몇 가지 기본 요소 꼬리 재귀 함수를 이용한 루프 작성법 고차 함수 (다른 함수를 인수로 받는 함수, 결과로 또 다른 함수를 돌려줄 수도 있다.) 다형적 고차함수 object MyModule { def abs(n: Int): Int = if (n &lt; 0) -n else n private def formatAbs(x: Int) = { val msg = \"The absolute value of %d is %d\" msg.format(x, abs(x)) } def main(args: Array[String]): Unit = println(formatAbs(-42)) } object 키워드object 키워드는 새로운 싱글톤 객체를 만든다. 스칼라에는 Java의 static 키워드에 해당하는 것이 없으며, Java에서 정적 멤버를 가진 클래스를 사용할 만한 상황일 때 Scala에서는 object를 사용한다. 예제코드를 통해 살펴본 스칼라의 기본 개념 위의 예제 코드에서 abs와 formatAbs는 순수 함수이다. main 메소드는 순수 함수를 호출하고 그 결과를 콘솔에 출력하는 일을 한다. 부수 효과가 발생함을 강조하기 위해 이런 메소드를 절차(Procedure) 또는 불순 함수(impure function)라고 부르기도 한다. 일반적으로, 반환 형식이 Unit이라는 것은 그 메서드에 부수 효과가 존재함을 암시한다. MyModule 객체와 같이 자신의 멤버들에게 이름 공간을 제공하는 것이 주된 목적인 객체를 흔히 모듈(module)이라고 부른다. 스칼라에는 연산자(operator)라는 특별한 개념이 존재하지 않으며, 모든 행동은 메소드이다. 고차 함수고차 함수(higher-order function, HOF; 또는 고계 함수)를 이해하기 위해, 계승을 구하는 factorial 함수를 작성해보자. def factorial(n: Int): Int = { def go(n: Int, acc: Int): Int = if (n &lt;= 0) acc else go(n-1, n*acc) go(n, 1) } factorial 함수의 본문 안에 재귀적인 보조 함수를 하나 정의함 (go) 이런 루프용 보조 함수에는 go나 loop 같은 이름을 붙이는 것이 관례 factorial 함수의 본문은 루프 초기 조건에 해당하는 값으로 go를 호출하는것 뿐이다. go 함수는 factorial 함수 안에서만 호출이 가능함 위 코드는 스칼라에서 꼬리 재귀 호출로 컴파일한다. 왜? go의 인수는 남아 있는 값 n과 현재 누적된 계승 acc 다음 반복으로 넘어갈 때는 go 자신을 호출한다. 루프에서 벗어날 때 (n &lt;= 0)는 재귀 호출 없이 값을 돌려준다. 이러한 특성 때문에 재귀 호출이 꼬리 위치(tail position)에서 일어난다면 while 루프를 사용했을 때와 동일한 바이트코드로 컴파일한다. (스택을 소비하지 않는 루프 형태로 컴파일) 스칼라의 꼬리 호출호출자가 재귀 호출의 결과를 그대로 돌려주는 것 외에는 아무 일도 하지 않을 때, 그런 호출을 꼬리 호출이라고 말한다. 예를 들어 go(n-1, n*acc)는 꼬리 위치에서 일어난다.) 반면 1 + go(n -1, n*acc) 같은 재귀 호출은 꼬리 호출이 아니다. go의 결과에 대해 다른 일(1을 더하는 것)을 수행해야 하기 때문 object MyModule { def abs(n: Int): Int = if (n &lt; 0) -n else n private def formatAbs(x: Int) = { val msg = \"The absolute value of %d is %d\" msg.format(x, abs(x)) } private def formatFactorial(n: Int) = { val msg = \"The factorial of %d is %d.\" msg.format(n, factorial(n)) } def main(args: Array[String]): Unit = { println(formatAbs(-42)) println(formatFactorial(7)) } } formatAbs와 formatFactorial을 하나의 함수 formatResult로 일반화 하면 어떨까? def formatResult(name: String, n: Int, f: Int => Int) = { val msg = \"The %s of %d is %d.\" msg.format(name, n, f(n)) } formatResult(\"absolute value\", -42, abs) formatResult(\"factorial\", 7, factorial) 여기서 formatResult는 f라는 다른 함수를 받는 일종의 고차 함수이다. 고차 함수의 인수에는 f, g, n 같은 이름을 사용하는 것이 관례. FP에서는 아주 짧은 변수 이름을 사용하는 경향이 있다. 왜냐면 인수로 받은 함수가 실제로 수행하는 일에 대해 구체적으로 알지 못하기 때문이다. (고차함수는 그냥 인수의 형식만 알 뿐) 다형적 함수다형적 함수(polymorphic function)을 이해하기 위해, 예제를 살펴보자. def findFirst(ss: Array[String], key: String): Int = { @annotation.tailrec def loop(n: Int): Int = if (n >= ss.length) - 1 else if (ss(n) == key) n else loop(n + 1) loop(0) // 배열의 첫 요소에서 루프를 시작한다. } 여기서는 String 배열로 한정되었지만, Int나 혹은 사용자가 정의한 타입의 배열에서 찾을 수 있게 일반화해보자. def findFirst[A](as: Array[A], p: A => Boolean): Int = { @annotation.tailrec def loop(n: Int): Int = if (n >= as.length) -1 else if (p(as(n))) n // 함수 p가 현재 요소와 부합한다면 원하는 요소를 찾은 것. else loop(n + 1) loop(0) } 파라미터 매개변수의 이름으로는 보통 [A, B, C] 같은 짧은 한 글자짜리 대문자를 사용하는게 관례 findFirst 함수 호출은 다음과 같이 한다. findFirst(Array(7, 9, 13), (x: Int) =&gt; x == 9) 여기서 Array(7, 9, 13)을 배열 리터럴이라 한다. (x: Int) =&gt; x == 9는 함수 리터럴 혹은 익명 함수라 한다.","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"http://icednut.github.io/tags/scala/"},{"name":"functional programming","slug":"functional-programming","permalink":"http://icednut.github.io/tags/functional-programming/"}]},{"title":"gRPC 살펴보기 (gRPC Overview)","slug":"20180706-about-grpc","date":"2018-07-04T13:15:27.000Z","updated":"2018-11-27T06:40:43.300Z","comments":true,"path":"2018/07/04/20180706-about-grpc/","link":"","permalink":"http://icednut.github.io/2018/07/04/20180706-about-grpc/","excerpt":"","text":"목차 About gRPC Why gRPC? gRPC 내부 구조 및 동작 과정 gRPC 개발 맛보기 protobuf 정의 gRPC Server gRPC Client gRPC 통신의 4가지 방식 Unary Server Streaming Client Streaming 양방향 Streaming 고민해볼 문제 Testing Authenticatoin (TLS, OAuth) Load Balancing (Client-side, Server-side) Monitoring Proxies, Web (REST Adapter, grpc-gateway) Versioning 참고 자료 About gRPCgRPC는 HTTP2 기반의 오픈 소스 하이 퍼포먼스 원격 프로시저 호출(RPC) 프레임워크 입니다. gRPC에서 클라이언트 어플리케이션은 다른 서버 어플리케이션의 메서드를 마치 로컬 객체인 것처럼 직접 호출할 수 있으므로 분산 어플리케이션 및 서비스를 보다 쉽게 만들 수 있습니다. 많은 RPC 처럼 gRPC는 서비스를 정의하고 파라미터 및 리턴 유형을 사용하여 원격으로 호출할 수있는 메소드를 지정한다는 아이디어를 기반으로 합니다. RPC(Remote Procedure Call)이란?원격 프로시저 호출(remote procedure call, 리모트 프로시저 콜, RPC)은 별도의 원격 제어를 위한 코딩 없이 다른 주소 공간에서 함수나 프로시저를 실행할 수 있게 하는 프로세스 간 통신 기술이다. 다시 말해, 원격 프로시저 호출을 이용하면 프로그래머는 함수가 실행 프로그램에 로컬 위치에 있든 원격 위치에 있든 동일한 코드를 이용할 수 있다. 출처: https://ko.wikipedia.org/wiki/%EC%9B%90%EA%B2%A9_%ED%94%84%EB%A1%9C%EC%8B%9C%EC%A0%80_%ED%98%B8%EC%B6%9C 또한 구글은 사내에서 Stubby라는 RPC 프레임워크를 만들어서 사용하고 있었는데 하루에 초당 100억건의 RPC Call을 처리한다고 합니다. 구글은 Stubby 다음 버전을 계획하면서 오픈소스로 외부에 공개하기로 결정하였고 이에 따라 gRPC가 탄생하게 되었습니다. 참고로 gRPC는 성능을 중요시하기 때문에 HTTP2 기반으로 동작합니다. 잠깐! 왜 이제와서 RPC를 거들먹거리는건가? (Why gRPC?) RPC 기술들: CORBA, DCOM, RMI (Java RMI) CORBA (with Java)로 헬로 월드 찍어 보셨어요? (http://www.ejbtutorial.com/programming/tutorial-for-corba-hello-world-using-java) 이렇게 힘든데 왜 구글은 RPC를 사용하는걸까요? 구글은 Stubby를 통해 다음과 같은 점들을 배웠다고 합니다. (gRPC Motivation) HTTP/JSON doesn`t cut it! Establish a lingua granca[^1] Design for fault tolerance and provide control knobs Don`t fly blind: Service Analytics Diagonosing problems: Tracing Load Balancing is critical (시간 관계상 이 부분은 다른 자료로 대체하도록 하겠습니다. https://www.slideshare.net/datawire/bringing-learnings-from-googley-microservices-with-grpc-varun-talwar-google) 그리하여 gRPC는 다음과 같은 사양 갖추었습니다. Transport: HTTP/2[^2] Wire format: Protocol Buffers 3^3 (Binary) Service definition: Protocol Buffers IDL gRPC는 이런 HTTP/2의 특징을 기반으로 하기때문에 양방향 스트리밍이 가능하고, 기본적인 통신 속도가 빠릅니다. on-connection 상태에서 비동기 통신의 구현이 용이합니다. 정리하자면 gRPC를 사용해야할 이유는 다음과 같습니다. Binary protocol (HTTP/2), Multiplexing many requests on one connection (HTTP/2) Header compression (HTTP/2) Strongly typed service and message definition (Protobuf) Idiomatic client/server library implementations in many languages gRPC Benchmarking: https://github.com/david-cao/gRPCBenchmarks gRPC의 특징 간단한 서비스 정의 (Simple Service Definition) 서비스 정의(모델 정의, 통신 과정 정의)를 Protocol Buffer를 사용 Protocol Buffer는 XML과 같은 구조화된 데이터 정의라고 보면 되며, 일종의 IDL(Interface Definition Language)이다. (그러나 XML보다 직관적이고 표현이 풍부하다) Protocol Buffer는 .proto 파일로 정의하며 서비스 인터페이스와 메세지 페이로드를 정의할 때 사용 protobuf example service HelloService { rpc SayHello(HelloRequest) returns (HelloResponse); } message HelloRequest { string greeting = 1; } message HelloResponse { string reply = 1; } 다양한 언어와 플랫폼에서 동작 (Works across language and platforms) protobuf로 생성한 서비스 정의에 따라 클라이언트와 서버에서 사용하는 언어에 맞게 모델과 인터페이스 Stubs를 생성 각 언어에 맞는 gRPC 프레임워크를 통해 개발 및 실행 진행 공식 지원하는 변환 타겟 언어: C/C++, C#, Dart*, Go, Java, Node.js, PHP*, Python, Ruby (*은 아직 Beta 단계) 양방향 스트리밍과 통합 인증 (Bi-directional streaming and integrated auth) http/2 기반의 양방향 스트리밍과 조립 가능한 인증 및 인터셉터 인터페이스를 제공 인증에는 SSL/TLS 혹은 Google Token-based authentication을 사용하거나 직접 인증 시스템을 연동할 수 있음 따라서 gRPC는 이런 곳에 적용하면 좋습니다. Server to Server Server to Mobile device ex) 주식 시장, 게임, 스마트홈 디바이스 등등 이쯤에서 gRPC의 내부 구조와 동작 과정을 살펴봅시다gRPC는 여러 가지 언어(C/C++, C#, Dart, Go, Java, Node.js, PHP, Python, Ruby에서 동작 가능합니다. 그러나 gRPC는 3가지 언어(C, Java, Go)로 동일하게 구현되어 있습니다. 그 외 나머지 언어들은 핵심은 C-Runtime 라이브러리로 형태로 개발하여 각 언어별로 랩핑되어 있습니다. 이렇게 한 이유는 개발 비용 절감과 구현, 언어별 퍼포먼스 일관성을 가져갈 수 있기 때문입니다. grpc-java (https://github.com/grpc/grpc-java) grpc-go (https://github.com/grpc/grpc-go) grpc (https://github.com/grpc/grpc) 그 중에서 gRPC Java는 다음과 같은 아키텍처를 갖추고 있습니다. gRPC 동작과정을 살펴보기 전에 간단하게 gRPC를 사용하여 Hello world 메세지를 주고 받는 Server, Client Java Application을 개발해보도록 하겠습니다. 개발 과정은 다음과 같습니다. Protocol Buffer 3 (IDL)을 이용하여 RPC 인터페이스 및 모델 정의 프로젝트 셋팅 (with Gradle) 서버 개발 클라이언트 개발 개발 과정1. 프로젝트 셋팅 (with Gradle)apply plugin: 'java' apply plugin: 'com.google.protobuf' targetCompatibility = versionJavaLang sourceCompatibility = versionJavaLang protobuf { protoc { artifact = \"com.google.protobuf:protoc:${protocVersion}\" } plugins { grpc { artifact = \"io.grpc:protoc-gen-grpc-java:${grpcVersion}\" } } generateProtoTasks { ofSourceSet('main').each { task -> task.builtins { java { outputSubDir = 'protoGen' } } task.plugins { grpc { outputSubDir = 'protoGen' } } } } generatedFilesBaseDir = \"$projectDir/src/\" } sourceSets { main { java { srcDir 'src/main/java' srcDir 'src/main/protoGen' } } } dependencies { compile(\"com.google.api.grpc:proto-google-common-protos:1.0.0\") compile(\"com.google.protobuf:protobuf-java-util:${protobufVersion}\") } task cleanProtoGen { doFirst { delete(\"$projectDir/src/main/protoGen\") } } clean.dependsOn cleanProtoGen 2. Protocol Buffer 3을 이용하여 RPC 인터페이스 및 모델 정의아래와 같이 모델과 RPC Stub 인터페이스를 정의합니다. 그런 뒤 Gradle의 generateProto를 수행하면 HelloRequest, HelloReply 모델 클래스와 커넥션 처리 로직이 담긴 Greeter Stub 클래스가 생성이 됩니다. 특이한 점은 모델 클래스 안에 파싱 로직이 담겨있고 Stub은 서버 측 뿐만 아니라 Java Client 측에서 호출할 수 있는 Stub 로직도 같이 생성됩니다. (서버 측 GreeterGrpc.GreeterImplBase, 클라이언트 측: GreeterGrpc.GreeterBlockingStub) syntax = \"proto3\"; option java_multiple_files = true; option java_package = \"io.icednut.grpc.common.exercise.helloworld\"; option java_outer_classname = \"HelloWorldProto\"; option objc_class_prefix = \"HLW\"; package helloworld; // Greeting 서비스 정의 service Greeter { // 파라미터로 받은 인사요청에 담긴 이름으로 인사 메세지가 담긴 모델 반환하기 rpc SayHello(HelloRequest) returns (HelloReply) {} } message HelloRequest { string name = 1; } message HelloReply { string message = 1; } 3. 서버 개발Java 서버 측 디펜던시를 추가합니다. compile 'io.grpc:grpc-netty:1.13.1' compile 'io.grpc:grpc-protobuf:1.13.1' compile 'io.grpc:grpc-stub:1.13.1' Greeter 서비스를 개발합니다. public class GreeterService extends GreeterGrpc.GreeterImplBase { @Override public void sayHello(HelloRequest req, StreamObserver&lt;HelloReply> responseObserver) { HelloReply reply = HelloReply.newBuilder() .setMessage(\"Hello \" + req.getName()) .build(); responseObserver.onNext(reply); responseObserver.onCompleted(); } } Greeter 서비스 처리를 진행할 서버를 개발합니다. public class GrpcCommonServer { private static final Logger logger = LoggerFactory.getLogger(GrpcCommonServer.class); private final Server server; private final int port; public GrpcCommonServer(int port, List&lt;BindableService> services) { this.port = port; ServerBuilder&lt;?> serverBuilder = ServerBuilder.forPort(this.port); services.forEach(service -> serverBuilder.addService(service)); this.server = serverBuilder.build(); } public void start() throws IOException, InterruptedException { server.start(); logger.info(\"Server started, listening on \" + port); this.blockUntilShutdown(); Runtime.getRuntime().addShutdownHook(new Thread(() -> { System.err.println(\"*** shutting down gRPC server since JVM is shutting down\"); GrpcCommonServer.this.stop(); System.err.println(\"*** server shut down\"); })); } public void stop() { if (server != null) { server.shutdown(); } } public void blockUntilShutdown() throws InterruptedException { if (server != null) { server.awaitTermination(); } } } Java Main 메소드에서 서버를 실행합니다. public class GrpcServerApplication { public static void main(String[] args) throws IOException, InterruptedException { GrpcCommonServer server = new GrpcCommonServer(50551, Arrays.asList(new GreeterService())); server.start(); server.blockUntilShutdown(); } } 3.1. 서버측 동작 과정서버측 동작 과정은 크게 서버 생성, 서버 실행 및 대기, 서버 종료 과정으로 나뉩니다. gRPC 프레임워크에 따라 RPC를 처리할 서버를 생성한 뒤 Netty 서버를 실행하고 Netty 서버가 소켓 및 HTTP2 프로토콜을 사용하여 RPC Call 요청 처리 대기를 합니다. RPC Call 요청이 들어오면 HTTP2 프로토콜로 바이너리 데이터를 주고 받는 방식으로 진행 됩니다. 서버 생성 과정을 살펴보면 다음과 같습니다. [서버 생성] 요청을 받을 프로세스의 포트와 요청에 부름을 받을 메소드가 담긴 service 객체를 조합하여 최종적으로 NettyServer를 생성한다 이렇게 생성한 서버에 start 메소드를 실행하면 요청 처리 대기 상태가 됩니다. [서버 실행] 요청 처리 대기 상태라는 말은 NioEventLoop가 실행되어 의미 있는 커넥션이 맺어질 때 io.grpc.netty.NettyServerTransport 와 io.grpc.netty.ProtocolNegotiators를 통해 io.grpc.netty.GrpcHttp2ConnectionHandler 타입의 응답 처리기(Handler)를 만들어서 클라이언트와의 연결 및 클라이언트와 주고 받는 데이터(byte array)를 처리하게 됩니다. public static ProtocolNegotiator serverPlaintext() { return new ProtocolNegotiator() { @Override public Handler newHandler(final GrpcHttp2ConnectionHandler handler) { class PlaintextHandler extends ChannelHandlerAdapter implements Handler { @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception { handler.handleProtocolNegotiationCompleted(Attributes.newBuilder() .set(Grpc.TRANSPORT_ATTR_REMOTE_ADDR, ctx.channel().remoteAddress()) .build(), null); ctx.pipeline().replace(this, null, handler); } ... } return new PlaintextHandler(); } }; } GrpcHttp2ConnectionHandler는 io.netty.handler.codec.http2.Http2ConnectionHandler 를 상속받은 구현체로 HTTP2 스펙을 따르며 그에 따른 커낵션 및 라이프사이클을 수행합니다. 그런 다음 클라이언트와 커낵션을 맺은 뒤 해당 커넥션과 protobuf Stub을 사용해서 byte array 형태의 데이터를 주고 받습니다. 앞의 Hello world 예제를 기준으로 설명하면 클라이언트는 sayHello()라는 함수를 호출하면 HelloRequest의 멤버인 String name을 byte array로 변환하여 전송합니다. 그러면 서버에서는 byte array stream으로 받고 연결을 끊지 않은채 스트림에서 데이터를 읽어와 io.grpc.protobuf.ProtoLiteUtils 클래스를 통해 모델 객체로 파싱합니다. (궁금해서 모델의 byte array를 열어보니 JSON 형태가 아닌 tag: value 형태의 문자열이었습니다.) 이렇게 파싱한 모델 객체와 byte array에 명시된 호출할 메소드를 호출하여 비로소 우리가 작성한 비지니스 로직을 실행하게 됩니다. 4. 클라이언트 개발클라이언트는 일반 Java command line application으로 가정하고 진행하도록 하겠습니다. 먼저 아래와 같이 디펜던시를 추가합니다. compile 'io.grpc:grpc-netty:1.13.1' compile 'io.grpc:grpc-protobuf:1.13.1' compile 'io.grpc:grpc-stub:1.13.1' 앞에 서버측에서 정의한 protobuf를 그대로 똑같이 사용하여 모델 및 Stub을 사용합니다. 그런 다음 해당 Stub을 사용하는 HelloWroldClient 클래스를 정의합니다. public class HelloWorldClient { private final ManagedChannel channel; private final GreeterGrpc.GreeterBlockingStub blockingStub; public HelloWorldClient(String host, int port) { this(ManagedChannelBuilder.forAddress(host, port) .usePlaintext() .build()); } HelloWorldClient(ManagedChannel channel) { this.channel = channel; blockingStub = GreeterGrpc.newBlockingStub(channel); } } 여기서 서버와의 접속 수단인 ManagedChannel 객체를 생성하고 Stub에 조립하여 사용합니다. 이렇게 하면 사실 개발자는 내부 통신 과정을 알 필요가 없습니다. 그 다음 stub.sayHello() 메소드를 사용하면 개발자가 보기엔 서버측의 메소드를 사용한 것처럼 보이지만 내부적으로는 Netty Client를 통해 HTTP2 방식으로 byte array 데이터를 전송하게 됩니다. public class HelloWorldClient { private final ManagedChannel channel; private final GreeterGrpc.GreeterBlockingStub blockingStub; public HelloWorldClient(String host, int port) { this(ManagedChannelBuilder.forAddress(host, port) .usePlaintext() .build()); } HelloWorldClient(ManagedChannel channel) { this.channel = channel; blockingStub = GreeterGrpc.newBlockingStub(channel); } public void greet(String name) { HelloRequest request = HelloRequest.newBuilder() .setName(name) .setAge(10) .build(); HelloReply response; try { response = blockingStub.sayHello(request); } catch (StatusRuntimeException e) { logger.log(Level.WARNING, \"RPC failed: {0}\", e.getStatus()); return; } logger.info(\"Greeting: \" + response.getMessage() + \"|\" + response.getAge()); } } 4.1. 클라이언트 측 동작 과정클라이언트 측은 사실 Stub 객체의 동작과정만 잘 알면 됩니다. 그 안에서 데이터 변환 및 서버 호출을 결정하고 수행하고 있습니다. 1. io.grpc.netty.NettyClientHandler - [id: 0x42c055ac, L:/127.0.0.1:53048 - R:localhost/127.0.0.1:8090] OUTBOUND SETTINGS: ack=false settings={ENABLE_PUSH=0, MAX_CONCURRENT_STREAMS=0, INITIAL_WINDOW_SIZE=1048576, MAX_HEADER_LIST_SIZE=8192} io.grpc.netty.NettyClientHandler - [id: 0x42c055ac, L:/127.0.0.1:53048 - R:localhost/127.0.0.1:8090] OUTBOUND WINDOW_UPDATE: streamId=0 windowSizeIncrement=983041 io.grpc.netty.NettyClientHandler - [id: 0x42c055ac, L:/127.0.0.1:53048 - R:localhost/127.0.0.1:8090] INBOUND SETTINGS: ack=false settings={MAX_CONCURRENT_STREAMS=2147483647, INITIAL_WINDOW_SIZE=1048576, MAX_HEADER_LIST_SIZE=8192} io.grpc.netty.NettyClientHandler - [id: 0x42c055ac, L:/127.0.0.1:53048 - R:localhost/127.0.0.1:8090] OUTBOUND SETTINGS: ack=true io.grpc.netty.NettyClientHandler - [id: 0x42c055ac, L:/127.0.0.1:53048 - R:localhost/127.0.0.1:8090] INBOUND WINDOW_UPDATE: streamId=0 windowSizeIncrement=983041 2. io.grpc.netty.NettyClientHandler - [id: 0x42c055ac, L:/127.0.0.1:53048 - R:localhost/127.0.0.1:8090] OUTBOUND DATA: streamId=3 padding=0 endStream=true length=14 bytes=00000000090a05776f726c64100a 3. io.grpc.netty.NettyClientHandler - [id: 0x42c055ac, L:/127.0.0.1:53048 - R:localhost/127.0.0.1:8090] INBOUND HEADERS: streamId=3 headers=GrpcHttp2ResponseHeaders[:status: 200, content-type: application/grpc, grpc-encoding: identity, grpc-accept-encoding: gzip] streamDependency=0 weight=16 exclusive=false padding=0 endStream=false 4. io.grpc.netty.NettyClientHandler - [id: 0x42c055ac, L:/127.0.0.1:53048 - R:localhost/127.0.0.1:8090] INBOUND DATA: streamId=3 padding=0 endStream=false length=18 bytes=000000000d0a0b48656c6c6f20776f726c64 5. io.grpc.netty.NettyClientHandler - [id: 0x42c055ac, L:/127.0.0.1:53048 - R:localhost/127.0.0.1:8090] INBOUND HEADERS: streamId=3 headers=GrpcHttp2ResponseHeaders[grpc-status: 0] streamDependency=0 weight=16 exclusive=false padding=0 endStream=true 6. io.grpc.netty.NettyClientHandler - [id: 0x42c055ac, L:/127.0.0.1:53048 - R:localhost/127.0.0.1:8090] OUTBOUND GO_AWAY: lastStreamId=0 errorCode=0 length=0 bytes= gRPC 통신의 4가지 방식길찾기(?) 서비스를 통해 gRPC의 4가지 통신 방식을 살펴보도록 하겠습니다. 먼저 protobuf를 먼저 정의합니다. syntax = \"proto3\"; option java_multiple_files = true; option java_package = \"io.grpc.examples.routeguide\"; option java_outer_classname = \"RouteGuideProto\"; option objc_class_prefix = \"RTG\"; package routeguide; // RouteGuide 서비스 정의합니다. // 서비스가 제공하는 RPC 메서드를 선언하고, 각 메서드의 요청/응답 메시지를 정의합니다. service RouteGuide { // 단순한 RPC // 클라이언트에서 요청를 보내고 서버의 응답을 리턴합니다 rpc GetFeature(Point) returns (Feature) {} // 서버에서 클라이언트로 스트리밍하는 RPC // 클라이언트에서 요청을 보내고 서버로 부터 더이상 받을 메시지가 없을때까지 // 스트림(sequence of messages)을 읽습니다 // 스트림을 사용하기 위해서 stream 키워드를 사용합니다 rpc ListFeatures(Rectangle) returns (stream Feature) {} // 클라이언트에서 서버로 스트리밍하는 RPC // 클라이언트에서 스트림을 모두 서버에 쓰고 끝나면 서버의 응답을 리턴합니다 rpc RecordRoute(stream Point) returns (RouteSummary) {} // 양방향 스트리밍 RPC // 클라이언트와 서버가 서로 독립적으로 스트림을 읽고 씁니다. rpc RouteChat(stream RouteNote) returns (stream RouteNote) {} } // 서비스의 요청/응답 메시지와 타입 정의를 작성합니다. message Point { int32 latitude = 1; int32 longitude = 2; } message Rectangle { Point lo = 1; Point hi = 2; } message Feature { string name = 1; Point location = 2; } message FeatureDatabase { repeated Feature feature = 1; // repeated를 사용하면 자바에서 List&lt;Feature>로 생성 } message RouteNote { Point location = 1; string message = 2; } message RouteSummary { int32 point_count = 1; // &lt;-- 추후 메시지 변화에 따른 하위 호환성을 위해서 숫자를 지정해야함. int32 feature_count = 2; int32 distance = 3; int32 elapsed_time = 4; } 1. Unary callServerpublic class RouteGuideService extends RouteGuideGrpc.RouteGuideImplBase { @Override public void getFeature(Point request, StreamObserver&lt;Feature> responseObserver) { responseObserver.onNext(checkFeature(request)); responseObserver.onCompleted(); } } Clientpublic class RouteGuideClient { private final ManagedChannel channel; private final RouteGuideGrpc.RouteGuideBlockingStub blockingStub; public RouteGuideClient(ManagedChannelBuilder&lt;?> channelBuilder) { channel = channelBuilder.build(); blockingStub = RouteGuideGrpc.newBlockingStub(channel); } public void getFeature(int lat, int lon) { Point request = Point.newBuilder() .setLatitude(lat) .setLongitude(lon) .build(); Feature feature; try { feature = blockingStub.getFeature(request); } catch (StatusRuntimeException e) { ... } } } 2. Server StreamingServerpublic class RouteGuideService extends RouteGuideGrpc.RouteGuideImplBase { @Override public void listFeatures(Rectangle request, StreamObserver&lt;Feature> responseObserver) { int left = min(request.getLo().getLongitude(), request.getHi().getLongitude()); int right = max(request.getLo().getLongitude(), request.getHi().getLongitude()); int top = max(request.getLo().getLatitude(), request.getHi().getLatitude()); int bottom = min(request.getLo().getLatitude(), request.getHi().getLatitude()); for (Feature feature : features) { if (!RouteGuideUtil.exists(feature)) { continue; } int lat = feature.getLocation().getLatitude(); int lon = feature.getLocation().getLongitude(); if (lon >= left &amp;&amp; lon &lt;= right &amp;&amp; lat >= bottom &amp;&amp; lat &lt;= top) { responseObserver.onNext(feature); } } responseObserver.onCompleted(); } } Clientpublic class RouteGuideClient { private final ManagedChannel channel; private final RouteGuideGrpc.RouteGuideBlockingStub blockingStub; public RouteGuideClient(ManagedChannelBuilder&lt;?> channelBuilder) { channel = channelBuilder.build(); blockingStub = RouteGuideGrpc.newBlockingStub(channel); } public void listFeatures(int lowLat, int lowLon, int hiLat, int hiLon) { Rectangle request = Rectangle.newBuilder() .setLo(Point.newBuilder().setLatitude(lowLat).setLongitude(lowLon).build()) .setHi(Point.newBuilder().setLatitude(hiLat).setLongitude(hiLon).build()).build(); Iterator&lt;Feature> features; try { features = blockingStub.listFeatures(request); for (int i = 1; features.hasNext(); i++) { Feature feature = features.next(); info(\"Result #\" + i + \": {0}\", feature); } } catch (StatusRuntimeException e) { ... } } } 3. Client StreamingServerpublic class RouteGuideService extends RouteGuideGrpc.RouteGuideImplBase { @Override public StreamObserver&lt;Point> recordRoute(StreamObserver&lt;RouteSummary> responseObserver) { return new StreamObserver&lt;Point>() { int pointCount; int featureCount; int distance; Point previous; long startTime = System.nanoTime(); @Override public void onNext(Point point) { pointCount++; if (RouteGuideUtil.exists(checkFeature(point))) { featureCount++; } if (previous != null) { distance += calcDistance(previous, point); } previous = point; } @Override public void onError(Throwable t) { logger.log(Level.WARNING, \"Encountered error in recordRoute\", t); } @Override public void onCompleted() { long seconds = NANOSECONDS.toSeconds(System.nanoTime() - startTime); responseObserver.onNext(RouteSummary.newBuilder().setPointCount(pointCount) .setFeatureCount(featureCount).setDistance(distance) .setElapsedTime((int) seconds).build()); responseObserver.onCompleted(); } }; } } Clientpublic class RouteGuideClient { private final ManagedChannel channel; private final RouteGuideGrpc.RouteGuideStub asyncStub; public RouteGuideClient(ManagedChannelBuilder&lt;?> channelBuilder) { channel = channelBuilder.build(); asyncStub = RouteGuideGrpc.newStub(channel); } public void recordRoute(List&lt;Feature> features, int numPoints) throws InterruptedException { final CountDownLatch finishLatch = new CountDownLatch(1); StreamObserver&lt;RouteSummary> responseObserver = new StreamObserver&lt;RouteSummary>() { @Override public void onNext(RouteSummary summary) { // summary 처리 } @Override public void onError(Throwable t) { if (testHelper != null) { testHelper.onRpcError(t); } finishLatch.countDown(); } @Override public void onCompleted() { finishLatch.countDown(); } }; StreamObserver&lt;Point> requestObserver = asyncStub.recordRoute(responseObserver); try { for (int i = 0; i &lt; numPoints; ++i) { int index = random.nextInt(features.size()); Point point = features.get(index).getLocation(); requestObserver.onNext(point); Thread.sleep(random.nextInt(1000) + 500); if (finishLatch.getCount() == 0) { return; } } } catch (RuntimeException e) { requestObserver.onError(e); throw e; } requestObserver.onCompleted(); if (!finishLatch.await(1, TimeUnit.MINUTES)) { warning(\"recordRoute can not finish within 1 minutes\"); } } } 4. 양방향 StreamingServerpublic class RouteGuideService extends RouteGuideGrpc.RouteGuideImplBase { @Override public StreamObserver&lt;RouteNote> routeChat(StreamObserver&lt;RouteNote> responseObserver) { return new StreamObserver&lt;RouteNote>() { @Override public void onNext(RouteNote note) { List&lt;RouteNote> notes = getOrCreateNotes(note.getLocation()); // Respond with all previous notes at this location. for (RouteNote prevNote : notes.toArray(new RouteNote[0])) { responseObserver.onNext(prevNote); } // Now add the new note to the list notes.add(note); } @Override public void onError(Throwable t) { logger.log(Level.WARNING, \"Encountered error in routeChat\", t); } @Override public void onCompleted() { responseObserver.onCompleted(); } }; } } Clientpublic class RouteGuideClient { private final ManagedChannel channel; private final RouteGuideGrpc.RouteGuideStub asyncStub; public RouteGuideClient(ManagedChannelBuilder&lt;?> channelBuilder) { channel = channelBuilder.build(); asyncStub = RouteGuideGrpc.newStub(channel); } public CountDownLatch routeChat() { final CountDownLatch finishLatch = new CountDownLatch(1); StreamObserver&lt;RouteNote> requestObserver = asyncStub.routeChat(new StreamObserver&lt;RouteNote>() { @Override public void onNext(RouteNote note) { // } @Override public void onError(Throwable t) { warning(\"RouteChat Failed: {0}\", Status.fromThrowable(t)); if (testHelper != null) { testHelper.onRpcError(t); } finishLatch.countDown(); } @Override public void onCompleted() { info(\"Finished RouteChat\"); finishLatch.countDown(); } }); try { RouteNote[] requests = {newNote(\"First message\", 0, 0), newNote(\"Second message\", 0, 1), newNote(\"Third message\", 1, 0), newNote(\"Fourth message\", 1, 1)}; for (RouteNote request : requests) { requestObserver.onNext(request); } } catch (RuntimeException e) { requestObserver.onError(e); throw e; } requestObserver.onCompleted(); return finishLatch; } } 고민해볼 문제 Testing gRPC client https://www.npmjs.com/package/grpcc gRPC JUnit Test https://grpc.io/blog/gracefully_clean_up_in_grpc_junit_tests Authenticatoin TLS, OAuth Load Balancing (Client-side, Server-side) Load Balancing in gRPC https://grpc.io/blog/loadbalancing https://github.com/grpc/grpc/blob/master/doc/load-balancing.md gRPC Load Balancing Example in Kubernetes https://github.com/saturnism/grpc-java-by-example/tree/master/kubernetes-lb-example Spring-gRPC Load Balancing with Eureka https://github.com/saturnism/grpc-java-by-example/tree/master/springboot-example Monitoring Zipkin, Prometheus, Statsd, Google, DIY java-grpc-prometheus example https://github.com/grpc-ecosystem/java-grpc-prometheus Proxies, Web haproxy, traefik, grpc-gateway Grpc LB, Service Discovery (etcd, zookeeper, eureka) Versioning 참고자료 https://grpc.io/docs/guides/concepts.html https://github.com/grpc/grpc-java https://github.com/grpc/grpc-web https://github.com/grpc-ecosystem https://github.com/grpc-ecosystem/awesome-grpc https://github.com/saturnism/grpc-java-by-example https://medium.com/@goinhacker/microservices-with-grpc-d504133d191d https://www.slideshare.net/borisovalex/enabling-googley-microservices-with-http2-and-grpc?next_slideshow=1 https://www.slideshare.net/VarunTalwar4/grpc-design-and-implementation https://www.slideshare.net/datawire/bringing-learnings-from-googley-microservices-with-grpc-varun-talwar-google http://www.baeldung.com/grpc-introduction Armeria [^1]: 링구아 프랑카(lingua franca)는 서로 다른 모어를 사용하는 화자들이 의사소통을 하기 위해 공통어로 사용하는 제 3의 언어(때로는 한 집단의 모어)를 말하며 국가나 단체에서 공식적으로 정한 언어를 뜻하는 공용어와는 다른 개념이다. 정의를 통해 알 수 있듯, 링구아 프랑카는 특정 언어를 지칭하는 표현이 아니라, 언어 가교의 기능을 수행하는 언어들을 통칭하는 표현이다. 여기에서 의미가 파생되어 학술, 상업 등의 특정 분야에서 널리 사용되는 언어라는 뜻으로 사용되기도 한다. 피진이나 크리올은 링구아 프랑카와 유사한 개념이지만 정의상 완전히 일치하지는 않는다. (그러나 대다수가 언어 가교의 기능을 수행하기에 많은 부분 겹친다고 볼 수 있다) - https://ko.wikipedia.org/wiki/%EB%A7%81%EA%B5%AC%EC%95%84_%ED%94%84%EB%9E%91%EC%B9%B4[^2]: HTTP/1은 기본적으로 클라이언트가 서버에 요청을 보내고, 서버가 요청에 대한 응답을 보내는 구조입니다. 따라서 요청 단위로 클라이언트와 서버를 왕복해야 합니다. 또한 쿠키를 포함한 헤더 크기는 불필요하게 큽니다. 이런 특징때문에 HTTP/1은 느립니다. 성능을 개선하기 위해서 구글은 SPDY를 개발하고, 이를 기반으로 HTTP/2 표준이 만들어집니다. 성능이 개선된 HTTP/2의 주요 특징은 아래와 같습니다. Header Compression: Header Table과 Huffman Encoding 기법을 사용하여 HTTP/2 헤더정보를 압축하였습니다. Multiplexed Streams: HTTP/1에서 요청마다 새로운 커넥션을 자주 만드는 것과는 달리 HTTP/2는 한개의 커넥션으로 동시에 여러개의 메시지를 주고 받을 수 있습니다. Server Push: HTTP/2에서는 클라이언트의 요청없이도 서버가 리소스를 보낼 수 있습니다. 클라이언트 요청이 최소화되기 때문에 성능이 향상될 수 있습니다. Stream Priority: 요청에 우선순위를 지정하여 중요한 리소스를 먼저 전달받을 수 있습니다. http://www.http2demo.io/ http://http2.golang.org/gophertiles?latency=1000","categories":[],"tags":[{"name":"gRPC","slug":"gRPC","permalink":"http://icednut.github.io/tags/gRPC/"}]},{"title":"Java9에서의 Stream에 관한 짧은 팁","slug":"20180524-java-stream-tips","date":"2018-05-24T06:07:00.000Z","updated":"2018-11-27T06:40:43.290Z","comments":true,"path":"2018/05/24/20180524-java-stream-tips/","link":"","permalink":"http://icednut.github.io/2018/05/24/20180524-java-stream-tips/","excerpt":"","text":"개요가장 빨리 만나는 코어 자바9 책을 읽다가 실무에서도 많이 쓰일 것 같은 Java9에서의 Stream 다루기가 나오길래 정리!! null이 제거된 Stream 얻기id 목록 스트림이 있고, 아래의 lookup 메소드를 이용하여 얻어진 User 목록 중 null이 제거된 목록 스트림을 얻어내려면 어떻게 할까?Optional&lt;User> lookup(String id); 보통 아래와 같이 작성할 것이다. Stream&lt;String> ids = Stream.of(\"1\", \"2\"); Stream&lt;User> users = ids.map(Users::lookup) .filter(Optional::isPresent) .map(Optinal::get); 하지만 flatMap을 이용하면 좀 더 우아하게 작성할 수 있다. Stream&lt;User> users = ids.map(Users::lookup) .flatMap(Optional::stream); 이렇게 stream으로 변환하면 각 stream 호출은 User 인스턴스가 없거나 혹은 1개로 구성된 stream을 반환한다. 그 후 flatMap 메소드에서 이 스트림들을 결합하면 null인 user 인스턴스는 제거되어 처리된다. 라고 책에서 봤는데 실제로 그런가 해서 코드를 뜯어봤더니 flatMap 메소드를 호출한다고 해서 null 인스턴스가 그 즉시 제거되는 것은 아니었다. 정확히 말하자면 결과를 모으는 작업, 즉 collect 메소드를 호출할 때 flatMap의 파라미터로 들어온 Function 람다를 실행(apply 메소드 호출)을 하게 된다. 이 때 람다는 위에서 작성한 Optaion&lt;User&gt;를 Stream&lt;User&gt;로 변환하는 람다인데 null 인스턴스를 품고 있는 Optional일 경우 Stream.empty()을 통해 빈 스트림으로 변환하고 결과를 모으는 Spliterator는 EmptySpliterator로 결정되어 결국엔 결과를 모으는 작업에서 제외된다. 그렇기 때문에 결국 null인 user 인스턴스가 제거된다. 뭔 소리여? 일단 아래와 같이 flatMap 메소드까지 호출해서 얻어낸 stream은 결과가 처리되기를 기다리고 있는 stream 인스턴스가 반환된다. Stream&lt;User> users = ids.map(Users::lookup) .flatMap(Optional::stream); 아래와 같이 collect 메소드를 호출해야지만 map과 flatMap에 주어진 람다를 호출해서 걸러진 결과가 ArrayList로 모아진다. 이렇게 결과를 모을 때 처리과정을 살펴보자. List&lt;User> users = ids.map(Users::lookup) .flatMap(Optional::stream) .collect(Collectors.toList()); 일단 map은 생략하고 flatMap 메소드의 코드를 살펴보자. ids는 Array의 stream이기 때문에 ReferencePipeline.Head 인스턴스로 시작되는 스트림으로 결정된다. 이후 map을 거쳐 flatMap으로 들어오면 ReferencePipeline에 있는 flatMap 메소드를 호출하게 된다. abstract class ReferencePipeline&lt;P_IN, P_OUT> extends AbstractPipeline&lt;P_IN, P_OUT, Stream&lt;P_OUT>> implements Stream&lt;P_OUT> { ... @Override public final &lt;R> Stream&lt;R> flatMap(Function&lt;? super P_OUT, ? extends Stream&lt;? extends R>> mapper) { Objects.requireNonNull(mapper); // We can do better than this, by polling cancellationRequested when stream is infinite return new StatelessOp&lt;P_OUT, R>(this, StreamShape.REFERENCE, StreamOpFlag.NOT_SORTED | StreamOpFlag.NOT_DISTINCT | StreamOpFlag.NOT_SIZED) { @Override Sink&lt;P_OUT> opWrapSink(int flags, Sink&lt;R> sink) { return new Sink.ChainedReference&lt;P_OUT, R>(sink) { @Override public void begin(long size) { downstream.begin(-1); } @Override public void accept(P_OUT u) { try (Stream&lt;? extends R> result = mapper.apply(u)) { // We can do better that this too; optimize for depth=0 case and just grab spliterator and forEach it if (result != null) result.sequential().forEach(downstream); } } }; } }; } ... } 이 때 flatMap 메소드의 22번째 줄인 try (Stream&lt;? extends R&gt; result = mapper.apply(u))라는 코드 실행되는데 이 코드를 실행하면 앞에서 파라미터로 넘겨준 Optional::stream 메소드 레퍼런스가 실행된다. 이후 다음과 같이 실행된다. user 인스턴스를 품고 있는 Optional 인스턴스 일 때 해당 Optional 인스턴스는 Stream.of(user)로 변환 user 인스턴스를 처리할 수 있는 spliterator 인스턴스를 갖고 있는 stream으로 결정 .collect(Collector.toList) 실행 시 해당 spliterator 인스턴스를 실행하여 user 인스턴스를 ArrayList에 add하여 결과를 모은다. null을 품고 있는 Optional 일 때 해당 Optional 인스턴스는 Stream.empty()로 변환 이 스트림은 EmptySpliterator를 갖고 있는 stream으로 결정 .collect(Collector.toList) 실행 시 EmptySpliterator 인스턴스를 처리하면 해당 스트림에는 처리할 요소가 없으므로 ArrayList에는 아무런 인스턴스도 add하지 않고 끝난다. 정리하자면 결과를 모으는 작업을 호출해야지 빈 스트림에 대해 아무런 처리하지 않고 넘어간다. 이번에는 lookup 메소드가 null을 반환할 수 있는 경우라면 stream 처리를 어떻게 할까?User classicLookup(String id); 이럴 때 보통 아래와 같이 filter 메소드를 통해 null 인스턴스를 필터링할 것이다. Stream&lt;User> users = ids.map(Users::classicLookup) .filter(Objects::nonNull); 하지만 jdk9을 쓴다면 아래와 같이 null을 Stream으로 변환하여 처리하면 아까와 같이 null인 요소는 건너뛰고 결과를 모을 수 있다. Stream&lt;User> users = ids.flatMap(id -> Stream.ofNullable(Users.classicLookup(id))); Stream&lt;User> users = ids.map(Users::classLookup) .flatMap(Stream::ofNullable); 스트림 결과 모으기를 할 때 합계, 카운트, 평균, 최댓값, 최솟값으로 모으려면?jdk9을 쓴다면 summarizing(Int|Long|Double) 메소드를 사용하여 SummaryStatistics 타입의 인스턴스를 받아서 처리하면 간단하게 구할 수 있다. 이 메서드는 스트림 객체를 숫자로 매핑하는 함수를 받고 합계, 카운트, 평균, 최댓값, 최솟값을 동시에 계산해서 (Int|Long|Double)SummaryStatistics 타입으로 결과를 돌려준다. IntSummaryStatistics summary = stream.collect( Collectors.summarizingInt(String::length) ); double averageWordLength = summary.getAverage(); double maxWordLegnth = summary.getMax(); 출처 가장 빨리 만나는 코어 자바9 p.320, p.322","categories":[],"tags":[{"name":"java9","slug":"java9","permalink":"http://icednut.github.io/tags/java9/"},{"name":"stream","slug":"stream","permalink":"http://icednut.github.io/tags/stream/"}]},{"title":"To-Do App 개발을 통한 Observer Pattern 이해하기 (javascript 버전)","slug":"20180412-understanding-observer-pattern","date":"2018-04-11T16:37:54.000Z","updated":"2018-11-27T06:40:43.300Z","comments":true,"path":"2018/04/12/20180412-understanding-observer-pattern/","link":"","permalink":"http://icednut.github.io/2018/04/12/20180412-understanding-observer-pattern/","excerpt":"","text":"다룰 내용 앞에서 Reverse Visitor 패턴까지 적용한 To-Do 앱의 개선할 부분이 있는지 파악 개선에 대해 Observer Pattern을 적용할 예정 나머지는 나중에 작성 예정…","categories":[],"tags":[{"name":"design pattern","slug":"design-pattern","permalink":"http://icednut.github.io/tags/design-pattern/"},{"name":"observer pattern","slug":"observer-pattern","permalink":"http://icednut.github.io/tags/observer-pattern/"}]},{"title":"중국커머스 서비스 개발기 세미나 후기","slug":"20180406-chinese-commerce-development-experience-seminar","date":"2018-04-06T01:58:35.000Z","updated":"2018-11-27T06:40:43.288Z","comments":true,"path":"2018/04/06/20180406-chinese-commerce-development-experience-seminar/","link":"","permalink":"http://icednut.github.io/2018/04/06/20180406-chinese-commerce-development-experience-seminar/","excerpt":"","text":"얼마전 회사에 ‘김형준’님께서 오셔서 ‘중국 커머스 서비스 개발기’라는 제목으로 약 2시간 동안 세미나를 하셨다. 어디서 많이 본 얼굴인데 하고 긴가민가 했는데 알고보니 Popit에 기고를 하고 계셨던 분이었다. 평소에도 그 분 글을 재미있게 보고 있었는데 우리회사에서 세미나를 하신다니 와!!! (popit 관련 글: http://www.popit.kr/author/babokim/) 아무튼 세미나 내용은 중국 개발업체로 파견 나가셔서 개발자 약 50명을 이끌고 서비스 개선 및 광군제(쐉쓰이) 대응에 관해 어떤 식으로 진행했는지에 대한 말씀을 해주셨는데 쉽고 재미있게 설명해주셔서 개인적으로 상당히 감명깊었다. 굳이 커머스 개발을 하지 않아도 대용량 트래픽과 유연한 서비스 대응에 대해 MSA를 고민을 하고 있는 상황이라면 이 세미나에서 영감을 받을 수 있으리라. 그럼 기억력에 의지하여 세미나 때 들은 내용을 적어볼까 한다. 중국 진출 및 처한 상황사실 앞에서 제목이 ‘중국 커머스 서비스 개발기’라고 했지만 원래 세미나 제목은 ‘그럭저럭 돌아가는 서비스 만들기’ 였다. 그럭저럭 돌아가는, 대충 돌아가는 서비스를 중국에서 해봤다 이 말인데 뭐야 중국까지 가서 왜 대충 그럭저럭 돌아가는 서비스를 만들고 온거지 라는 의문 첫 인상이었다. 대충 그럭저럭 돌아간다는 의미가 무엇일까? 대충 그럭저럭 돌아간다는 시스템을 차차 알아가기로 하고, 발표자가 중국 개발업체에 파견을 나가게 되었는데 거기서 받은 미션이 현재 운영 중인 시스템을 경쟁력 있는 시스템으로 만들어달라. 라는 미션이었다고 한다. 그런데 현재 운영 중인 시스템은… Windows Form Stored Procedure SQLServer (Table: 675개) 아키텍처는 심플했지만 시대에 맞는 기민한 대응이 힘들었고 한다. (중복되는 구조의 Stored Procedure가 많았고, 비슷한 이름의 테이블이 많은데다가 특정 테이블의 구조를 변경할 경우 시스템에 미치는 영향을 예측할 수 없었다고 함. 이런 상황에서 요구사항 대응은 힘들었으리라..) 이런 상황에서 기존 서비스를 경쟁력 있는 서비스가 될 수 있도록 개선해야 되는 미션이 있었다고 한다. 그래도 시작은 해야…기존 시스템을 개선하기 전에 어떤식으로 개선할 것인지 기준을 정했는데 아래와 같은 기준을 정했다고 한다. 다른 개발 언어, 플랫폼 다른 운영 환경 기존 시스템과 연결 안하기 특히 놀라웠던 것은 기존에 있던 시스템을 새로운 언어로 다시 개발하기 위해 기존에 일했던 팀원에게 업무 분배를 했는데 아래와 같이 당부를 했다고 한다. 개발자 한 명에 기능 하나 테이블은 1 or 2개 화면 역시 1 or 2개 1주일 동안 무조건 동작하는 것 만들기 하드코딩 허용 HTML 날 코딩 허용 등등 가장 놀라웠던 것은 테이블 간에 JOIN하지 말기 위와 같이 당부하면서 사용하는 기술도 개발자들이 직접 선택하게 하였는데 이는 변화에 자발적인 참여를 유도하고 내 선택이 서비스에 미치는 영향도 느껴보게 하기 위함이었다고 한다. 다수의 개발자들이 멘붕에 빠지고 다소 혼란스러워 보였으나 중국 개발자들은 시키면 어떻게서든 꾸역꾸역하는 끈기가 있었다고 한다. (퀄리티는 만족스럽진 않았지만..) 시행착오 끝에 결국 사용기술은 아래와 같이 결정이 되었다고 한다. 서비스를 개발하기 위해 처음 써본 언어를 공부해 가면서 개발한다는 것은 경영진 입장에선 썩 달가운 모습은 아니었을 것이다. 그렇다고 손 놓고 있으면 미션을 달성할 수 없지 않은가? 이들이 중요하게 생각하는 것은 지금 이게 뭔지 이해는 할 수 없어도 돌아가는 어떤 것을 빨리 만드는 것. 그리고 개발이 끝나면 회고는 하지 않지만 만들었던 것을 잊고 다시 한 번 또 만들면서 개선해보는 것, 이 두 가지를 중요하게 생각하고 실천 했다고 한다. 그러면서 개발자 전체가 조금씩 성장할 수는 있었지만 여전히 한계는 존재했고 사건 사고도 있었다고 한다. (자세한 사고는 생략) 그들이 했던 MSAMicro Service Architecture는 쉬운 아키텍처가 아니고 개발 성숙도가 높은 조직에서나 적용해야 성공적으로 운영할까 말까 한다고 한다. 그런데 그들은 기능을 잘게 나누고 기능만 나눈 것 뿐만 아니라 물리적으로도 서비스를 잘게 나누었다. 결국 기능 하나하나가 Microservice 였던 것이다. 왜 그렇게 했을까? 현재 개발 조직의 능력으로 할 수 있는 최선이 작게 만드는 것 위와 같은 이유 였다고 한다. 즉 현재 상황에서 최선을 선택한 것이다. (의도치 않게 MSA를 하게 됨) Microservice를 실제로 하면서 가장 큰 장벽은 아래와 같았다고 한다. JOIN 없이 기능을 개발하는 것 떄문에 여러 서비스 호출을 하나의 Transaction으로 묶을 수 없었음 너무 많은 고민/걱정 서비스 단위는 어떻게 쪼갤가.. 트렌젝션 장애 처리는 어떻게… 서비스 간 의존/호출 관계가 복잡해지면 어떻게 할까? JOIN이 없이 개발한다는 것은 서비스 간에 서로의 데이터가 필요한 순간이 있을텐데 이런 상황이 발생할 경우 두 서비스에 같은 테이블을 두고 같은 데이터를 쌓도록 했다고 한다. 중복처럼 보일 수 있지만 한 서비스에서는 해당 테이블에 데이터를 쌓은 뒤 이벤트를 발생시키고 다른 서비스에서는 그 이벤트를 구독해서 데이터를 복사해오는 방식으로 개발했다고 한다. 이렇게 각 서비스별로 중복되는 데이터를 갖고 있게 되거나 서비스 간에 데이터 정합성이 안맞는 문제가 발생할 수도 있지만 서비스간에 조인을 해야되는 골치아픈 상황은 피할 수 있게 되었다고 한다. 또 트렌젝션 처리는 안하는 것으로 하였는데 이는 비용에 따른 선택 이었다고 한다. 트렌젝션을 엄격하게 지키면서 광군제와 같은 대용량 트래픽이 몰리는 이벤트를 처리할 수 있을까? MSA를 하게 되면 빠지지 않고 따라오는 개념이 바로 Event Driven이다. 서비스 간에 통신은 이벤트 드리븐으로 하게 되면 서비스 고유의 역할에만 집중할 수 있게 되고 서비스 플로우에 대한 오류는 관련 있는 서비스만 처리하게 되는 구조가 되게 된다. 거기다가 이벤트 드리븐 특성 상 이러한 일들은 비동기(Async)로 동작하게 된다. (ex: A 서비스에서 처리가 끝나면 Event Queue에 이벤트 전송 -&gt; B 서비스에서 받아가서 처리) 특히 이 부분에서 좀 감명 깊었는데 실제로 MSA를 하다보니 아래와 같이 MSA가 쉽지 않은 것이라는 것을 몸소 체득하게 되었다고 한다. 그리고 MSA를 하면서 모든 서비스에 대해 모니터링이 필요한데 모니터링을 하기 위해서는 로그가 중요하다. 모든 서비스에서 발생하는 로그, 이벤트를 기록했는데 눈에 띄는 것은 모든 로그를 HDFS에 저장하고 Presto로 이벤트 및 로그를 제플린에서 질의하고 있었다. 또 감명깊었던 부분은 모든 서비스 플로우에 대해 Requst ID를 부여하여 request를 추적할 수 있도록 로그를 남겼다는 점이다. 예를들어 서비스 플로우 A가 있으면 A에 해당하는 서비스가 ㄱ 서비스, ㄴ 서비스, ㄷ 서비스가 있으면 request가 서비스를 거칠 때 마다 requestID를 부여하고 덧붙이는 방식이었다. 이렇기 떄문에 서비스 플로우 A에 대한 콜 스택이 어떻게 되는지 추적도 할 수 있고 어느 서비스에서 오류가 발생해서 그 다음 서비스로 못넘어 갔는지도 모니터링이 가능했다고 한다. 더 나아가 이러한 데이터를 바탕으로 실시간 모니터링 툴까지 개발한 모습도 보여주었다. 마치며..MSA를 하면서 오류가 발생하는 것은 어쩔 수 없다. 그런데 이들은 어쩔 수 없음을 윗선(경영진)에서 부터 공감하고 허용하고 있었다. 오류는 즉 매출에 영향이 있음에도 불구하고 이런 인식을 갖고 있던 것은 무엇일까? 중국의 많은 인구로 인한 대규모 트래픽과 기민한 서비스 대응만이 살아남는 구조이기 때문에 오류가 발생해도 매출 발생 대응이 중요했기 때문이라고 본다. 이러한 상황이 애자일을 할 수 밖에 없는 상황이 된 것으로 본다. 우리나라 정서에는 안맞는 부분이 있을 수도 있겠지만 배울건 있다고 본다. MSA를 하기 위해 공부를 멈추지 말아야 겠다. 참고 자료 http://www.popit.kr/%EB%8C%80%EC%9A%A9%EB%9F%89-%ED%99%98%EA%B2%BD%EC%97%90%EC%84%9C-%EA%B7%B8%EB%9F%AD%EC%A0%80%EB%9F%AD-%EB%8F%8C%EC%95%84%EA%B0%80%EB%8A%94-%EC%84%9C%EB%B9%84%EC%8A%A4-%EB%A7%8C%EB%93%A4%EA%B8%B0/ http://www.popit.kr/micro-service-docker%EB%A1%9C-%ED%95%A0-%EC%88%98-%EB%B0%96%EC%97%90-%EC%97%86%EC%97%88%EB%8D%98-%EC%82%AC%EC%97%B0/ http://www.popit.kr/author/babokim/page/2/","categories":[],"tags":[{"name":"microservice","slug":"microservice","permalink":"http://icednut.github.io/tags/microservice/"}]},{"title":"To-Do App 개발을 통한 Visitor Pattern 이해하기 (javascript 버전)","slug":"20180329-understanding-visitor-pattern","date":"2018-03-29T11:04:52.000Z","updated":"2018-11-27T06:40:43.292Z","comments":true,"path":"2018/03/29/20180329-understanding-visitor-pattern/","link":"","permalink":"http://icednut.github.io/2018/03/29/20180329-understanding-visitor-pattern/","excerpt":"","text":"다룰 내용 앞에 Composite Pattern이 적용된 To-Do 앱의 문제점이 뭐고 어떻게 해결할지 진행 문제점 해결에는 Visitor Pattern과 Reverse Visitor를 사용할 예정 왜 Visitor Pattern인가?앞서 To-Do App 개발 시 할 일(Task)에 관련된 행위를 Composite Pattern으로 구현하였다. 그런데 이 코드에는 문제점이 있다. 바로 Composite이 전파된다는 점이다. Composite가 전파된다는게 무슨 의미인지 살펴보자. Composite 전파먼저 Task, TaskList, TaskItem은 Composite Pattern으로 구현하여 Task의 getResult() 이라는 함수에서 할 일 목록을 가져오는 행위 중 자식에게 너 자신(TaskItem)과 너의 자식 목록(TaskList)을 데이터를 가져오는 행위 즉 재귀 확산 호출을 통한 데이터 구성하는 행위가 추상화 되어 있다. 그런데 문제는 이렇게 가져온 데이터를 그리는 Renderer에서도 Task 데이터를 그릴 때 데이터를 참조하여 그리는 로직 또한 Composite Pattern으로 구현해야 된다는 점이다. 이것을 Composite가 전파된다 라고 표현하는데 이건 따지고 보면 Composite으로 인한 중복코드 생성이다. const Task = class{ ... getResult(sort, stateGroup){ const list = this._list; return { item: this, children: (!stateGroup ? [...list].sort(sort) : [ ...list.filter(v=>!v.isComplete()).sort(sort), ...list.filter(v=>v.isComplete()).sort(sort) ]).map(v=>v.getResult(sort, stateGroup)) // 여기가 Composite 핵심 부분 }; } ... }; Task가 Composite 구조이기 때문에 DomRenderer에서도 그릴 떄 Composite 구조를 따라감 const DomRenderer = class{ constructor(list, parent){ this._list = list; this._parent = parent; this._sort = 'title'; } render(){ const list = this._list; const parent = this._parent; parent.innerHTML = ''; parent.appendChild( 'title,date'.split(',').reduce((nav, c)=>{ nav.appendChild( el('button', 'innerHTML', c, '@fontWeight', this._sort == c ? 'bold' : 'normal', 'addEventListener', ['click', e=>(this._sort = Task[c], this.render())] ) ); return nav; }, el('nav')) ); this._render(parent, this._list, this._list.getResult(Task[this._sort]), 0); // 여기에서 Task의 getResult 함수를 호출해서 Composite 구조의 Task를 요청 } _render(base, parent, {item, children}, depth){ const temp = []; base.style.paddingLeft = depth * 10 + 'px'; if (item instanceof TaskList){ temp.push( el('h2', 'innerHTML', item._title) ); } else { temp.push( el('h3', 'innerHTML', item._title), el('time', 'innerHTML', item._date.toString(), 'datetime', item._date.toString()), el('button', 'innerHTML', item.isComplete() ? 'progress' : 'complete', 'addEventListener', ['click', _=>this.toggle(item)] ), el('button', 'innerHTML', 'remove', 'addEventListener', ['click', _ => this.remove(parent, item)] ) ); } const sub = el('section', 'appendChild', el('input', 'type', 'text'), 'appendChild', el('button', 'innerHTML', 'addTask', 'addEventListener', ['click', e => this.add(item, e.target.previousSibling.value)] ) ); children.forEach(v=>this._render(sub, item, v, depth + 1)); // 이 부분이 바로 Composite 구조 temp.push(sub); temp.forEach(v=>base.appendChild(v)); } ... } 또 DomRenderer에서 Composite Pattern으로 Task를 순회하면서 데이터를 가져와 그리는 로직을 ConsoleRenderer를 구현할 때도 마찬가지로 비슷한 로직을 구현해야 된다. 이렇게 보면 중복코드 작업은 비효율 적이라는 것이 불보듯 뻔하다. 해결 방법은?위 문제의 원인은 Renderer에서 Task 데이터를 그릴 때 Composite Pattern으로 순회하여 데이터를 참조하는 것이 원인이다. 이걸 해결하기 위해서는 Renderer에서 Task 데이터 참조와 그리기(render) 행위를 분리해야 한다. 그런 다음 Task 데이터 참조하는 행위는 Task 클래스에게, 그리기 행위는 Visitor 클래스에게 위임하여 Task 데이터 참조를 하는 행위가 발생하면 그 행위 안에서 Visitor에 위임된 행위를 실행하게 하면 되는 것이다. (왜냐면 Visitor 클래스에 그리는 행위가 위임되어 있기 때문) 이렇게 Composite Pattern이 나올 때는 꼭 Visitor Pattern이 따라온다고 보면 된다. (Composite 전파를 막기 위해) 글만 보면 이해가 안가니 코드를 통해 살펴보도록 하자. Step 1. To-Do App에 Visitor Pattern 적용하기Visitor를 한 줄로 요약하자면 다음과 같다. 나를 데려가면 날 데려간 곳에서 내가 무언가를 할게 무슨 뚱딴지 같은 소리란 말인가? 일단 이 말의 의미를 알기 위해 앞에서 작성한 것과 같이 실행코드 부터 시작해서 Composite Pattern이 적용된 Renderer에 그리기 관련 행위를 Visitor로 분리하는 작업을 진행해보자. 실행코드const list1 = new TaskList('s75'); const item1 = new TaskItem('3강 교안 작성'); list1.add(item1); const sub1 = new TaskItem('코드정리'); item1.add(sub1); const subsub1 = new TaskItem('subsub1'); sub1.add(subsub1); // Visitor Pattern 적용 전 const todo = new DomRenderer(list1, sel('#todo')); todo.render(); // Visitor Pattern 적용 후 const todo = new Renderer(list1, new DomVisitor('#todo')); todo.render(); 실행 코드 중에 눈에 띄는 것은 Renderer 클래스와 생성자로 들어가있는 DomVisitor 클래스이다. 전에 Visitor Pattern을 적용하기 전 Composite Pattern만 적용되어 있을 때는 DomRenderer를 생성하여 해당 렌더러에 Task 조회 및 Task 그리기 작업을 했었다. Renderer의 그리기에 관한 로직은 DomVistor에 위임되었기 때문에 Renderer 클래스는 공통화할 수 있을 것이다. 때문에 Renderer 클래스의 이름이 그냥 일반적으로 Renderer가 되었다. 앞에서 했던 것처럼 의존성이 없는 Task 클래스부터 작성해보자. Taskconst Task = class { static title(a, b) {return a._title > b._title;} static date(a, b) {return a._date > b._date;} constructor(_title = err(), _date = new Date) { prop(this, { _title, _date, _list: [] }); } get title() { return this._title; } get date() { return this._date.toUTCString(); } add(task) { if (!is(task, Task)) err(); this._list.push(task); } remove(task) { const list = this._list; if (list.includes(task)) list.splice(list.indexOf(task), 1); } getResult(sort, stateGroup = true) { const list = this._list; return { item: this, children: (!stateGroup ? [...list].sort(sort) : [ ...list.filter(v => !v.isComplete()).sort(sort), ...list.filter(v => v.isComplete()).sort(sort) ]).map(v => v.getResult(sort, stateGroup)) }; } isComplete() { override(); } accept(sort, stateGroup, visitor) { visitor.start(sort, stateGroup, this); this.getResult(sort, stateGroup).children.forEach( ({ item }) => item.accept(sort, stateGroup, visitor) ); visitor.end(); } } 우선 앞에서 봤던 Composite Pattern의 Task 클래스와 다른 점은 accept라는 함수가 생긴 점이다. 이 함수의 역할은 Composite 구조를 순회하면서 visitor 객체의 start(), end() 함수를 호출하고 있다. 이렇게 앞 뒤로 무언가 호출하는 이런 구조를 라이프 사이클이라고 한다. 여기서는 Composite 구조 순회의 앞 뒤로 visitor를 호출하고 있다. 이것만 봤을 때는 visitor.start()에서 그림을 그리는 로직이나 글씨로 표현하는 로직 등과 같이 render 로직이 들어가고 순회 완료 후 visitor.end() 함수에서 마무리 작업을 할 것으로 보인다. const TaskItem = class extends Task { constructor(title, date) { super(title, date); this._isComplete = false; } isComplete() { return this._isComplete; } toggle() { this._isComplete = !this._isComplete; } }; const TaskList = class extends Task { constructor(title, date) { super(title, date); } isComplete() { } }; 그 외 Task 클래스의 자식인 TaskItem과 TaskList 클래스는 변함없다. (부모에서 이미 추상화된 Composite이 있어 이를 재사용하고 있기 때문) RendererRenderer는 태스크와 협조하여 태스크에 대한 그림을 그릴 수 있는 visitor를 호출하는 행위를 추상화 한 것이다. 그리는 행위가 visitor로 위임 되었기 때문에 Renderer는 Composite을 조회하고 visitor를 Composite에 연결해주는 행위만 남게 된다. 이건 모든 Renderer의 공통 로직이기 때문에 의존성이 사라진 순수한 Renderer 클래스 로직만 남게 된다. const Renderer = class { constructor(_list = err(), _visitor = err()) { prop(this, { _list, _visitor: prop(_visitor, { renderer: this }), _sort: 'title'}); } add(parent, title, date) { if (!is(parent, Task)) err(); parent.add(new TaskItem(title, date)); this.render(); } remove(parent, task) { if (!is(parent, Task) || !is(task, Task)) err(); parent.remove(task); this.render(); } toggle(task) { if (!is(task, TaskItem)) err(); task.toggle(); this.render(); } render() { this._visitor.reset(); this._list.accept(Task[this._sort], true, this._visitor); } } Visitorvisitor의 부모를 먼저 정의해보자. const Visitor = class{ set renderer(v) {this._renderer = v;} reset(){ovreride();} start(task){ovreride();} end(){ovreride();} } 이렇게 정의된 Visitor 클래스를 요구사항에 맞게 구현하여 Composite 클래스에 연결해주면 된다. 그럼 앞에서 Dom 형태로 Todo를 그렸던 DomRenderer에서 Dom을 그리는 로직만 따로 분리하여 DomVisitor 클래스를 구현한다. const DomVisitor = class extends Visitor { constructor(_parent) { super(); prop(this, { _parent }); } reset() { this._current = el(sel(this._parent), 'innerHTML', ''); } start(sort, stateGroup, task) { if (!is(this._renderer, Renderer)) err(); switch(true) { case is(task, TaskItem): this._item(task); break; case is(task, TaskList): this._list(task); break; } this._current = this._current.appendChild(el('section', '@marginLeft', '15px', 'appendChild', el('input', 'type', 'text'), 'appendChild', el('button', 'innerHTML', 'addTask', 'addEventListener', ['click', e => this._renderer.add(task, e.target.previousSibling.value)] ) )); } end() { this._current = this._current.parentNode; } _list(task) { this._current.appendChild(el('h2', 'innerHTML', task.title)); } _item(task) { [el('h3', 'innerHTML', task.title, '@textDecoration', task.isComplete() ? 'line-through' : 'none'), el('time', 'innerHTML', task.date, 'datetime', task.date), el('button', 'innerHTML', task.isComplete() ? 'progress' : 'complete', 'addEventListener', ['click', _ => this._renderer.toggle(task)]), el('button', 'innerHTML', 'remove', 'addEventListener', ['click', _ => this._renderer.remove(parent, item)] )].forEach(v => this._current.appendChild(v)); } } 이렇게 되면 Rederder에는 더 이상 그리는 로직은 없고 DomVisitor에 위임 되었다. Renderer는 단지 DomVisitor의 라이프사이클 메소드(start, end, reset) 메소드를 호출할 뿐이다. Step 2. Visitor Pattern의 문제 그리고 Reverse Visitor앞에서 Visitor를 사용하는 곳을 다시 살펴보자. Taskconst Task = class { accept(sort, stateGroup, visitor) { visitor.start(sort, stateGroup, this); this.getResult(sort, stateGroup).children.forEach( ({ item }) => item.accept(sort, stateGroup, visitor) ); visitor.end(); } } Rendererconst Renderer = class { render() { this._visitor.reset(); this._list.accept(Task[this._sort], true, this._visitor); } } 뭔가 문제점이 보이지 않는가? 여기서의 문제점은 Task 클래스의 accept 클래스에서 visitor의 라이프 사이클 메소드를 호출하고 있는 것 문제이다. 그럼 이게 왜 문제일까? Task 클래스를 수정 시 라이프 사이클 메소드를 호출하는 로직을 삭제한다던가 변경해버리면 Renderer에게 영향을 끼친다. 즉 Composite 클래스 수정 시 이를 사용하는 쪽에서 영향을 끼친다는 의미이다. 이는 곧 객체지향에 위반 된다. (무슨 법칙을 위반한 걸까?) 그럼 이걸 어떻게 풀어야할까? 답은 간단하다. 라이프사이클 관련 메소드를 Visitor를 사용하는 곳에서 직접 호출하게 하는 것이 아닌 Visitor에서 호출하게 만들면 된다. 라이프사이클 메소드를 Visitor 클래스가 직접 호출하기 때문에 이 Visitor를 Reverse Visitor라고 부르는 것이다. 즉 라이프사이클을 visitor에서 캡슐화 하여 operation 이라는 메소드만 호출하면 visitor가 알아서 라이프 사이클 메소드를 호출하는 것이다. Rendererconst Renderer = class { render() { this._visitor.reset(); this._visitor.operation(Task[this._sort], true, this._list); } } Visitorconst Visitor = class { set renderer(v) { this._renderer = v; } reset() { override(); } operation(sort, stateGroup, task){ this._start(sort, stateGroup, task); task.getResult(sort, stateGroup).children.forEach( ({item}) => this.operation(sort, stateGroup, item) ); this._end(); } _start(task) { override(); } _end() { override(); } }; 대신에 Reverse Visitor를 적용하게 되면 Visitor 안에서 다시 Composite의 메소드(task.getResult)를 호출하게 되고 Visitor 자신도 Composite 구조가 되어버린다. (Composite 자료구조를 순회하면서 라이프사이클이 캡슐화된 메소드 operation을 호출해야 되기 때문) Composite를 피하려고 했는데 Reverse Visitor에 다시 Composite 구조를 만들고 있는 셈이다. 따라서 이 부분은 많은 경험에 비추어 변경이 잘 일어나지 않을 부분이겠구나 감이 오면 Visitor만 쓰고 그렇지 않다면 Reverse Visitor를 쓰는 수 밖에 없다.","categories":[],"tags":[{"name":"design pattern","slug":"design-pattern","permalink":"http://icednut.github.io/tags/design-pattern/"},{"name":"visitor pattern","slug":"visitor-pattern","permalink":"http://icednut.github.io/tags/visitor-pattern/"}]},{"title":"To-Do App 개발을 통한 Composite Pattern 이해하기 (javascript, java 버전)","slug":"20180327-understanding-composite-pattern","date":"2018-03-27T07:10:53.000Z","updated":"2018-11-27T06:40:43.287Z","comments":true,"path":"2018/03/27/20180327-understanding-composite-pattern/","link":"","permalink":"http://icednut.github.io/2018/03/27/20180327-understanding-composite-pattern/","excerpt":"","text":"다룰 내용 디자인 패턴 중에 Composite Pattern에 대해 정리 Composite Pattern을 Javascript 버전, Java 버전으로 각각 작성 To-do 앱을 개발한다고 가정하고 해당 패턴을 적용 화면(HTML, CSS)개발은 생략하고 실행코드와 비즈니스 코드만 다룰 예정 들어가기 전에 Composite Pattern은 뭘까? 한 마디로 정의하자면 Tree 메뉴와 같이 재귀호출하여 처리하는 행위를 추상화한 것을 Composite Pattern이라고 한다. 뭔말인지 모르겠으니까 To-Do App을 구현하면서 알아보자. To-Do Domain우선 To-Do App이 뭔지 알아보자. (이것을 To-Do App의 Domain을 알아보자 라고 한다.) TODO 앱은 일단 다음과 같다. 그림을 보면 왼쪽에 뭔가 분류 항목(리스트)가 있고, 오른쪽에는 할 일 항목이 있는 것을 볼 수 있다. 이렇게 화면을 보고 데이터가 어떻게 되어 있을지를 상상해봐야 하는데 이걸 도메인 훈련이라고 부르며 상당한 노력과 경험이 필요하다. (도메인을 보고 완벽하게 데이터로 환원시킬 수 있어야 한다.) 도메인 파악에는 여러 방법론이 있지만 데이터베이스를 바탕으로 도메인을 파악할 경우 그 도메인에서 행위를 명사로 표현할 수 있는 것과 동사로 표현할 수 있는 것으로 나뉜다. 여기서 명사는 엔티티(Entity)라고 부르고 동사는 행동(Behavior)라고 부른다. 엔티티라고 부르는 것은 데이터와 연관이 있다. 위 그림 To-Do App 도메인에서 엔티티는 무엇일까? 일단 왼쪽이나 오른쪽 둘다 공통적으로 보여지는 리스트 엔티티가 있을 것이고, 할 일 항목 하나하나가 엔티티가 보인다. 결국 TaskList와 TaskItem으로 엔티티를 표현할 수 있다. (데이터베이스에서는 이 엔티티가 테이블이 되겠지만 객체지향 세계에서는 클래스가 되고 인스턴스가 된다.) Step1. 실행코드 작성하기To-Do App의 도메인을 알아봤으니 실행 코드를 작성해보자. 실행 코드를 작성하자는 말은 To-Do App을 실행시키는 코드를 작성한다는 의미이다. 왜 실행코드부터 작성할까? 코드는 사람이 사용하기 편한 방향으로 개발해야되는데 실행 코드를 먼저 작성해보면 사용자 측면에서 개발하게 된다. 이렇게 실행하는 코드가 있으면 좋을텐데라고 생각하고 실행코드 부터 작성하면 사용자 측면에서 생각하여 개발하게 된다는 의미이다. 실행코드 말고 프로덕션 코드부터 만드는 것은 똥을 만들 가능성이 커진다. Javascript 버전 - app.jsconst list1 = new TaskList('비사이드'); list1.add('지라설치'); list1.add('지라클라우드접속'); const list2 = new TaskList('s75'); list2.add('2강 답안 작성'); list2.add('3강 교안 작성'); console.log(list1.byTitle()); console.log(list2.byDate()); Java 버전 - Application.javapublic class Application { public static void main(String[] args) { TaskList list1 = new TaskList(\"비사이드\"); list1.add(\"지라설치\"); list1.add(\"지라클라우드 접속\"); TaskList list2 = new TaskList(\"s75\"); list2.add(\"2강 답안 작성\"); list2.add(\"3강 교안 작성\"); System.out.println(list1.byTitle(false)); System.out.println(list2.byDate(false)); } } 작성한 실행코드를 보면서 생각해보자. TaskList 인스턴스를 만들면서 파라미터로 항목의 이름을 넘겼는데 그럼 작성일시는 안넘겨도 될까? 아마 내부적으로 현재 시간으로 셋팅하는게 들어가겠지? 하고 혼자 생각해보면서 실행코드에 뭔가 누락된 부분이 있는지 검토해본다. TaskList의 할일(Task)를 등록하는 함수의 이름을 add라고 지었는데 왜 이렇게 지었을까? 코드 작성에서 작명은 상향식과 하향식이 있는데 상향식은 의미를 넓게 지은뒤 리팩토링하면서 점점 구체적인 의미로 짓는 것이며, 하향식은 그 반대이다. 상향식으로 지어놓으면 추후 추가되는 요구사항에 대한 의미에 유연하게 대응할 수 있으므로 상향식으로 짓는 것이 좋다. (그래서 일단 넓은 의미로 add라고 이름을 지은 것) Step 2. 할 일 등록 및 조회 개발그 다음 할 일을 나타내는 Task 클래스를 먼저 작성하는게 좋을까? 아니면 할 일을 관리하는 TaskList 클래스를 작성하는게 좋을까? 여기서 둘의 관계를 고찰해보면 할일 목록(TaskList)은 할일(Task)을 담고 있기 때문에 TaskList는 Task에 의존성이 있다고 볼 수 있다. 의존성이 없는 엔티티부터 구체화하는 것이 편한데 여기서는 Task가 의존성이 없기 때문에 Task 클래스 부터 작성하는 것이 편하다. 이렇게 도메인만 보고 엔티티의 의존성을 파악하려면 경험이 필요하다. (으…난 솔직히 TaskList 부터 작성하려고 생각하고 있었는데…) 그럼 Task 클래스부터 작성해보자. (할일 제목과 등록 날짜 기준으로 정렬도 할 수 있게 해보자.) task.jsconst Task = class{ constructor(title, date){ if(!title) throw 'invalid title'; this._title = title; this._date = date; this._isComplete = false; } isComplete(){return this._isComplete;} toggle(){this._isComplete = !this._isComplete;} sortTitle(task){ return this._title > task._title; } sortDate(task){ return this._date > task._date; } }; const taskSort = { title:(a, b)=>a.sortTitle(b), date:(a, b)=>a.sortDate(b) } Task.javapublic class Task { private String title; private LocalDateTime date; private boolean isComplete; public Task(String title, LocalDateTime date) { this.title = Optional.ofNullable(title).orElseThrow(() -> new InvalidTitleException()); this.date = date; this.isComplete = false; } public boolean isComplete() { return this.isComplete; } public void toggle() { this.isComplete = !this.isComplete; } public int sortTitle(Task task) { return this.title.compareTo(task.title); } public int sortDate(Task task) { return this.date.compareTo(task.date); } } class TaskSort { private Map&lt;String, Comparator&lt;Task>> sortMethods; public TaskSort() { this.sortMethods = new HashMap&lt;>(); sortMethods.put(\"title\", (a, b) -> a.sortTitle(b)); sortMethods.put(\"date\", (a, b) -> a.sortDate(b)); } public Comparator&lt;Task> getSortMethod(String sortType) { return sortMethods.get(sortType); } } Task 클래스를 살펴보면 할일을 완료했는지 여부에 대한 _isComplete라는 필드도 보이고 이걸 toggle() 함수를 통해 값을 변경하는 것을 볼 수 있다. 이렇게 Task의 완료를 toggle() 함수를 통해 제어(_isComplete의 값을 변경)하는 것을 캡슐화라고 한다. 또 다른 캡슐화로는 TaskSort가 있는데 여기에는 Task 제목(title)로 정렬할 것인지, 등록일시(date)로 정렬할 것인지에 대한 행위만 들어있다. 그 구체적인 행위는 Task에게 위임하고 TaskSort의 title과 date 필드의 value는 뭘 기준으로 정렬하는 것인지에 대한 행위만 들어있다. Task에 위임된 sortTitle과 sortDate 함수를 보면 정렬에 필요한 정렬 비교 기준 로직이 들어있다. 이렇게 정렬에 대한 핵심 로직은 감춰진채 Task에서는 정렬에 관한 인터페이스(함수)만 노출한 것도 캡슐화라고 할 수 있다. 이제 할 일 목록(TaskList)를 작성해보자. Task에서 준비한 할일 제목(title), 등록날짜(date)에 대한 정렬을 실행할 수 있는 인터페이스를 TaskList에서 제공한다. title과 date에 따라 소팅하는 로직을 태스크가 갖고 있는 것은 객체지행에 위배되기 때문이다. 그러므로 TaskList에서 제공한 정렬 관련 함수는 Task에게 정렬에 대한 핵심 로직을 위임하여 TaskList는 실행만 하게 한다. task_list.jsconst TaskList = class{ constructor(title){ if(!title) throw 'invalid title'; this._title = title; this._list = []; } add(title, date = Date.now()){this._list.push(new Task(title, date));} remove(task){ const list = this._list; if(list.include(task)) list.splice(list.indexOf(task), 1); } byTitle(stateGroup = true){return this._getResult('title', stateGroup);} byDate(stateGroup = true){return this._getResult('date', stateGroup);} _getResult(sort, stateGroup){ const list = this._list, s = taskSort[sort]; return !stateGroup ? [...list].sort(s) : [ ...list.filter(v=>!v.isComplete()).sort(s), ...list.filter(v=>v.isComplete()).sort(s) ] } } TaskList.javapublic class TaskList { private String title; private List&lt;Task> list; public TaskList(String title, List&lt;Task> list) { this.title = title; this.list = new ArrayList&lt;>(); } public void add(String title, LocalDateTime date) { this.list.add(new Task(title, date)); } public void add(String title) { add(title, LocalDateTime.now()); } public void remove(Task task) { if (list.contains(task)) { list.remove(task); } } public List&lt;Task> byTitle(boolean stateGroup) { return this.getResult(\"title\", stateGroup); } public List&lt;Task> byDate(boolean stateGroup) { return this.getResult(\"date\", stateGroup); } private List&lt;Task> getResult(String sortType, boolean stateGroup) { TaskSort taskSort = new TaskSort(); Comparator&lt;Task> sortMethod = taskSort.getSortMethod(sortType); return !stateGroup ? list.stream().sorted(sortMethod).collect(Collectors.toList()) : new ArrayList&lt;>() {{ this.addAll(list.stream().filter(v -> !v.isComplete()).sorted(sortMethod).collect(Collectors.toList())); this.addAll(list.stream().filter(v -> v.isComplete()).sorted(sortMethod).collect(Collectors.toList())); }}; } } Step 2. Class Diagram Step 2. 결과물javascript https://github.com/icednut/design-pattern-study/tree/master/composite_pattern/javascript/step_02 java https://github.com/icednut/design-pattern-study/tree/master/composite_pattern/java/step2 Step 3. 태스크 하위로 태스크 달기 구현 요구사항이 추가되어서 태스크 하위로 태스크 목록을 볼 수 있어야 한다고 하자. 뭐 일단 하위로 얼만큼 달리는지는 생각하지 말고 1단만 달린다고 해보자. 실행코드는 아마 다음과 같을 것이다. app.jsconst list1 = new TaskList('비사이드'); list1.add('지라설치'); list1.add('지라클라우드 접속'); const list2 = new TaskList('s75'); list2.add('2강 답안 작성'); list2.add('3강 교안 작성'); const list = list2.byDate(); list[1].task.add('코드 정리'); list[1].task.add('다이어그램정리'); console.log(list2.byDate()[1].sub); Application.javapublic class Application { public static void main(String[] args) { TaskList list1 = new TaskList(\"비사이드\"); list1.add(\"지라설치\"); list1.add(\"지라클라우드 접속\"); TaskList list2 = new TaskList(\"s75\"); list2.add(\"2강 답안 작성\"); list2.add(\"3강 교안 작성\"); TaskList list = list2.byDate(false); list.get(1).getTask().add(\"코드 정리\"); list.get(1).getTask().add(\"다이어그램정리\"); System.out.println(list2.byDate(false).get(1).sub); } } 자, 앞에서 하던대로 Task 부터 고쳐보자. Task 밑에 Task 목록이 달려야 하니까 TaskList를 멤버로 갖고 있어야 할 것이다. 그러면 자연스레 TaskList에 관련된 로직이 Task에 들어가게 된다. 왜? TaskList에 항목을 추가하는 행위(add)나 Task 밑에 하위로 항목을 추가한 행위가 같기 때문이다. task.jsconst Task = class{ constructor(title, date){ if(!title) throw 'invalid title'; this._title = title; this._date = date; this._isComplete = false; this._list = []; } add(title, date = Date.now()){this._list.push(new Task(title, date));} remove(task){ const list = this._list; if(list.includes(task)) list.splice(list.indexOf(task), 1); } _getResult(sort, stateGroup){ const list = this._list, s = taskSort[sort]; return { task:this sub:!stateGroup ? [...list].sort(s) : [ ...list.filter(v=>!v.isComplete()).sort(s), ...list.filter(v=>v.isComplete()).sort(s) ] }; } isComplete(){return this._isComplete;} toggle(){this._isComplete = !this._isComplete;} sortTitle(task){return this._title > task._title;} sortDate(task){return this._date > task._date;} }; Task.javapublic class Task { private String title; private LocalDateTime date; private boolean isComplete; private List&lt;Task> list; public Task(String title, LocalDateTime date) { this.title = Optional.ofNullable(title).orElseThrow(() -> new InvalidTitleException()); this.date = date; this.isComplete = false; this.list = new ArrayList&lt;>(); } public void add(String title, LocalDateTime date) { this.list.add(new Task(title, date)); } public void add(String title) { add(title, LocalDateTime.now()); } public void remove(Task task) { if (list.contains(task)) { list.remove(task); } } private TaskWrapper getResult(String sortType, boolean stateGroup) { TaskSort taskSort = new TaskSort(); Comparator&lt;Task> sortMethod = taskSort.getSortMethod(sortType); List&lt;Task> sub = !stateGroup ? list.stream().sorted(sortMethod).collect(Collectors.toList()) : new ArrayList&lt;>() {{ addAll(list.stream().filter(v -> !v.isComplete()).sorted(sortMethod).collect(Collectors.toList())); addAll(list.stream().filter(v -> v.isComplete()).sorted(sortMethod).collect(Collectors.toList())); }}; return new TaskWrapper(this, sub); } public boolean isComplete() { return this.isComplete; } public void toggle() { this.isComplete = !this.isComplete; } public int sortTitle(Task task) { return this.title.compareTo(task.title); } public int sortDate(Task task) { return this.date.compareTo(task.date); } public static class TaskWrapper { private final Task task; private final List&lt;Task> sub; public TaskWrapper(Task task, List&lt;Task> sub) { this.task = task; this.sub = sub; } public Task getTask() { return task; } public List&lt;Task> getSub() { return sub; } } } class TaskSort { private Map&lt;String, Comparator&lt;Task>> sortMethods; public TaskSort() { this.sortMethods = new HashMap&lt;>(); sortMethods.put(\"title\", (a, b) -> a.sortTitle(b)); sortMethods.put(\"date\", (a, b) -> a.sortDate(b)); } public Comparator&lt;Task> getSortMethod(String sortType) { return sortMethods.get(sortType); } } Task 클래스에 add(), remove(), _getResult()가 추가된 것을 볼 수가 있는데 이는 TaskList에 있던 코드와 동일하다. 그럼 이제 TaskList 클래스를 정리해보자. 어떻게? TaskList에서 할일 목록을 가져오는 함수인 _getResult() 함수를 호출 할 때 이제 Task의 _getResult() 함수도 호출해서 Task에 소속된 Task 목록을 가져오면 되는 것이다. TaskList 클래스는 하위 항목이 달린 Task를 어떻게 표현할지에 대한 로직은 관심이 없게 한다. 그건 Task에게 위임하고 Task의 _getResult 함수만 호출하면 하위가 달린 Task는 하위를 알아서 구성하게 하여 캡슐화 한다. 이걸 TaskList와 Task의 내부거래라고 한다. 왜 내부거래인가? 실행코드에서는 이런 TaskList와 Task의 항목 구성 방법을 알지 못한다. 그저 내부적으로 TaskList 그리고 Task만 알고 그에 대한 처리를 할 뿐이다. 그래서 내부거래라고 한다. 이걸 코드로 풀어보자. task_list.jsconst TaskList = class{ constructor(title){ if(!title) throw 'invalid title'; this._title = title; this._list = []; } add(title, date = Date.now()){this._list.push(new Task(title, date));} remove(task){ const list = this._list; if(list.includes(task)) list.splice(list.indexOf(task), 1); } byTitle(stateGroup = true){return this._getResult('title', stateGroup);} byDate(stateGroup = true){return this._getResult('date', stateGroup);} _getResult(sort, stateGroup){ const list = this._list, s = taskSort[sort]; return (!stateGroup ? [...list].sort(s) : [ ...list.filter(v=>!v.isComplete()).sort(s), ...list.filter(v=>v.isComplete()).sort(s) ]).map(v=>v._getResult()); } }; TaskList.javapublic class TaskList { private String title; private List&lt;Task> list; public TaskList(String title) { this.title = title; this.list = new ArrayList&lt;>(); } public void add(String title, LocalDateTime date) { this.list.add(new Task(title, date)); } public void add(String title) { add(title, LocalDateTime.now()); } public void remove(Task task) { if (list.contains(task)) { list.remove(task); } } public List&lt;Task.TaskWrapper> byTitle(boolean stateGroup) { return this.getResult(\"title\", stateGroup); } public List&lt;Task.TaskWrapper> byDate(boolean stateGroup) { return this.getResult(\"date\", stateGroup); } private List&lt;Task.TaskWrapper> getResult(String sort, boolean stateGroup) { TaskSort taskSort = new TaskSort(); Comparator&lt;Task> sortMethod = taskSort.getSortMethod(sort); List&lt;Task> tasks = new ArrayList&lt;>(); tasks.addAll(list.stream().filter(v -> !v.isComplete()).sorted(sortMethod).collect(Collectors.toList())); tasks.addAll(list.stream().filter(v -> v.isComplete()).sorted(sortMethod).collect(Collectors.toList())); return !stateGroup ? list.stream().sorted(sortMethod).map((Task v) -> v.getResult(sort, stateGroup)).collect(Collectors.toList()) : tasks.stream().map((Task v1) -> v1.getResult(sort, stateGroup)).collect(Collectors.toList()); } } TaskList를 보면 .map(v=&gt;v._getResult()); 라는 코드가 추가된 것을 볼 수가 있는데 이는 _getResult() 함수를 Task 클래스의 것을 호출하겠다는 의미이다. 이렇게 하위 목록을 가져오는 코드가 Task에게 위임된 것을 볼 수 있다. Step 3. Class Diagram Step 3. 결과물javascript https://github.com/icednut/design-pattern-study/tree/master/composite_pattern/javascript/step_03 java https://github.com/icednut/design-pattern-study/tree/master/composite_pattern/java/step3 Step 4. 하위 태스크를 무한대로 추가 (Composite Pattern 등장)앞에 코드대로라면 태스크 하위는 1단까지만 가능하다. 그런데 태스크 하위로 또 태스크가 달리고 그렇게 달린 태스크에 또 하위로 태스크가 달리게 하고 계속 태스크를 하위에 추가할 수 있게 하려면 어떻게 해야될까? 이 때 Compostie Pattern이 등장하게 된다. Composite Pattern은 이렇게 반복되는 처리에 대한 비지니스 로직을 처리할 때 빛을 발한다. 마찬가지로 실행코드부터 작성해보자. app.jsconst list1 = new TaskList('s75'); const item1 = new TaskItem(\"3강교안작성\"); list1.add(item1); const sub1 = new TaskItem(\"코드정리\"); item1.add(sub1); const subsub1 = new TaskItem(\"subsub1\"); sub1.add(subsub1); list1.getResult(Task.title); Application.javapublic class Application { public static void main(String[] args) { TaskList list1 = new TaskList(\"s75\"); TaskItem item1 = new TaskItem(\"3강교안작성\", null); list1.add(item1); TaskItem sub1 = new TaskItem(\"코드정리\", null); item1.add(sub1); TaskItem subsub1 = new TaskItem(\"subsub1\", null); sub1.add(subsub1); TaskWrapper result = list1.getResult(Task.SortAction.TITLE, true); System.out.println(result); } } 만약 코드가 완성된다면 실행코드를 수행했을 때 getResult() 함수의 결과는 다음과 같을 것이다. {item:'s75', children:[ {item:taskItem('3강교안작성'), children:[ {item:taskItem('코드정리'), children:[ {item:taskItem('subsub1'), children:[]} ]} ]} ]} 앞에서 하던대로 이번에도 Task 부터 작성 시작!이제는 Task의 하위에 또 TaskList가 올 수 있기 때문에 Task의 getResult() 함수를 고쳐야 한다. 어떻게? Task의 getResult() 함수 호출 시 하위 Task 각각에 대해 getResult() 함수로 자식의 Task 리스트를 덧붙이는 방식으로 진행한다. 결국 Task의 getResult() 함수는 재귀 호출되어 자식 Task 목록을 구성하는 것이다. 이렇게 되면 너무 많은 재귀호출로 인해 발생하는 StackOverflow는 어떻게 해결할 것인가? 아마도 반복문으로 해결할듯 싶은데 이 부분은 나중에 하는 것으로 남겨두자. 일단 Task의 getResult 함수부터 재작성해보자. task.jsconst Task = class{ constructor(title, date){ if(!title) throw 'invalid title'; this._title = title; this._date = date; this._isComplete = false; this._list = []; } add(task){ if(task instanceof Task) this._list.push(task); else throw 'invalid'; } remove(task){ const list = this._list; if(list.includes(task)) list.splice(list.indexOf(task), 1); } getResult(sort, stateGroup){ const list = this._list; return { item:this._getResult(), children:(!stateGroup ? [...list].sort(sort) : [ ...list.filter(v=>!v.isComplete()).sort(sort), ...list.filter(v=>v.isComplete()).sort(sort) ]).map(v=>v.getResult(sort, stateGroup)) }; } _getResult(){throw 'override';} isComplete(){throw 'override';} sortTitle(){throw 'override';} sortDate(){throw 'override';} }; TaskWrapper.javapublic class TaskWrapper { private TaskWrapper item; private List&lt;TaskWrapper> children; public TaskWrapper() { } public TaskWrapper(Task task, List&lt;TaskWrapper> children) { this.item = task; this.children = children; } public TaskWrapper getItem() { return item; } public List&lt;TaskWrapper> getChildren() { return children; } } Task.javapublic abstract class Task extends TaskWrapper { protected String title; protected LocalDateTime date; protected boolean isComplete; protected List&lt;Task> list; public Task(String title, LocalDateTime date) { this.title = Optional.ofNullable(title).orElseThrow(() -> new InvalidTitleException()); this.date = date; this.isComplete = false; this.list = new ArrayList&lt;>(); } public void add(Task task) { this.list.add(task); } public void remove(Task task) { if (list.contains(task)) { list.remove(task); } } public TaskWrapper getResult(Task.SortAction sortAction, boolean stateGroup) { Comparator&lt;Task> sortMethod = sortAction::invoke; List&lt;TaskWrapper> sub; if (!stateGroup) { sub = list.stream() .sorted(sortMethod) .map(each -> each.getResult(sortAction, stateGroup)) .collect(Collectors.toList()); } else { sub = new ArrayList&lt;>(); sub.addAll(list.stream() .filter(v -> !v.isComplete()) .sorted(sortMethod) .map(each -> each.getResult(sortAction, stateGroup)) .collect(Collectors.toList())); sub.addAll(list.stream() .filter(v -> v.isComplete()) .sorted(sortMethod) .map(each -> each.getResult(sortAction, stateGroup)) .collect(Collectors.toList())); } return new TaskWrapper(this.getResultComposite(sortAction, stateGroup), sub); } protected abstract Task getResultComposite(Task.SortAction sortAction, boolean stateGroup); public abstract boolean isComplete(); public abstract void toggle(); public abstract int sortTitle(Task task); public abstract int sortDate(Task task); public static enum SortAction { TITLE { public int invoke(Task a, Task b) { return a.sortTitle(b); } }, DATE { public int invoke(Task a, Task b) { return a.sortDate(b); } }; public abstract int invoke(Task a, Task b); } } Composite Pattern을 적용한 Task 클래스는 아무런 의존성이 없는 가장 최상위 부모가 된다. 그래서 항목으로 표현할 때는 Task를 상속 받아서 TaskItem이라는 클래스로 구체화될 것이고, 항목 목록으로 표현할 때는 Task를 상속 받아서 TaskList라는 클래스가 될 것이다. TaskItem과 TaskList 클래스에서 getResult() 함수를 호출하게 되면 가장 최상위 부모인 Task 클래스의 getResult() 함수를 호출하게 될 것이고, item 부분에는 자식에서 구현된 hook을 실행하고 (TaskItem, TaskList에서 Hook에 대한 행위가 위임되어 있기 때문) chidren에서는 정렬 후 자식이 있으면 자식들의 getResult 함수를 호출해서 항목을 구성해나가는 형태가 될 것이다. 이렇게 getResult 함수는 자기가 자신을 호출하는게 아니라 자식의 getResult 함수를 호출하는 확산 형태로 진행되게 된다. Task의 _getResult는 이제 Hook이 되고 실제 할일을 나타내는(Hook을 구현한) TaskItem 클래스를 작성하여 핵심 동작을 그 클래스에 위임한다. task_item.jsconst TaskItem = class extends Task{ constructor(title, date = Date.now()){ super(title); this._date = date; this._isComplete = false; } _getResult(sort, stateGroup){return this;} isComplete(){return this._isComplete;} sortTitle(){return this._title > task._title;} sortDate(){return this._date > task._date;} toggle(){this._isComplete = !this._isComplete;} } TaskItem.javapublic class TaskItem extends Task { public TaskItem(String title, LocalDateTime date) { super(title, date == null ? LocalDateTime.now() : date); this.isComplete = false; } @Override protected Task getResultComposite(Task.SortAction sortAction, boolean stateGroup) { return this; } @Override public boolean isComplete() { return this.isComplete; } @Override public void toggle() { this.isComplete = !this.isComplete; } @Override public int sortTitle(Task task) { return this.title.compareTo(task.title); } @Override public int sortDate(Task task) { return this.date.compareTo(task.date); } } task_list.jsconst TaskList = class extends Task{ constructor(title){super(title);} _getResult(){return this._title;} isComplete(){} sortTitle(){return this;} sortDate(){return this;} byTitle(stateGroup = true){return this.getResult(Task.title, stateGroup);} byDate(stateGroup = true){return this.getResult(Task.date, stateGroup);} } TaskList.javapublic class TaskList extends Task { public TaskList(String title) { super(title, null); } @Override protected Task getResultComposite(Task.SortAction sortAction, boolean stateGroup) { return new TaskItem(this.title, this.date); } @Override public boolean isComplete() { return false; } @Override public void toggle() { } @Override public int sortTitle(Task task) { return 0; } @Override public int sortDate(Task task) { return 0; } public TaskWrapper byTitle(boolean stateGroup) { return this.getResult(SortAction.TITLE, stateGroup); } public TaskWrapper byDate(boolean stateGroup) { return this.getResult(SortAction.DATE, stateGroup); } } Task, TaskItem, TaskList 클래스를 잘 보면 Composite Pattern 이라고 했는데 또 한가지 패턴이 보인다. 바로 Template Method Pattern도 쓰여있는 것을 볼 수 있다. 이렇게 실무에서는 디자인 패턴이 여러개가 결합된 형태로 적용된다. 여기서는 Todo App 이라는 반복되는 행위(Loop)를 Composite Pattern으로 풀었는데 HTML Parser, Markdown Parser도 컴포짓 패턴으로 구현할 수 있으며 심지어 네비게이션의 길찾기도 컴포짓 패턴으로 구현할 수 있다고 한다. (우와 그럼 컴포짓 패턴이 만능 아닌가? 사실 네비게이션 길찾기는 도무지 상상이 안간다..) Step 4. Class Diagram Step 4. 결과물javascript https://github.com/icednut/design-pattern-study/tree/master/composite_pattern/javascript/step_04 java https://github.com/icednut/design-pattern-study/tree/master/composite_pattern/java/step4 Step 5. Task를 그리는 Renderer 구현하기Todo App에서 데이터와 행위에 대해 추상화를 어느정도 하였으니 이번엔 화면에 그리는 작업을 하는 Renderer를 구현해보자. 잉? 앞에서 화면 구현은 안한다고 하지 않았나? 물론 그렇게 말했지만 그래도 브라우저에 간단한 DOM으로 출력하는 형태로 Renderer를 구현해보자. (이제 이걸 DomRenderer라고 부르며 Java Version은 ConsoleRenderer라고 콜솔에 출력하는 형태로 구현할 것이다.) Task가 Composite Pattern으로 구현되어 있기 때문에 이를 그리는데 사용하는 Renderer의 구조도 Composite Pattern 구조를 따라가게 된다. 이걸 컴포지션은 전파된다라고 표현한다. Renderer는 구현 전략을 간단하게 표현하자면 Renderer는 TaskList를 소유하고 이걸 이용해 getResult를 호출하면 줄줄이 사탕으로 딸려오는 Task 데이터를 참조하여 그릴 것이다. 시작하기 전에 Util 성 코드 부터 하나 추가하자. util.jsconst el =(tag, ...attr)=>{ const el = document.createElement(tag); for(let i = 0; i &lt; attr.length;){ const k = attr[i++], v = attr[i++]; if(typeof el[k] == 'function') el[k](...(Array.isArray(v) ? v : [v])); else if(k[0] == '@') el.style[k.substr(1)] = v; else el[k] = v; } return el; }; 위 코드는 DOM을 생성하는 함수 el을 선언한 것이다. 첫 번째 파라미터로는 만드려고 하는데 element의 Tag명을 받고, 그 이후 파라미터는 부터는 함수, style, attribute를 받는다. 자세한 사용 방법은 DomRenderer 클래스를 작성하면서 알아보자. 그럼 마찬가지로 실행코드 작성 후 의존성이 없는 Task 부터 시작해서 TaskList, TaskItem 그 다음 DomRenderer 클래스 순으로 작성해보자. 위 시퀀스 다이어그램을 보면 자식 Renderer에서 TaskList의 getResult() 함수를 호출하면 부모인 Task의 getResult() 함수를 호출하게 되는 꼴이고 Task.getResult()는 자식(TaskList)의 Hook인 _getResult() 함수를 호출하여 처리한다. 그렇게 반환된 결과에서 TaskItem 각각은 또 getResult() 함수를 호출하게 되고 이렇게 점점 getResult() 함수 호출이 확산되어 가는 모습을 볼 수 있다. app.jsconst list1 = new TaskList(\"s75\"); const item1 = new TaskItem(\"3강교안작성\"); list1.add(item1); const sub1 = new TaskItem(\"코드정리\"); item1.add(sub1); const subsub1 = new TaskItem(\"subsub1\"); sub1.add(subsub1); list1.getResult(Task.title); const todo = new DomRenderer(list1, sel(\"#todo\")); todo.render(); Application.javapublic class Application { public static void main(String[] args) { TaskList list1 = new TaskList(\"s75\"); TaskItem item1 = new TaskItem(\"3강교안작성\", null); list1.add(item1); TaskItem sub1 = new TaskItem(\"코드정리\", null); item1.add(sub1); TaskItem subsub1 = new TaskItem(\"subsub1\", null); sub1.add(subsub1); ConsoleRenderer todo = new ConsoleRenderer(list1); todo.render(); } } 그 다음 Task 클래스는 어떻게 작성할까? 이제는 TaskList와 TaskItem은 Task 클래스를 상속 받고 있기 때문에 Task에 공통로직을 모을 수 있게 되었다. 또 Task의 getResult 함수의 결과로 item은 자기 자신을 보내고 children으로는 children 각각의 요소들에 해당하는 getResult 함수호출을 확산하도록 구현한다. task.jsconst Task = class{ static title(a, b){return a.sortTitle(b);} static date(a, b){return a.sortDate(b);} constructor(title){ if(!title) throw 'invalid title'; else this._title = title; this._list = []; } add(task){ if(task instanceof Task) this._list.push(task); else throw 'invalid'; } remove(task){ const list = this._list; if(list.includes(task)) list.splice(list.indexOf(task), 1); } getResult(sort, stateGroup){ const list = this._list; return { item:this, children:(!stateGroup ? [...list].sort(sort) : [ ...list.filter(v=>!v.isComplete()).sort(sort), ...list.filter(v=>v.isComplete()).sort(sort) ]).map(v=>v.getResult(sort, stateGroup)) }; } isComplete(){throw 'override';} sortTitle(){throw 'override';} sortDate(){throw 'override';} }; Task.javapublic abstract class Task extends TaskWrapper { protected String title; protected List&lt;Task> list; public Task(String title) { this.title = Optional.ofNullable(title).orElseThrow(() -> new InvalidTitleException()); this.list = new ArrayList&lt;>(); } public void add(Task task) { this.list.add(task); } public void remove(Task task) { if (list.contains(task)) { list.remove(task); } } public TaskWrapper getResult(SortAction sortAction, boolean stateGroup) { Comparator&lt;Task> sortMethod = sortAction::invoke; List&lt;TaskWrapper> children; if (!stateGroup) { children = list.stream() .sorted(sortMethod) .map(each -> each.getResult(sortAction, stateGroup)) .collect(Collectors.toList()); } else { children = new ArrayList&lt;>(); children.addAll(list.stream() .filter(v -> !v.isComplete()) .sorted(sortMethod) .map(each -> each.getResult(sortAction, stateGroup)) .collect(Collectors.toList())); children.addAll(list.stream() .filter(v -> v.isComplete()) .sorted(sortMethod) .map(each -> each.getResult(sortAction, stateGroup)) .collect(Collectors.toList())); } return new TaskWrapper(this, children); } public abstract boolean isComplete(); public abstract int sortTitle(Task task); public abstract int sortDate(Task task); public static enum SortAction { TITLE { public int invoke(Task a, Task b) { return a.sortTitle(b); } }, DATE { public int invoke(Task a, Task b) { return a.sortDate(b); } }; public abstract int invoke(Task a, Task b); } } 이제 TaskItem과 TaskList 클래스에서는 더 이상 _getResult 훅을 구현하지 않아도 된다. 과감하게 삭제하자. task_item.jsconst TaskItem = class extends Task{ constructor(title, date = Date.now()){ super(title); this._date = date; this._isComplete = false; } isComplete(){return this._isComplete;} sortTitle(){return this._title > task._title;} sortDate(){return this._date > task._date;} toggle(){this._isComplete = !this._isComplete;} } TaskItem.javapublic class TaskItem extends Task { protected LocalDateTime date; private boolean isComplete; public TaskItem(String title, LocalDateTime date) { super(title); this.date = date == null ? LocalDateTime.now() : date; this.isComplete = false; } @Override public boolean isComplete() { return this.isComplete; } public void toggle() { this.isComplete = !this.isComplete; } @Override public int sortTitle(Task task) { return this.title.compareTo(task.title); } @Override public int sortDate(Task task) { if (task instanceof TaskItem) { return this.date.compareTo(((TaskItem) task).date); } return 0; } } task_list.jsconst TaskList = class extends Task{ constructor(title){super(title);} isComplete(){} sortTitle(){return this;} sortDate(){return this;} } TaskList.javapublic class TaskList extends Task { public TaskList(String title) { super(title); } @Override public boolean isComplete() { return false; } @Override public int sortTitle(Task task) { return 0; } @Override public int sortDate(Task task) { return 0; } } 마지막으로 DomRenderer 클래스를 구현할 차례다. 실행코드에서 작성했던 DomRenderer의 render() 함수부터 작성해보자. dom_renderer.jsconst DomRenderer = class{ constructor(list, parent){ this._parent = parent; this._list = list; this._sort = 'title'; } add(parent, title, date){ parent.add(new TaskItem(title, date)); this.render(); // 모델 렌더링은 추가된 요소만 그리는게 아니라 모델 전체를 다시 그린다. } remove(parent, task){ parent.remove(task); this.render(); } toggle(task){ if(task instanceof TaskItem){ task.toggle(); this.render(); } } render(){ const parent = this._parent; parent.innerHTML = ''; parent.appendChild('title,date'.split(',').reduce((nav,c)=>( nav.appendChild( el('button', 'innerHTML', c, '@fontWeight', this._sort == c ? 'bold' : 'normal', 'addEventListener', ['click', e=>(this._sort = Task[c], this.render())]) ), nav ), el('nav'))); this._render(parent, this._list, this._list.getResult(Task[this._sort]), 0); } _render(base, parent, {item, children}, depth){ const temp = []; base.style.paddingLeft = depth * 10 + 'px'; if(item instanceof TaskList){ temp.push(el('h2', 'innerHTML', item._title)); }else{ temp.push( el('h3', 'innerHTML', item._title, '@textDecoration', item.isComplete() ? 'line-through' : 'none'), el('time', 'innerHTML', item._date.toString(), 'datetime', item._date.toString()), el('button', 'innerHTML', item.isComplete() ? 'progress' : 'complete', 'addEventListener', ['click', _ => this.toggle(item)]), el('button', 'innerHTML', 'remove', 'addEventListener', ['click', _ => this.remove(parent, item)]) ); } const sub = el('section', 'appendChild', el('input', 'type', 'text'), 'appendChild', el('button', 'innerHTML', 'addTask', 'addEventListener', ['click', e => this.add(item, e.target.previousSibling.value)]) ); children.forEach(v => this._render(sub, item, v, depth + 1)); temp.push(sub); temp.forEach(v => base.appendChild(v)); } }; ConsoleRenderer.javapublic class ConsoleRenderer { private TaskList list; private Task.SortAction sort; public ConsoleRenderer(TaskList taskList) { this.list = taskList; this.sort = Task.SortAction.TITLE; } public void render() { this.renderComposite(list.getResult(sort, false), 0); } protected void renderComposite(TaskWrapper result, int depth) { List&lt;String> temp = new ArrayList&lt;>(); TaskWrapper item = result.getItem(); if (item instanceof TaskList) { TaskList taskList = (TaskList) item; temp.add(taskList.title); } else if (item instanceof TaskItem) { TaskItem taskItem = (TaskItem) item; String completeStar = taskItem.isComplete() ? \"*\" : \" \"; temp.add(taskItem.title + \" (\" + completeStar + \")\" + \" - \" + taskItem.date.format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); } temp.forEach(v -> { for (int i = 0; i &lt; depth; i++) { System.out.print(\" \"); } System.out.println(v); }); result.getChildren().forEach(taskWrapper -> { this.renderComposite(taskWrapper, depth + 1); }); } } render() 함수를 살펴보면 Task 클래스의 getResult 함수와 많이 닮아 있다. 이유는 Task의 재귀호출로 데이터를 가져오는 컴포짓에 따라서 render() 함수도 마찬가지로 재귀로 데이터를 가져와서 DOM을 생성해야 되기 때문이다. (컴포지션 전파 때문) 여기까지가 To-Do App을 Composite Pattern으로 구현한 결과이다. 그럼 이대로 끝난 것일까? 컴포지션 전파가 과연 좋은 코드라고 할 수 있을까? 추후 또 다른 Renderer를 구현한다 치면 그 클래스에서 컴포지션 전파를 하게 하는게 올바른걸까? 다음 포스팅에서는 컴포지션 전파를 끊어내기 위한 Visitor Pattern을 살펴보도록 하자. To-Do App Composite Pattern 결과물Javascript version https://gist.github.com/icednut/c619b19495a79ebfce7252e3a4573414 Java Version https://github.com/icednut/design-pattern-study/tree/master/composite_pattern/java/step5","categories":[],"tags":[{"name":"design pattern","slug":"design-pattern","permalink":"http://icednut.github.io/tags/design-pattern/"},{"name":"composite pattern","slug":"composite-pattern","permalink":"http://icednut.github.io/tags/composite-pattern/"}]},{"title":"Java Garbage Collector 이해하기 Part 1 (with G1GC, Garbage First GC)","slug":"20180325-about-java-garbage-collection","date":"2018-03-25T03:53:46.000Z","updated":"2018-11-27T06:40:43.298Z","comments":true,"path":"2018/03/25/20180325-about-java-garbage-collection/","link":"","permalink":"http://icednut.github.io/2018/03/25/20180325-about-java-garbage-collection/","excerpt":"","text":"Garbage Collection이란?Garbage Collector를 이해 하려면 Java에서의 메모리 관리 방법과 Garbage Collection이라는 행위(GC Algorithm)를 이해할 필요가 있다. 그 후 Garbage Collector 별로 어떻게 Garbage Collection을 하는지 알아볼 것이다. 이 글에서는 Oracle에서 공식 개발 및 배포하고 있는 Hotspot JVM을 기준으로 진행한다. Java에서 메모리를 해제하는 것은 개발자의 영역이 아니다.Java에서는 변수나 객체를 다양한 방법으로 선언하고 메모리를 할당 받는다. 그러나 이미 할당 받은 객체나 변수를 해제하는 방법은 없다. System.gc()나 close()와 같은 함수를 떠올릴 수도 있겠지만, 이것은 Garbage Collection을 명시적으로 수행하거나 해당 객체의 사용을 중지하겠다는 의사 표현일 뿐 직접적으로 객체를 메모리에서 삭제(해제)하진 않는다. 여기서 메모리 해제는 Heap이나 Method Area에 있는 특정한 Object를 Memory에서 삭제한다는 의미다. 그럼 Java에서는 이런 메모리 해제 작업을 누가 어떻게 할까? 바로 Garbage Collector가 담당하며, 메모리 해제하는 작업을 Garbage Collection이라고 한다. JVM Specification에서 Garbage Collection에 대한 정의는 다음과 같다. Heap storage for objects is reclaimed by an automatic storage management system (typically a garbage collector); objects are never explicity deallocated. Heap은 Object를 위한 메모리 공간이고 Garbage Collector라고 하는 자동화된 시스템에 의해 Heap은 재사용 될 수 있다. Object는 절대로 (개발자에 의해) 명시적으로 해제되지 않는다. - Java Virtual Machine Speculation, Sectio 3.5.3 [JVMS2 1999] JVM 벤더들은 위 JVM Specification만 보고 그에 맞게 메모리 구조(Heap Layout)을 구성하고 Garbage Collection에 대한 알고리즘을 적용한 Garbage Collector를 구현했다. 이러한 노력 덕분에 Java를 사용하면 메모리 해제에 대한 고민을 개발자가 안해도 되게 되었지만 개발자의 의도와는 다르게 프로그램이 갑자기 Garbage Collection만 하면 Suspend 된다거나 하는 현상이 나타날 수 있다. 이러한 현상에 대처하기 위해서는 개발자도 Garbage Collection에 대해 알 필요가 있다. 그래서 Garbage Collection이 뭐라고?Garbage Collection이란 행위를 살펴보면 다음과 나눠서 볼 수 있다. Collect: Heap과 Method Area라는 메모리 영역에서 사용되지 않는 Object를 모으고 Flush: 이렇게 모은 Garbage들을 메모리에서 해제한다. 그럼 사용되지 않는 Object는 어떻게 판단할까? Java에서는 Root Set과의 관계로 판단한다. 즉 Root Set과 연된되지 않는 Object가 있으면 그것은 Garbage Collection 대상이 된다는 의미이다. 그럼 Root Set이란 뭘까? (정확히 말해 Root Set은 뭘로 구분할까?) Stack의 참조 정보 Local Variable Section과 Operand Stack이라는 스택 공간에 Object Reference 데이터가 있다면 이것은 Reachable Object로 판단하며 현재 Thread들이 사용하고 있는 것으로 간주한다. 즉, Garbage Collection의 입장에서는 두 스택공간이 Root Set이 되는 것이다. Constant Pool에 있는 Reference 정보 Method Area에 로딩된 클래스(static variable이 선언된 클래스)들은 Thread들이 직접적으로 참조하고 있지 않지만 Constant Pool을 통해 간접적으로 Link하고 있는 Reachable Object이다. 그러므로 Constant Pool도 Root Set으로 볼 수 있다. Native Method로 넘겨진 Object Reference Native Method로 넘겨진 Object는 JNI 형태로 현재 참조관계가 있는 Object이기 때문에 Reachable Object로 판단한다. 위 세 가지 기준에 따라 Reachable Object 여부를 판단하게 되며 Root Set과 관계 없이 상호 참조만 하고 있는 Object가 있다면 Garbage Collector는 이것을 Garbage로 판단하고 메모리를 해제한다. Heap Fragmentation(힙의 단편화) 등장Garbage Collection의 목적은 새로운 Object의 할당을 위해 한정된 Heap 공간을 재활용하려는 목적으로 수행된다. 그러나 여기서 Garbage가 빠져나간 공간 재활용을 위해 해제한 메모리 공간은 할당했던 그 자리에서 일어나기 때문에 메모리 공간이 듬성듬성해진다. 이렇게 듬성듬성해진 공간이 1kbyte, 2kbyte, 3kbyte 3개를 확보한 상태에서 5kbyte 크기의 Object를 할당하려고하면 할당할 수 없게 된다. 이러한 문제를 Heap Fragmentation이라고 한다. 이걸 방지하기 위해 어떻게 해야 될까? Garbage Collector는 메모리 해제 후 Compation이라는 알고리즘을 사용한다. (Compaction: 압축, 메모리 공간 정리 작업) 정리Garbage Collection을 한 줄로 정리하자면 다음과 같다. Garbage Collection이란 Heap을 재활용하기 위해 Root Set에서 참조되지 않는 Object를 없애 가용한 공간을 만드는 작업 Garbage Collection이란 이러한 메모리 해제 작업에 대한 알고리즘이고, Garbage Collector은 Garbage Collection을 실행하는 주체라고 보면 된다. Garbage Collection의 기본 알고리즘Java의 Garbage Collection 알고리즘은 여러 시행착오와 경험에 의해 발전되어 왔다. 대표적으로 6개의 알고리즘이 있는데 최근에 Garbage First(G1 GC)라는 새로운 알고리즘도 나왔다. (G1 GC는 Train 알고리즘의 아이디어를 빌려와 채용했다고 한다.) 각 알고리즘의 동작과정과 특징을 살펴보면 GC알고리즘 한 개가 있으면 이 것에 대한 단점을 보완하거나 멀티코어 환경, 서버환경, 클라이언트(모바일) 환경에서의 효율적인 GC를 위해 더 발전된 형태로 다음 GC 알고리즘이 탄생한 것을 볼 수 있다. 그럼 6가지 GC 알고리즘에 대해 알아보자. Reference Counting Algorithm Mark-and-Sweep Algorithm Mark-and-Compaction Algorithm Copying Algorithm Generational Algorithm Train Algorithm Reference Counting Algorithm이 알고리즘은 Java 초기에 나온 알고리즘을 Garbage를 수집하는 것에만 집중되어 있다. Reference Counting 알고리즘 이후의 알고리즘들은 수집 뿐만 아니라 Heap Memory를 어떻게 재활용해야 하는 고민들에 초점이 맞추어 지는 것을 볼 수 있다. Reference Count 알고리즘의 기본 아이디어는 다음과 같다. 각 Object 마다 Reference Count를 관리하여 Reference Count가 0이 되는 Object는 Garbage로 간주하고 메모리 해제 즉, Object에 Reference 되면 Reference Count는 1이 증가하고 Reference가 사라지면 1이 감소 이 Reference 관계가 간접적이라 하더라도 참조하고 있는 모든 Object에 대해 연쇄적으로 Reference Count가 변경 동작 방식 이해이 부분은 추후 업데이트 예정 예제1 예제2 문제점이 부분은 추후 업데이트 예정 Memory Leak이 발생할 가능성이 있다. (Root Set - a - b - c - a의 상황에서 Root Set과 a의 관계가 끊어지게 되도 a는 살아있게 됨) Mark-and-Sweep AlgorithmMark-and-Sweep 알고리즘은 Tracing Algorithm이라고도 불린다. 이 알고리즘은 Reference Counting 알고리즘의 단점을 극복하기 위해 나왔다고 볼 수 있다. Mark-and-Sweep 알고리즘은 두 가지 단계로 구분되어 진행된다. Mark Phase Garbage Object를 구별해 내는 단계 Root Set에서 Reference 관계가 있는 Object에 대해 Marking하는 작업 진행 Marking은 주로 Object Header에 Flag에 하거나 별도의 Bitmap Table등을 사용 Sweep Phase Marking되지 않은 Object를 지우는 작업 동작 방식 이해이 부분은 추후 업데이트 예정 문제점이 부분은 추후 업데이트 예정 Garbage Collection 과정 중에는 Heap의 사용이 제한되기 때문에 프로그램이 잠깐 멈추는 현상(Suspend) 발생 Heap Fragmentation 발생 Mark-and-Compaction Algorithm이 알고리즘은 Mark-and-Sweep 알고리즘의 단점을 보완하고자 나왔다. 앞의 알고리즘에서 Compaction이 포함되었다고 보면 된다. 이 알고리즘도 두 가지 단계로 구분되어 진행된다. Mark Phase Mark-and-Sweep 알고리즘의 Mark Phase와 Sweep Phase가 이 단계와 동일 Compaction Phase Mark Phase에서 살아남은 Live Object를 연속된 메모리 공간에 차곡차곡 적재 Arbitrary 방식, Linear 방식, Sliding 방식이 있는데 Hotspot JVM은 Sliding 방식을 채용 동작 방식 이해이 부분은 추후 업데이트 예정 문제점이 부분은 추후 업데이트 예정 Compaction Phase를 통해 Fragmentation을 방지 및 메모리 공간의 효율성이 좋아졌지만, 모든 Reference를 메모리 공간에서 업데이트하는 작업이 성능 측면에서 오버헤드가 될 수 있다. Mark Phase와 Compaction Phase 모두 Suspend 현상이 발생한다. Copying Algorithm이 알고리즘은 Fragmentation의 문제를 해결하기 위해 제시된 또 다른 방법이라고 보면된다. 이 알고리즘 부터는 Heap을 영역별로 나누어서 다루게 되는데 Copying 알고리즘은 Heap을 Active 영역, Inactive 영역으로 나누어 사용한다. 이 알고리즘의 동작을 요약하면 다음과 같다. Active 영역에만 Object를 할당 받을 수 있음 Active 영역이 꽉차서 더 이상 Allocation이 불가능해지면 Garbage Collection 수행 Active 영역에서 살아남은 Live Object는 Inactive 영역으로 Copy하고 Active 영역을 비움 (이를 Scavenge라고 함) Inactive에 복사할 때 한 쪽 방향에서 차곡차곡 적재를 하기 때문에 Fragmentation이 극복됨 이 알고리즘의 단점은 Garbage Collection을 하려고 하면 일단 프로그램은 Suspend 상태가 된다. 동작 방식 이해이 부분은 추후 업데이트 예정 문제점이 부분은 추후 업데이트 예정 GC 수행 전 Suspend하고 GC 진행 Fragmentation 방지에는 효과적이지만 전체 Heap의 절반 정도를 사용하지 못함 (Active, Inactive로 나뉘어 있기 때문) Copy 작업이 오버헤드 Generational Algorithm앞서 소개한 Copying 알고리즘을 사용하면서 JVM은 몇 가지 경험을 알게 된다. Copying 알고리즘을 사용하면서 대부분의 프로그램에서 생성되는 대다수의 Object는 생성된지 얼마 되지 않아 Garbage가 된다 어떤 프로그래밍라 하더라도 수명이 긴 몇 개의 Object는 반드시 가지고 있다 이렇게 긴 수명의 Object (Long Lived Object)의 경우 Inactive와 Active를 계속 왔다 갔다 하면서 Copy 작업이 일어나며 이에 대한 Overhead가 만만치 않음 위 경험들을 극복하기 위해 Generational 알고리즘이 나오게 되었으며, 이 알고리즘은 Copying 알고리즘의 연장선상에 있다고 볼 수 있다. 이 알고리즘에서는 Heap을 Youngest Generation Sub Heap, Oldest Generation Sub Heap 이렇게 두 부분으로 나누어 사용한다. 이 알고리즘의 특징은 다음과 같다. Object는 처음에 할당하게 되면 Youngest Generation Sub Heap에 위치 GC가 일어날 때마다 살아남은 Object는 age라는 메타 정보를 증가 age가 임계값을 넘어가는 Youngest Generation Sub Heap의 Object들은 Oldest Generation Sub Heap으로 이동 (이를 Promotion이라고 함) 이 알고리즘의 장점은 Heap을 Young, Old라는 두 가지 부분으로 나누어서 다루기 때문에 각 부분마다 GC를 따로따로 실행할 수 있게 되었고, 또 Young, Old 각각 다른 알고리즘을 적용할 수도 있게 되었다. 그렇기 때문에 Hotspot JVM이나 IBM JVM에서도 이 알고리즘을 사용하게 된다. 여기서는 단순히 Young, Old라고만 적었는데 Hotspot JVM에서는 Young Generation 안에서도 Eden, Survivor 등과 같은 영역으로 나눠서 좀 더 세분화하여 Heap을 다룬다. Train AlgorithmTracing 알고리즘 이후 Suspend 현상이 나타나는 것은 골치거리였다. 특히 WAS와 같이 짧은 트랜잭션을 처리하는 시스템의 경우 불규칙적인 Suspend 현상은 불쾌한 사용자 경험만 안겨줄 뿐이다. Train 알고리즘은 Suspend와 같은 현상을 극복하기 위해 Heap을 작은 Memory Block으로 나누어 Single Block 단위로 Mark Phase &amp; Copy Phase로 구성된 Garbage Collection을 수행한다. 덕분에 작은 메모리 블록 별로 스레드가 GC를 수행하여 Suspend를 분산시켜 Pause Time 줄여보자는 아이디어인 것이다. 이 알고리즘은 Garbage First Garbage Collector의 알고리즘이 되며 결국 Java 9에서는 G1GC가 Default Garbage Collector로 채택되게 된다. 동작 방식 이해이 부분은 추후 업데이트 예정 Hotspot JVM의 Garbage Collection오라클에서 유지보수하고 있는 공식 Hotspot JVM은 Generational Collection 방식을 택하고 있다. 최근 Garbage First Garbage Collection을 기본으로 택하면서 그 방식이 약간 변경되긴 했지만 공통적으로 Heap을 Generation이라는 영역별로 나누어 사용하는 것이 Hotspot JVM의 가장 큰 특징이다. 이미지 출처: http://performeister.tistory.com/60 Hotspot JVM의 Heap 메모리 구조는 다음과 같이 되어 있다. Young Generation Eden Survivor 1 Survivor 2 Old Generation Tenured Permanent Generation Eden 영역 Young Generation은 Object를 Allcation하는 영역이며, 그 중에서 Eden 영역은 Object가 최초로 할당되는 영역 Object Allocation은 TLAB(Thread Local Allocation Buffer)라는 기술을 사용 What is TLAB? Thread 마다 할당을 위한 주소 범위를 미리 부여하고 그 범위 내에서 Object Allocation을 하게 하는 것 이러한 범위를 Thread Local Allocation Buffer라고 부름 Thread 별로 공간을 나누어 주어 그 안에서 아무런 대기 현상 없이 Allocation이 가능해짐 단 TLAB를 Thread에게 최초 할당하거나 할당된 TLAB가 부족하여 새로 받을 때는 동기화 이슈가 발생하지만 Object Allocation 횟수에 비하면 이 동기화는 껌 Survivor 1, 2 영역 (From, To 영역이라고도 함) Eden 영역에서 Old Generation으로 가기 위한 대기 장소 이 영역의 Object가 Old Generation으로 가는 것을 Promotion 이라고 함 여기까지를 Young Generation 이라고 하며, Young Generation에서 발생하는 Garbage Collection을 Minor GC라고 부른다. Old Generation Tenured 영역이라고도 하며 Long Lived Object가 머무르는 곳이다. Old Generation에서 발생하는 Garbage Collection을 Major GC라고 부른다. Major GC는 Promotion을 통해 Old Generation으로 Object가 이동하는 과정에서 메모리가 부족해지면 발생 Major GC는 Minor GC로 인해 Garbage Collection이 확산된 것 Permanent Generation 추후 설명 예정 이렇게 Generation을 나누고 Minor GC, Major GC로 나눠서 GC를 하게 되면 전체적인 Suspend Time을 줄일 수 있다. 여기에는 대부분의 Object는 새로 생겨난 후 얼마되지 않아 Garbage가 된다는 가정이 깔려있다. 또한 Older Object가 Younger Object를 참조하는 일은 상당히 드물다는 가정이 깔려있다. 이러한 가정을 바탕으로 Minor GC를 가볍게 유지하기 위해 노력한다. 그런데 Older Object가 Young Generation에 있는 Object를 참조하는 경우는 어떻게 할 것인가? 드물긴해도 불가능한 것은 아니다. 만약 이런 상황이라면 Minor GC 이후 Major GC에서 Old generation의 Object들의 Reference를 모두 추적한다면 Heap Memory 전체 Suspend 시간이 길어져 곤란하다. 이를 해결하기 위해 태어난게 Card Table과 Write Barrier 이다. Card Table &amp; Write Barrier추후 설명 업데이트 예정 Old Object가 Young Object를 참조하고 있다면 Old Object의 시작주소에 해당하는 Card에 Dirty 표시 이렇게 표시하는 작업을 수행하는 것을 Write Barrier이 수행 출처 Java Performance Fundamental, 김한도 지음 (2009년도 출판) [http://performeister.tistory.com/60]: http://performeister.tistory.com/60 ​","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://icednut.github.io/tags/java/"},{"name":"garbage collector","slug":"garbage-collector","permalink":"http://icednut.github.io/tags/garbage-collector/"}]},{"title":"Druid 파헤치기 - 입문","slug":"20180305-start-druid","date":"2018-03-05T05:47:15.000Z","updated":"2018-11-27T06:40:43.301Z","comments":true,"path":"2018/03/05/20180305-start-druid/","link":"","permalink":"http://icednut.github.io/2018/03/05/20180305-start-druid/","excerpt":"","text":"Druid란 무엇인가? Druid is a system built to allow fast (“real-time”) access to large sets of seldom-changing data. Druid is an open-source data store designed for sub-second queries on real-time and historical data. It is primarily used for business intelligence (OLAP) queries on event data. Druid is a good fit for products that require real-time data ingestion of a single, large data stream. Especially if you are targeting no-downtime operation and are building your product on top of a time-oriented summarization of the incoming data stream. with Druid it is entirely within the realm of possibility (we have done it) to achieve queries that run in less than a second across trillions of rows of data. 드루이드는 변하지 않는 대규모 데이터셋에 빠르게 (실시간으로) 액세스하기 위해 만들어진 시스템이다. 드루이드는 실시간과 시계열 데이터에서 1초 미만의 쿼리를 위해 설계된 오픈소스 데이터 저장소이다. 주로 이벤트 데이터에 대한 BI쿼리(OLAP)에 사용된다. 드루이드는 싱글 혹은 대규모 데이터 스트림에서 실시간 데이터 입수(ingestion)이 필요한 제품에 적합하다. 특히 무중단 운영과 데이터 스트림 입수에서 시간 기반 요약을 제공하는 제품을 개발할 때 특히 그렇다. 드루이드를 사용하면 수십억 데이터 행에서 1초 이내에 쿼리를 실행할 수 있게 된다.출처: Druid 공식 사이트 (http://druid.io/docs/0.11.0/design/design.html) 드루이드 공식 사이트에 소개된 드루이드 소개글을 보면 대용량의 시계열 데이터를 실시간으로 빠르게 분석하고 싶을 때 사용하는 데이터 저장소라고 소개하고 있다. 다른 여러 저장소도 있지만 오픈소스 진영에서는 드루이드가 주목 받고 있는 것 같다. (http://xyz.insightdataengineering.com/blog/pipeline_map/ 여기에도 Druid를 소개하고 있음) 여기서 잠깐! OLAP(On-Line Analytical Processing)가 뭐지? Online analytical processing, or OLAP, is an approach to answering multi-dimensional analytical (MDA) queries swiftly in computing. OLAP is part of the broader category of business intelligence, which also encompasses relational database, report writing and data mining. Typical applications of OLAP include business reporting for sales, marketing, management reporting, business process management (BPM), budgeting and forecasting, financial reporting and similar areas, with new applications coming up, such as agriculture. At the core of any OLAP system is an OLAP cube (also called a ‘multidimensional cube’ or a hypercube). OLAP (Online Analytical Processing, 온라인 분석 처리)는 다차원 컬럼 분석(MDA, Multi-dimensional analytical) 쿼리에 신속하게 응답하는 방법이다. OLAP는 관계형 데이터베이스, 리포트 작성 및 데이터 마이닝을 포함하는 비지니스 인텔리전스의 광범위한 카테고리 중 한 부분이다. 일반적인 OLAP 어플리케이션으로는 영업, 마케팅, 리포팅 관리, 비지니스 프로세스 관리, 예산 및 예측, 예산 보고 등과 같은 영역이 포함되며 농업과 같은 분야에서도 쓰일 수 있다. OLAP 시스템의 핵심은 OLAP 큐브(다른 말로 다차원 큐브 혹은 하이퍼큐브)이다.출처: https://en.wikipedia.org/wiki/Online_analytical_processing#cite_note-22 OLAP는 최종 사용자가 다차원 정보에 직접 접근하여 대화식으로 정보를 분석 및 활용하는 과정으로 정의 할 수 있다. OLAP에서는 다음과 같이 대화식 질문들에 대한 답을 빠르게 해결하는 것이 목적이다. 35세 이상의 고객들은 작년에 얼마나 지출했고 시간에 따라 어떻게 변했는가? 각 연령 집단의 경우 제품 범주별 수익 내역(차익금 비율, 전체 수익 모두)은 어떠한가? BI 분야에서는 단순히 ‘이번 달 매출액이 얼마인가?’ 이렇게 물어보지 않고 여러 각도로 정보를 구성하여 원하는 정보를 추출하기를 원한다. OLAP는 결과 산출을 빠르게 하기 위해 다양한 차원들에 대해 선계산 값을 미리 산출하여 OLAP 큐브라는 데이터 구조로 측정값을 저장한다. 즉, 큐브는 시간, 지역, 제품군 등 여러 차원(Dimension)을 판매량, 재고량과 같은 측정값(Measure)으로 요약한 데이터이다. [OLAP Cube example 1] [OLAP Cube example 2] 위와 같은 OLAP 큐브가 구축되어 있다면 다음과 같은 쿼리를 처리할 수 있게 된다. 올해 가장 매출이 저조한 대리점과 저조한 상품 품목은? 서울지역에서 가장 매출이 높은 상품과 순이익이 가장 높은 상품은? 지역별로 전월 대비 매출이 가장 높은 상품은? OLAP을 하기 위해서는 OLTP(On-Line Transaction Processing)이 선행되어야 한다.OLAP 큐브를 만들기 위해서는 여러 관계형 데이터들을 집약한 Data Warehouse가 필요하다. 관계형 데이터는 OLTP라는 영역에서 데이터를 수집한다. OLTP (OnLine Transaction Processing)Batch 와 반대되는 개념으로 실시간으로 db의 데이터를 트랜잭션 단위로 갱신/조회하는 처리방식. 은행, 증권사 등에서 씀. 기존과 달리 다수의 client가 거의 동시에 이용할수 있도록 송수신자료를 트랜잭션단위로 압축한것이 특징. DW (Data Warehouse)OLTP에서 발생한 데이터를 모아서 주제별로 합쳐 분석하기 편한 형태로 통합한 데이터 시스템 OLAP의 더 자세한 내용에 대해서는 다음 링크들을 참조하자. http://12bme.tistory.com/144 http://egloos.zum.com/carrpediem/v/2459408 http://118k.tistory.com/66 http://olap.com/olap-definition/ http://i-bada.blogspot.kr/2014/01/olap-online-analytical-processing.html https://galaktikasoft.com/blog/olap-glossary.html https://support.office.com/ko-kr/article/olap-online-analytical-processing-%EA%B0%9C%EC%9A%94-15d2cdde-f70b-4277-b009-ed732b75fdd6 https://en.wikipedia.org/wiki/OLAP_cube Druid의 Key Features 1초 미만의 OLAP 쿼리 가능 (Sub-second OLAP Queries): 드루이드는 신속한 다차원 필터링, 임시 어트리뷰트 그룹핑 및 매우 빠른 집계(Aggregation)가 가능하다. 실시간 스트리밍 집계 (Real-time Streaming Ingestion): 드루이드는 락(Lock)없는 실시간 수집을 사용하여 대량의 데이터를 받음과 동시에 쿼리 실행이 가능하다. 강력한 분석 도구 (Power Analytic Applications): 드루이드는 수천 명의 동시 사용자가 사용할 수 있도록 설계된 강력한 사용자 지향 분석 어플리케이션이다. 효율적인 비용 (Cost Effective) 높은 가용성 (Highly Available) 확장성 (Scalable) Druid는 언제 써야할까?드루이드는 다음과 같은 요구사항에 적합하다. 빠른 집계 및 OLAP 쿼리가 필요한 응용 프로그램을 개발할 때 실시간 분석을 원하면서 굉장히 많은 데이터를 다룰 때 (조 단위의 이벤트 로우 수, 페타 바이트의 데이터) 실패 없이 항상 사용할 수 있는 데이터 저장소가 필요할 때 현재 드루이드 공식 사이트에서 소개하고 있는 프로덕션 드루이드 클러스터 성공 사례의 규모는 다음과 같다고 한다. 3+ trillion events/month (3조 이벤트/1개월) 3M+ events/sec through Druid’s real-time ingestion (초당 3백만 이벤트를 드루이드에 실시간 입수) 100+ PB of raw data (100 페타 바이트의 로우 데이터) 50+ trillion events (50조 이벤트) Thousands of queries per second for applications used by thousands of users (수천명 유저에 의한 초당 수천 쿼리 실행) Tens of thousands of cores (수만 개의 코어) 다만 주의할 점은 드루이드는 현재 Dremel 및 PowerDrill과 유사한 방식으로 싱글 테이블 쿼리만 허용하며 테이블 간 JOIN은 할 수 없다. 하지만 아래와 같은 장점이 추가되었다. 중첩된 데이터 구조를 가지는 컬럼 기반의 스토리지 포멧 중간 정리가 있는 계층적인 쿼리 분산 빠른 필터링을 위한 인덱싱 실시간 집계 (집계된 데이터는 즉시 쿼리가 가능함) 내장애성을 지닌 데이터 손실염려가 없는 분산 구조 Druid Architecture드루이드는 각기 다른 역할을 가진 서비스로 구성되어 있다. 각 서비스는 작은 일을 잘 처리하도록 설계되어 있다. Historical Nodes히스토리컬 노드는 드루이드 클러스터의 핵심이다. 히스토리컬 노드는 딥 스토리지에서 세그먼트를 다운로드하고 이러한 세그먼트에 대한 브로커 노드의 쿼리 실행을 하여 결과를 브로커 노드에 반환한다. 히스토리컬 노드는 데이터를 공유하지 않으며 Zookeeper를 통하여 세그먼트 로드, 세그먼트 삭제를 모니터링한다. Broker Nodes브로커 노드를 통해 쿼리를 받고 데이터를 제공한다. 브로커 노드는 쿼리 분산 실행 및 결과 수집, 병합을 담당한다. 브로커 노드도 쿼리 실행을 위해 Real-time 노드와 히스토리컬 노드가 어떤 것인지를 판단할 때 Zookeeper를 사용한다. Coordinator Nodes코디네이터 노드는 드루이드 클러스터의 히스토리컬 노드에 있는 세그먼트를 관리한다. 코디네이터 노드는 히스토리컬 노드에 새로운 세그먼트를 로드, 이전 세그먼트 삭제 및 균형을 맞추기 위한 세그먼트 이동을 지시한다. (히스토리컬 노드에 지시하기 위해 Zookeeper를 사용) Realtime Nodes드루이드에서 실시간 처리는 독립형 실시간 노드를 사용하거나 인덱싱 서비스로 할 수 있다. 실시간 처리 로직은 두 서비스가 동일하다. 실시간 처리는 데이터 수집, 데이터 인덱싱 (세그먼트 작성) 및 세그먼트를 히스토리컬 노드에 전달한다. 실시간 처리 로직에 의해 집계된 데이터는 즉시 질의가 가능하다. 그 외 드루이드는 3가지 외부 디펜던시가 포함된다. Zookeeper: 클러스터 내부에서의 서비스 디스커버리 및 데이터 토폴로지의 운영 Metadata storage instance: 세그먼트에 대한 메타데이터를 관리하기 위한 메타 데이터 저장소 Deep Storage LOB store/file system: 세그먼트를 저장하기 위한 딥 스토리지 LOB 저장소/파일 시스템 여기서 잠깐! 세그먼트가 뭐지? (세그먼트와 딥 스토리지)드루이드로 데이터가 입수(Batch Ingestion or Streaming Ingestion)되면 인덱싱 처리가 진행된다. 여기서 인덱싱 작업이란 다음과 같다. 데이터를 컬럼 기반 포멧의 형태로 변경 비트맵 인덱스를 활용한 데이터 색인 작업 다양한 알고리즘을 이용한 데이터 압축 이러한 인덱싱 작업을 거친 결과물을 드루이드에서는 세그먼트(Segment)라고 부른다. 세그먼트는 드루이드에서 데이터를 저장하는 기본 구조인 것이다. 세그먼트는 컬럼 기반으로 저장된 여러 개의 차원(Dimension)과 측정값(Metrics)를 포함하며 각 컬럼별로 인덱싱이 되어 있다.세그먼트는 딥 스토리지(Deep Storage)라는 LOB / 파일 시스템에 저장된다. 그 후 데이터는 히스토리컬 노드의 로컬에 다운로드 되고 쿼리 실행하기 전에 메모리에 로딩된다. 히스토리컬 노드 하나가 죽어도 딥 스토리지에는 세그먼트가 있기 때문에 다른 히스토리컬 노드에서 쿼리 서비스를 제공한다. Batch Ingestion in Druid먼저 아래와 같은 이벤트 데이터가 있다고 가정하자. timestamp publisher advertiser gender country click price 2011-01-01T01:01:35Z bieberfever.com google.com Male USA 0 0.65 2011-01-01T01:03:63Z bieberfever.com google.com Male USA 0 0.62 2011-01-01T01:04:51Z bieberfever.com google.com Male USA 1 0.45 2011-01-01T01:00:00Z ultratrimfast.com google.com Female UK 0 0.87 2011-01-01T02:00:00Z ultratrimfast.com google.com Female UK 0 0.99 2011-01-01T02:00:00Z ultratrimfast.com google.com Female UK 1 1.53 드루이드는 이 데이터의 구조를 세 가지 요소로 분류한다. Timestamp columns Dimension columns Metric columns Timestamp 컬럼은 말 그대로 시간이 저장된 컬럼을 말하며 Dimension은 이벤트에서 각각의 컬럼을 말하며 필터링에 사용된다. 위 예에서 Dimension은 publisher, advertiser, gender, country를 말한다. Metric은 결합(Aggregation)과 계산(Computation)에서 사용되는 컬럼이다. 위 예에서는 click, price가 해당된다. Metric은 보통 count, sum, mean을 계산할 수 있는 숫자 타입이다. 드루이드는 기본적으로 데이터를 세그먼트 단위로 샤딩하며 샤딩 기준은 시간이다. (데이터 파편화에 대해서는 추후 다시 설명) Roll-up예제 데이터가 하루에 조 단위로 들어온다면 우리가 원하는 분석 결과를 빠르게 얻어서 인사이트를 찾아낼 수 있을까? 이러한 이벤트 데이터의 분석을 좀 더 빠르게 하기 위해 요약하는 작업을 Roll-up이라고 부른다.드루이드에서 아래와 같이 롤업 규칙을 정하면 규칙에 따라 요약 데이터가 생성된다. (여기서 아래 규칙은 수도코드임) GROUP BY timestamp, publisher, advertiser, gender, country :: impressions = COUNT(1), clicks = SUM(click), revenue = SUM(price) timestamp publisher advertiser gender country impressions clicks revenue 2011-01-01T01:00:00Z ultratrimfast.com google.com Male USA 1800 25 15.70 2011-01-01T01:00:00Z bieberfever.com google.com Male USA 2912 42 29.18 2011-01-01T02:00:00Z ultratrimfast.com google.com Male UK 1953 17 17.31 2011-01-01T02:00:00Z bieberfever.com google.com Male UK 3194 170 34.01 이렇게 데이터를 롤업하면 데이터의 크기를 줄일 수 있다. 롤업 시간기준은 최대 밀리 초까지 지원한다고 한다. Batch Ingestion Example{ &quot;type&quot; : &quot;index_hadoop&quot;, &quot;spec&quot; : { &quot;ioConfig&quot; : { &quot;type&quot; : &quot;hadoop&quot;, &quot;inputSpec&quot; : { &quot;type&quot; : &quot;granularity&quot;, &quot;dataGranularity&quot;: &quot;day&quot;, &quot;inputPath&quot;: &quot;/path/to/hdfs/hive_table&quot;, &quot;filePattern&quot;: &quot;.+&quot;, &quot;pathFormat&quot;: &quot;&#39;time&#39;=yyyyMMdd&#39;00&#39;&quot; } }, &quot;dataSchema&quot; : { &quot;dataSource&quot; : &quot;hive_table_druid_data_source&quot;, &quot;granularitySpec&quot; : { &quot;type&quot; : &quot;uniform&quot;, &quot;rollup&quot;: &quot;false&quot;, &quot;segmentGranularity&quot; : { &quot;type&quot;: &quot;period&quot;, &quot;period&quot;: &quot;P1D&quot;, &quot;timeZone&quot;: &quot;Asia/Seoul&quot; }, &quot;queryGranularity&quot; : &quot;none&quot;, &quot;intervals&quot; : [&quot;2017-11-26/2018-02-26&quot;] }, &quot;parser&quot; : { &quot;type&quot; : &quot;hadoopyString&quot;, &quot;parseSpec&quot; : { &quot;format&quot; : &quot;tsv&quot;, &quot;listDelimiter&quot;:&quot;,&quot;, &quot;columns&quot;: [ &quot;user_id&quot;, &quot;col001&quot;,&quot;col002&quot;,&quot;col003&quot;,&quot;col004&quot;,&quot;col005&quot;,&quot;col006&quot;,&quot;col007&quot;,&quot;col008&quot;,&quot;col009&quot;,&quot;col010&quot;, &quot;product_id&quot;,&quot;log_time&quot; ], &quot;dimensionsSpec&quot; : { &quot;dimensions&quot; : [ &quot;user_id&quot;, &quot;col004&quot;,&quot;col005&quot;,&quot;col009&quot;, &quot;product_id&quot;,&quot;log_time&quot; ] }, &quot;timestampSpec&quot; : { &quot;format&quot; : &quot;yyyyMMddHH&quot;, &quot;column&quot; : &quot;log_time&quot; } } }, &quot;metricsSpec&quot; : [ { &quot;type&quot; : &quot;longSum&quot;, &quot;name&quot; : &quot;audience_count&quot;, &quot;fieldName&quot;: &quot;user_id&quot; } ] }, &quot;tuningConfig&quot; : { &quot;type&quot; : &quot;hadoop&quot;, &quot;partitionsSpec&quot; : { &quot;type&quot; : &quot;hashed&quot;, &quot;targetPartitionSize&quot; : 100000 }, &quot;jobProperties&quot; : { &quot;mapreduce.user.classpath.first&quot;: &quot;true&quot; } } } } Druid Querying드루이드에서는 먼저 브로커에서 쿼리 실행을 받으면 세그먼트에 따라 쿼리를 재작성하여 히스토리컬 노드 혹은 리얼타임 노드에게 쿼리 실행을 위임한다. 브로커 노드는 결국 결과를 모으로 머지하여 최종 결과를 반환한다. Druid에서 할 수 있는 쿼리는 다음과 같다. Aggregation Queries Timeseries TopN GroupBy Metadata Queries Time Boundary Segment Metadata Datasource Metadata Search Queries Search 참고 자료 http://12bme.tistory.com/144 http://egloos.zum.com/carrpediem/v/2459408 http://118k.tistory.com/66 http://olap.com/olap-definition/ http://i-bada.blogspot.kr/2014/01/olap-online-analytical-processing.html https://galaktikasoft.com/blog/olap-glossary.html https://support.office.com/ko-kr/article/olap-online-analytical-processing-%EA%B0%9C%EC%9A%94-15d2cdde-f70b-4277-b009-ed732b75fdd6 https://en.wikipedia.org/wiki/OLAP_cube- http://egloos.zum.com/carrpediem/v/2459408 http://druid.io https://github.com/druid-io/druid https://en.wikipedia.org/wiki/Online_analytical_processing http://www.popit.kr/time-series-olap-druid-%EC%9E%85%EB%AC%B8/","categories":[],"tags":[]},{"title":"Java Web 개발 살펴보기 (Model 1 부터 Spring Web 까지)","slug":"20170904-java-web-develop-with-spring","date":"2017-09-04T00:38:14.000Z","updated":"2018-11-27T06:40:43.299Z","comments":true,"path":"2017/09/04/20170904-java-web-develop-with-spring/","link":"","permalink":"http://icednut.github.io/2017/09/04/20170904-java-web-develop-with-spring/","excerpt":"","text":"Java Web 개발 살펴보기 (Model 1 부터 Spring Web 까지)스프링 스터디를 하면서 정리한 Java 웹 개발 변천사를 포스팅 한다. Java Web 개발 과정은 다음과 같으며, 여유가 된다면 곁가지로 파생되는 기술들인 Servlet 3.x, WebSocket, Async I/O, Spring 5 (WebFlux)까지 해보려 한다. 일단 아래 내용들을 따라가기 전에 실습 환경 셋팅을 해야 한다. Java Servlet 개발 실습 환경 셋팅실습에 사용할 IDE와 라이브러리, 빌드툴은 다음과 같다. IntelliJ IDEA 2017 JDK 1.8 Java Servlet 3.1 Gradle 4.x 실습 프로젝트 생성 과정은 다음과 같다. IntelliJ IDEA &gt; 메뉴 표시줄 &gt; File &gt; New &gt; Project를 클릭 왼쪽에서 Gradle 이라는 항목을 클릭 후 Java, Web 체크 박스에 체크 후 Next 적당한 GroupId와 ArtifactID 입력 후 Next Create seperate module per source set 체크 박스 해제 후 Next Project Name 확인 후 Finish 버튼 클릭하면 프로젝트가 생성되며 Gradle wrapper가 다운로드 되며 프로젝트가 로딩 된다. 프로젝트 루트에 있는 build.gradle 파일을 열어서 dependencies 부분에 아래 내용을 붙여넣는다.dependencies { compile group: 'javax.servlet', name: 'javax.servlet-api', version: '3.1.0' testCompile group: 'junit', name: 'junit', version: '4.12' } 메뉴 표시줄 &gt; View &gt; Tool Windows &gt; Web을 클릭하면 왼쪽 하단에 Web 설정 관련 패널이 표시된다. 오른쪽 클릭 후 Module Settings 클릭하면 모듈 설정 창이 뜬다. 여기서 아래 스크린샷과 같이 war파일 항목을 클릭하여 포커싱 한다. 중간에 위치한 Add Application Server specific descriptor… 버튼 바로 위에 있는 + 버튼을 클릭하면 web.xml이라는 항목이 표시되는데 이걸 클릭하자. 서블릿 버전과 서블릿 설정 파일인 web.xml의 위치를 어디로 할 것인가를 묻는 다이얼로그가 뜨는데 web.xml 파일의 위치는 다음과 같이 입력한다.${PROJECT_ROOT}/web/WEB-INF/web.xml 아래 Web Resource Directories에 Web Resource Directory 항목을 더블클릭 한다. JSP가 위치할 폴더를 물어보는 다이얼로그가 뜨는데 이 때 아래 경로를 입력한다.${PROJECT_ROOT}/web 마지막으로 src/main/webapp 폴더는 삭제한다. (해당 폴더는 더이상 사용하지 않기 때문) 실습 프로젝트 실행을 위한 준비 과정은 다음과 같다. IntelliJ IDEA &gt; 메뉴 표시줄 &gt; Run &gt; Edit Configurations… 클릭 왼쪽 상단에 + 버튼 클릭 &gt; Tomcat Server &gt; Local 클릭 아래와 같은 다이얼로그가 뜨면 다이얼로그 상단에 위치한 Name 항목에 적당한 이름을 입력 후 오른쪽 하단에 Fix 버튼을 클릭한다. 아래와 같이 ooo.war (exploded) 항목을 클릭한다. (디버깅을 위해 war 파일을 푼 형태로 실행) 그 다음 OK 버튼을 클릭하여 설정을 완료한다. ${PROJECT_ROOT}/web 폴더 아래에 index.jsp 파일을 생성하고 아래 내용을 입력한다. Hello! Hello, world! IntelliJ 상단 툴바에 있는 실행 버튼을 클릭하여 실행 &gt; 브라우저가 자동으로 뜨면서 Hello, world가 보이면 성공 Model 1 Only view code (JSP) 옛 PHP 개발 방식과 유사하다. JSP 파일 안에 모든 비지니스 로직과 View 로직(html)을 함께 넣은 형식 예제 실습 (스프링 퀵 스타트 P.241 ~ P.262) P.244 - 로그인 구현 (login.jsp) P.247 - 로그인 인증처리 (login_proc.jsp) P.249 - 글 목록 (getBoardList.jsp) P.252 - 글 상세 보기 (getBoard.jsp) P.255 - 글 등록 (insertBoard.jsp) P.256 - 글 등록 처리 (insertBoard_proc.jsp) P.258 - 글 수정 처리 (updateBoard_proc.jsp) P.260 - 글 삭제 (deleteBoard_proc.jsp) P.261 - 로그아웃 (logout_proc.jsp) Model 2 Model 1의 view 코드에서 진짜 view를 담당하는 코드(html, jsp)과 view에 바인딩할 데이터를 로딩하는 로직(controller)으로 나눠진 형태 이제 view에서는 비지니스 로직과 DB 액세스 로직이 없어지게 된다. Model 2는 MVC (Model, View, Controller)라고도 불린다. 예제 실습 (스프링 퀵 스타트 P.265 ~ P.284) P.267 - 서블릿 클래스 등록 &amp; Controller 서블릿 구현 P.270 - 로그인 기능 구현 (DispatcherServlet.java, login.jsp) P.272 - 글 목록 (DispatcherServlet.java, getBoardList.jsp) P.275 - 글 상세보기 (DispatcherServlet.java, getBoardList.jsp, getBoard.jsp) P.277 - 글 등록 (DispatcherServlet.java, insertBoard.jsp) P.279 - 글 수정 (DispatcherServlet.java, getBoard.jsp) P.280 - 글 삭제 (DispatcherServlet.java, getBoard.jsp) P.280 - 로그아웃 (DispatcherServlet.java, getBoard.jsp) Advanced Model 2 앞에서 소개한 Model 2의 방식으로 코딩하다보면 중복되는 코드가 생겨남 이런 중복되는 로직을 좀 더 객체지향적으로 리팩토링한 방식 Spring WebMVC가 탄생하기 전 MVC 프레임워크를 직접 개발해 보는 것으로 책은 소개하고 있다. 예제 실습 (스프링 퀵 스타트 P.285 ~ P.311) P.288 - Controller 인터페이스 작성 (Controller.java) P.289 - LoginController 구현 (LoginController.java) P.290 - HandlerMapping 구현 (HandlerMapping.java) P.291 - ViewResolver 구현 (ViewResolver.java) P.292 - DispatcherServlet 수정, hadnlerMapping과 viewResolver를 dispatcherServlet에 추가 (DispatcherServlet.java) P.295 - 글 목록 검색 구현 (GetBoardListController.java, HandlerMapping.java) P.296 - 글 상세보기 구현 (GetBoardController.java, HandlerMapping.java) P.297 - 글 등록 구현 (InsertBoardController.java, HandlerMapping.java) P.300 - 글 수정 구현 (UpdateBoardController.java, HandlerMapping.java) P.302 - 글 삭제 구현 (DeleteBoardController.java, HandlerMapping.java) P.303 - 로그아웃 구현 (LogoutController.java, HandlerMapping.java) P.308 - 상세화면 페이지에 EL/JSTL 적용하기 (getBoard.jsp) P.310 - 글 목록 페이지에 EL/JSTL 적용하기 (getBoardList.jsp) Spring WebMVC (with XML Configuration) Model 2를 처음 개발하는 사람도 일관성 있게 코딩하기 위해 나온 웹 프레임워크 이 웹 프레임워크를 사용하기 위해 web infrastructure 관련 bean들이 필요한데 이러한 bean을 사용하기 위한 설정을 xml로 한 형태를 말한다. 스프링 웹MVC를 쓰면 처음 개발하는 사람도 이전의 개발 이슈들을 극복한 일관성 있는 코딩을 할 수 있게 될거라 기대하지만.. 막상 해보면 스프링 웹MVC를 쓰기 위한 Web infrastructure Bean들을 대충 뭐가 있는지 정도는 알아야 뭘 어떻게 설정하고 컨트롤러는 어떻게 써야되는 것인지 감이 잡힌다. (이게 초기 학습 장벽) 참고로 Servlet 클래스는 DispatcherServlet 하나만 사용한다. (오해하면 안되는게 서블릿 객체를 하나만 사용한다는 말이 아님) 예제 실습 (스프링 퀵 스타트 P.313 ~ 346) P.315 - Spring DispatcherServlet 등록 (web.xml) P.320 - WEB-INF/config 폴더에 스프링 설정 파일 등록 (presentation-layer.xml) P.322 - 인코딩 설정 (web.xml) P.326 - 로그인 기능 구현 (LoginController.java) P.328 - 핸들러 맵핑 등록 (presentation-layer.xml) P.329 - 글 목록 기능 구현 (GetBoardListController.java) P.331 - 핸들러 맵핑 등록 (presentation-layer.xml) P.333 - 글 상세조회 기능 구현 (GetBoardController.java) P.334 - 핸들러 맵핑 등록 (presentation-layer.xml) P.335 - 글 등록 기능 구현 (InsertBoardController.java) P.336 - 핸들러 맵핑 등록 (presentation-layer.xml) P.337 - 글 수정 기능 구현 (UpdateBoardController.java) P.339 - 글 삭제 기능 구현 (DeleteBoardController.java) P.340 - 로그아웃 기능 구현 (LogoutController.java) P.342 ~ 345 - ViewResolver 적용 (presentation-layer.xml) Spring WebMVC (with XML Configuration &amp; Annotation) 앞의 방식에서 Controller와 url 맵핑을 Java Annotation을 사용한 형태 이 방식을 취하면 XML에 웹 관련 설정(url 맵핑 설정)이 사라지게 된다. 스프링은 이렇게 점점 설정을 줄여가는 방식으로 발전됨 왜? 설정을 찾아서 적는 일도 고된 일이고 프로젝트를 할 때마다 설정을 복사 &amp; 붙여넣기를 해야되는 중복 작업을 줄일 수 있기 때문 예제 실습 (스프링 퀵 스타트 P.349 ~ 417) P.350 ~ P.353 - @Controller 적용하기 (InsertBoardController.java) P.354 ~ P.361 - @RequestMapping 적용하기 (InsertBoardController.java, presentation-layer.xml) P.363 - 글 등록 (InsertBoardController.java) P.365 - 글 목록 (GetBoardListController.java) P.366 - 글 상세보기 (GetBoardController.java) P.367 - 글 수정 (UpdateBoardController.java) P.368 - 글 삭제 (DeleteBoardController.java) P.369 - 로그인 (LoginController.java) P.370 - 로그아웃 (LogoutController.java) P.371 - 컨트롤러 통합 (BoardController.java) P.373 - 요청 방식에 따른 처리 구현 (LoginController.java) P.375 - JSP에서 Command 객체 사용 (login.jsp) P.377 - @ModelAttribute 사용 (LoginController.java, login.jsp) P.378 - Controller에서 Servlet API 사용 (LoginController.java, getBoardList.jsp) P.380 - Controller 리턴타입 이해 (BoardController.java) P.382 - @RequestParam 사용 (getBoardList.jsp, BoardController.java) P.385 - @ModelAttribute 사용 (BoardController.java, getBoardList.jsp) P.388 - @SessionAttributes 사용 (BoardController.java) P.397 ~ P.408 - 비지니스 레이어(Service 클래스) 리팩토링 (BoardController.java, BoardServiceImpl.java, presentation-layer.xml) P.409 ~ P.417 - 글 검색 기능 보완 곁다리로 빠지기 파일 업로드: 스프링 퀵 스타트 P.419 ~ 434 다국어 처리: 스프링 퀵 스타트 P.435 ~ 450 JSON View: 스프링 퀵 스타트 P.451 ~ 464 Spring WebMVC (with Java Configuration &amp; Annotation) Spring에서 어느 순간 XML을 이용한 Bean 설정 방식 보다 Java 클래스를 이용한 Bean 설정 방식이 대두되기 시작함 Java 설정 방식이 점차 늘어가는 이유는 Infrastructure 관련 Bean들을 좀 더 찾기 쉽고 디버깅 및 이해하기 쉽기 때문에 이 방식이 선호됨 Spring 뿐만 아니라 Java Servlet도 마찬가지로 web.xml이 사라지고 Java Class와 Annotation으로 서블릿 설정할 수 있게 된다. (servlet 3.0) 예제 실습 준비 중.. Spring WebMVC (with Spring Boot Web Starter) 이젠 스프링 Infrastructure Bean 선언하는 것도 귀찮다! 혹은 스프링 설정하는게 너무 어렵다! 하는 요구가 늘어남에 따라 Spring팀에서는 Spring-boot 라는 것을 내놓게 된다. 사람들이 왜 spring-boot를 열광하게 되냐 하면 Java annotation 선언 하나만으로 스프링 Infrastructure Bean들이 자동으로 선언되고 로딩된다. (즉 사용자가 더 이상 스프링에 대한 설정을 잘 몰라도 사용할 수 있게 된다는 의미) 예제 실습 준비 중.. Spring WebFlux &amp; Reactor (Spring Framework 5.x) Spring WebFlux에서는 Java Servlet이 사라짐 따라서 더 이상 war 파일로 패키징하지 않음 웹 요청을 받는 인프라스트럭쳐가 Reactive, Functional Programming 스타일로 바뀜 예제 실습 준비 중.. 참고자료 https://docs.spring.io/spring/docs/5.0.0.RC3/spring-framework-reference/web.html#spring-web 책 스프링 퀵 스타트","categories":[],"tags":[{"name":"spring","slug":"spring","permalink":"http://icednut.github.io/tags/spring/"},{"name":"java","slug":"java","permalink":"http://icednut.github.io/tags/java/"},{"name":"servlet","slug":"servlet","permalink":"http://icednut.github.io/tags/servlet/"},{"name":"spring mvc","slug":"spring-mvc","permalink":"http://icednut.github.io/tags/spring-mvc/"},{"name":"spring 5","slug":"spring-5","permalink":"http://icednut.github.io/tags/spring-5/"}]},{"title":"Spark SQL을 이용하여 avro 파일과 parquet 파일 다루기","slug":"20170902-spark-sql-with-avro-parquet","date":"2017-09-02T06:38:55.000Z","updated":"2018-11-27T06:40:43.293Z","comments":true,"path":"2017/09/02/20170902-spark-sql-with-avro-parquet/","link":"","permalink":"http://icednut.github.io/2017/09/02/20170902-spark-sql-with-avro-parquet/","excerpt":"","text":"준비Scala &amp; Spark SQL에서 avro, parquet 파일을 읽고 쓰는 것은 어떻게 하는지 그리고 간단한 예제를 통해 실습한 내용을 정리한다. (avro와 parquet에 대한 설명은 여기서는 생략)먼저 아래 내용들을 통해 실습 환경을 셋팅하자. CDH 설치 Google에서 Cloudera CDH 검색 CDH &gt; quickstart Virtual Box 버전을 다운로드 압축 해제 후 Virtual Box에서 실행 sqoop을 통한 avro 파일로 hdfs에 import 작업 진행 hdfs의 적당한 곳에 디렉토리를 생성한다.$ hdfs dfs -mkdir /user/cloudera/test_avro_warehouse sqoop을 통해 MySQL 데이터를 HDFS로 import 한다. (파일 포맷은 avro. 압축 형태는 snappy)$ sqoop import-all-tables \\ -m 1 \\ --connect jdbc:mysql://quickstart:3306/retail_db \\ --username=retail_dba \\ --password=cloudera \\ --as-avrodatafile \\ --compression-codec=snappy \\ --warehouse-dir=/user/cloudera/test_avro_warehouse 이번에는 parquet 파일로 hdfs에 import 진행 sqoop을 통해 MySQL 데이터를 HDFS로 import 한다. (파일 포맷은 parquet. 압축 형태는 snappy)$ sqoop import-all-tables \\ -m 1 \\ --connect jdbc:mysql://quickstart:3306/retail_db \\ --username=retail_dba \\ --password=cloudera \\ --as-parquetfile \\ --compression-codec=snappy \\ --warehouse-dir=/user/cloudera/test_avro_warehouse spark-shell 실행 $ spark-shell AvroSpark에서 avro 파일을 읽고 쓰려면 avro 관련 라이브러리를 import 해야 된다. import com.databricks.spark.avro._ 그 다음 sqlContext.read.avro(“…”) 혹은 sqlContext().read.format(“com.databricsk.spark.avro”).load(“…”)을 통해 파일을 읽는다. import com.databricks.spark.avro._ val df = sqlContext.read.avro(\"input dir\") import com.databricks.spark.avro._ val df = sqlContext.read.format(\"com.databricks.spark.avro\").load(\"input dir\") 연습1. hdfs://quickstart/user/cloudera/test_avro_warehouse/orders에서 order_status가 COMPLETE 면서 customer_id 별로 주문을 몇건씩 했는지 살펴본 뒤 결과는 parquet로 저장 해보자. (parquet 압축은 gzip)import com.databricks.spark.avro._ import org.apache.spark.sql._ val ordersDf = sqlContext.read.avro(\"/user/cloudera/test_avro_warehouse/orders\") val countRdd = ordersDf.filter(\"order_status = 'COMPLETE'\").map(row => (row.getAs[Integer](\"order_customer_id\"), 1)).reduceByKey(_ + _).map(pair => Row(pair._1, pair._2)) sqlContext.setConf(\"spark.sql.parquet.compression.codec\", \"gzip\") val schema = StructType( StructField(\"customer_id\", IntegerType, false) :: StructField(\"count\", IntegerType, false) :: Nil ) val countDf = sqlContext.createDataFrame(countRdd, schema) countDf.write.parquet(\"/user/cloudera/test_parquet_warehouse/orders_count\") 연습2. json 파일을 읽어서 HDFS에 avro 파일로 저장해보자. (with snappy compression)import com.databricks.spark.avro._ val personJsonDf = sqlContext.read.json(\"/user/cloudera/test_json_warehouse\") sqlContext.setConf(\"spark.sql.avro.compression.codec\", \"snappy\") personJsonDf.write.avro(\"/user/cloudera/test_avro_warehouse/person\") val personAvroDf = sqlContext.read.avro(\"/user/cloudera/test_avro_warehouse/person\") personAvroDf.printSchema() personAvroDf.show(3) ParquetParquet 파일을 다룰 때는 따로 import 해줘야할 라이브러리가 없다. 그냥 sqlContext.read.parquet(&quot;inpurt file&quot;)을 통해 parquet 파일을 읽으면 된다. 연습3. hdfs://quickstart/user/cloudera/test_parquet_warehouse/orders을 읽어서 HDFS에 avro 파일로 저장해보자.import com.databricks.spark.avro._ val ordersCountDf = sqlContext.read.parquet(\"/user/cloudera/test_parquet_warehouse/orders_count\") sqlContext.setConf(\"spark.sql.avro.compression.codec\", \"snappy\") ordersCountDf.write.avro(\"/user/cloudera/test_avro_warehouse/orders_count\") 참고 자료 https://www.cloudera.com/more/training/certification/cca-spark.html https://www.cloudera.com/documentation/enterprise/latest/topics/cdh_ig_avro_usage.html#concept_okv_lwy_pv https://www.cloudera.com/documentation/enterprise/latest/topics/spark_avro.html","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"http://icednut.github.io/tags/spark/"},{"name":"scala","slug":"scala","permalink":"http://icednut.github.io/tags/scala/"},{"name":"avro","slug":"avro","permalink":"http://icednut.github.io/tags/avro/"},{"name":"parquet","slug":"parquet","permalink":"http://icednut.github.io/tags/parquet/"}]},{"title":"Oracle Code Seoul","slug":"20170830-oracle-code-seoul","date":"2017-08-30T00:00:12.000Z","updated":"2018-11-27T06:40:43.283Z","comments":true,"path":"2017/08/30/20170830-oracle-code-seoul/","link":"","permalink":"http://icednut.github.io/2017/08/30/20170830-oracle-code-seoul/","excerpt":"","text":"CQRS를 언제, 왜, 그리고 어떻게 사용할 것인가? CQRS Motivation: 기존 방식의 CRUD Application으로는 상태 정보를 관리하기 힘듬 (따로 구현해야 됨). 상태 정보를 저장할 수 있도록 구현이 필요. DB를 하나만 쓰는 것이 아닌 확장성을 고려한 개발 필요 Event Sourcing: DB에 현재 상태를 계속 저장. 이에 따라 상태 재생이 가능하게 되고 테스팅이 용이해진다. (Event는 atomic, immutable 해야 된다.) Event Driven Architecture collaboration needed. 주문 시스템을 보면 주문 시 모든 시스템이 Lock이 걸린 뒤 주문을 처리하지 않는다. 각 시스템이 용이하게 운영될 수 있도록 이벤트를 통해 분산 시스템이 될 수 있어야 함. (comminication via events, published reliably) split-up transations. 주문이 시작되면 여러 개의 트랜잭션으로 나눠지는데 이 때문에 일관성 확보가 가능해짐(?) Command Query Responsability Segregation 읽기와 쓰기를 분리. command는 이벤트 방식으로 전달. 읽기와 쓰기를 연결하는 것은 Event Store. Event Store에서의 상태 정보는 IMDG로도 관리할 수 있다. (ex: 커피 주문 시작은 CommandService에서 처리하면 이벤트 스토어로 이벤트를 날린 뒤 QueryService로 이벤트를 전달하여 주문 정보를 저장.) 분산 시스템이 아닌 단일 시스템에 CQRS를 적용하는 것은 오버헤드를 늘리는 꼴이 될 수도 있다. CQRS에서는 읽기 DB와 쓰기 DB 등 서비스 별로 여러 개가 있을 수 있는데 동기화를 할 필요가 없다. (동기화는 좋은 생각이 아님) 오히려 이벤트를 통한 일관성 확보가 중요. CQRS를 통해 어떤 문제를 해결할 수 있을까? 일반적인 CRUD 방식보다 확장성이 좋다. 또한 읽기서비스에서 failover가 가능해진다. Demo 시연 Java EE &amp; Kafka를 활용한 커피 주문 시스템 구현 https://github.com/sdaschner/scalable-coffee-shop 참고로 Oracld Event Hub에서 카프카를 사용할 수 있다. 더 자세한 데모 설명은 sebastian-daschner.com을 참조. Java 9와 Spring 5로 바라보는 Java의 미래 2017/09/21 java 9과 spring 5이 출시될 예정 Java는 위기를 맞이하면서 발전을 거듭해 왔다. Java 위기 1 서블릿, EJB, JSP, 크고 무거운 WAS, 다양한 웹 프레임워크 등 코드가 복잡해짐. 자바 객체지향의 기본으로 돌아가자는 움직임이 일어남. Java 위기 2 언어 발전의 요구와 호환성 언어 발전과 구버전의 하위 호환성 둘 다 잡아야 되는 상황 발생. 다행히 Java는 언어 발전과 함께 하위 호환성도 지킴. Java 위기 3 간결하고 관례를 통한 개발 움직임이 대두되기 시작. (특히 Ruby) Java에서도 Annotation이 등장하면서 관례 적용이 시작됨 Java 위기 4 함수형 프로그래밍과 비동기 논블로킹 개발의 도전 대두 대용량 비동기 논블로킹 프로그래밍으로는 함수형 프로그래밍이 좋다고 보는 시각이 늘어남. Java 9과 Spring 5 새로운 위기: 애노테이션, 메타프로그래밍, 관례의 범람 어노테이션은 코드 행위를 규정하는 것이 아닌 메타 정보를 담는다. 상속, 확장이 없음. 따라서 어노테이션은 테스트가 불가. 또한 메타 어노테이션에 대한 동작 규정이 없음 (ex: @Controller) Relection과 런타임 바이트코드 생성의 문제는 테스트, 디버깅이 힘들고 성능이 저하됨 이 위기를 어떻게 극복할까? 함수형 스타일의 자바 웹 코드로 전환 (리액티브, 함수의 조함, 불변객체 사용) Spring 5에서는 더 이상 서블릿을 안써도 된다. HandlerFunction, RouterFunction을 사용 Java 9 Java 9에는 Flow API와 Reactive Streams가 추가 된다고 한다.","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://icednut.github.io/tags/Java/"}]},{"title":"앵귤러 첫걸음 저자 세미나 노트","slug":"20170722-angular-seminar-note","date":"2017-07-22T03:39:28.000Z","updated":"2018-11-27T06:40:43.292Z","comments":true,"path":"2017/07/22/20170722-angular-seminar-note/","link":"","permalink":"http://icednut.github.io/2017/07/22/20170722-angular-seminar-note/","excerpt":"","text":"커리큘럼 프론트엔드 개발환경의 변화와 앵귤러 맛보기 앵귤러 아키텍처 앵귤러 프레임워크 활용 예시 질의응답 및 마무리 시작하기 전에.. Angular Framework 전체 구조를 알아보고 Angular CLI, Spring-boot를 사용하여 데모 프로젝트 개발 과정 소개할 예정 Angular로 Server Side Rendering을 하기 위해 Angular preboot 프로젝트가 진행되고 있다고 함 (세미나에서는 다루지 않음) 찾아보니깐 이걸 말하고 있었음 (https://github.com/angular/universal) 저자는 프론트엔드 전문 개발자는 아니며 백엔드 개발자이지만 운영툴을 만들면서 Angular를 접하게 되었다고 함. 프론트엔드 개발환경의 변화와 앵귤러 맛보기 Javascript, jQuery의 탄생 (Javascript는 Brendan Erich가 2주만에 만들었다고 함. 만들 당시 Prototype 프로그래밍과 스크립트에 심취해 있어 Javascript에 해당 철학들이 녹아들어졌다고 함) 브라우저 별 ES6 지원 현황: http://kangax.github.io/compat-table/es6 JS가 2015년도에 왜 갑자기 관심을 받기 시작했을까? 저자 생각으로는 node.js 때문이 아닐까라고 생각.. Node.js 덕분에 Javascrit를 브라우저에서 벗어나 서버 웹어플 개발에도 사용할 수 있게 됨 -&gt; 그래서 JS가 발전하게 되었다고 생각함. 라이브러리 모듈 현황(JS가 엄청 많다는걸 보여주고 있음): http://www.modulecounts.com/ JS 개발 스펙트럼: http://joaoperibeiro.com/the-front-end-developer-spectrum 프론트엔드의 주요 3대 도구 분류 패키지 관리 도구 Bower NPM Yarn 자동화 및 Task 도구 Grunt Gulp Yeoman NPM Compiler (Preprocessor) CoffeeScript Babel Typescript Module화를 향한 노력 CommonJS, AMD(RequireJS) Webpack, Module in ES6 Angular Framework 이해하기 Angular is a framework. Angular는 Client application(Web, Mobile Web, Native Mobile, Native Desktop)을 좀 더 만들기 쉽게 하기 위해 나왔으며 Typescript로 개발할 수 있다. 앵귤러는 매주 마다 뭘 개발할건지 그리고 뭘 배포할 것인지 공유를 한다고 함 (올해 말에는 구글 내부에서 사용하는 빌드 툴도 개발할 계획이라고 함) 구글은 Angular를 이용한 웹 어플리케이션의 정석 결과물을 오픈 소스로 공개했다. angular.io가 앵귤러로 만든 앱의 가장 좋은 선례 (https://github.com/angular/angular/tree/master/aio) 구글의 의도: Angular로 개발할라믄 angular.io를 참고해서 만들어라. Angular는 왜 Typescript를 차용했을까? 이걸 참조할 것 (http://www.notforme.kr/archives/1809) ngrx (Angular Redux) 주요개념1. Component 모든 View는 Component로 통한다. (컴포넌트는 앵귤러에서 처음 나온 개념은 아니고 웹 컴포넌트라고 이미 있었음. ex: polymer) 컴포넌트 기반으로 웹어플 개발을 할 때는 컴포넌트들은 트리 구조로 관리 된다는 것을 기억하자. 컴포넌트 트리의 최상위 루트 컴포넌트는 관례적으로 AppComponent이다. 주요개념2. Template Template? View를 구성하는 Angular-style의 마크업 Component와 짝꿍 주요개념3. Component Lifecycle 어플리케이션이 컴포넌트가 언제 생성되고 관리 되는지에 대한 라이프사이클을 알고 있어야 됨. 라이프사이클에 따른 컴포넌트 관리는 Angular Framework가 해줌 컴포넌트 라이프사이클에 대한 Hooking은 ngOnChanges, ngOnInit, ngDoCheck, …, ngOnDestory를 구현하여 할 수 있음. Angular를 처음 써본사람들의 실수가 constructor와 ngOnInit의 차이를 잘 몰라서 constructor에 뭔가 초기화 코드를 작성하려고 한다는 점. constructor에서 구현하면 안되고 ngOnInit을 사용하자. ngDoCheck() -&gt; 컴포넌트를 쫙 스캔할 때 호출되는 메소드(? 뭔지 좀 더 알 필요가 있음) 주요개념4. Directive &amp; Pipe Directive와 Pipe는 Template에서 사용하는 개념 Directive: View를 동적으로 제어하기 위한 요소 Structural Directive NgIf, NgFor, NgSwitch, … Attribute Directives NgStyle, NgClass, … Angular에서는 document를 통해서 DOM 셀렉팅 및 변경하는 것을 죄악시 함. Angular가 그런 부분들을 다 하려고 노력. Pipe: View에 노출하는 데이터를 변형할 때 사용 ex: \\{\\{ now | date:&#39;YYYY-MM-dd&#39; \\}\\} ex: json beauty pipe 주요개념5. Data Binding View와 컴포넌트를 따로 테스트 할 수 없을까? 테스트하려면 셀레니움을 통한 통합 테스트를 해야되는데 그거 말고 view만 테스트하고 싶을 때는? Data Binding을 통해 View와 컴포넌트의 종속성을 제거 Component(+Template)과 View 사이의 연결 고리 Angular에 제공하는 3가지 바인딩: Property(In), Event(Out), 2-way Binding Attribute와 Property의 차이점 Html DOM을 브라우저에 로딩하기 전에는 Attribute지만 로딩하여 메모리에 올라간 것이 Property Angular는 여기서 Property를 변경해준다. (Attribute 변경이 아님) 주요개념6. Service &amp; Dependency Injection 단일책임원칙, 의존성 주입 Angular는 constructor의 파라미터로 의존성을 주입받는다. 컴포넌트마다 providers를 쓰는 것은 지양하긴 한다. 왜냐 DI 받으려고 하는 정보가 바뀔 때마다 모든 컴포넌트를 다 찾아가서 고쳐야되기 때문. AppModule의 providers에 정의하면 모든 컴포넌트의 constructor에서 DI 받을 수 있다. 주요개념7. Module 여기서 말하는 모듈은 ES6에서 말하는 모듈은 아님 앞의 주요 개념에 대한 Angular 요소들을 하나로 담은 컨테이너라고 보면 됨. ex: FormsModule, RouterModule, … AppModule는 Angular로 개발할 때 딱 1번만 작성하면 됨. Angular CLI &amp; Spring-boot를 이용한 데모 시연 Google 내부에서는 Angular-cli를 쓰진 않는다고 함. Google에서는 추후 Bazel(https://bazel.build/) + CLouser 기반의 빌드 도구를 내놓을 수도 있다고 함. 저자 말로는 현재까지 Angular 개발 시 Angular-cli가 제일 좋다고 함. (저자의 의견일 뿐) 저자는 nginx의 gzip 옵션을 붙여서 쓴다고 함 데모는 Todo App을 라이브코딩 했는데 시간에 쫓겨서 Todo 등록, 조회만 구현","categories":[],"tags":[{"name":"Angular","slug":"Angular","permalink":"http://icednut.github.io/tags/Angular/"}]},{"title":"스프링 퀵 스타트 Day 01","slug":"20170719-spring-basic-day01","date":"2017-07-19T13:58:53.000Z","updated":"2018-11-27T06:40:43.293Z","comments":true,"path":"2017/07/19/20170719-spring-basic-day01/","link":"","permalink":"http://icednut.github.io/2017/07/19/20170719-spring-basic-day01/","excerpt":"","text":"순서 개발 환경 셋팅 Spring Overview IoC, Dependency Injection 실습 Day 01 개발 환경 셋팅 JDK 1.8 설치 H2 Database 설치 Gradle Build Tool 설치 IntelliJ IDEA 2017 설치 Spring Initializer를 통한 실습 프로젝트 생성 XML 설정 프로젝트 생성 실습 Spring-boot 프로젝트 생성 실습 Spring Overview왜 스프링인가? 스프링을 써서 개발하면 웹 어플리케이션 개발을 빠르고 효율적으로 할 수 있도록 어플리케이션의 바탕이 되는 틀 공통 프로그래밍 모델과 기술 API 등을 제공해준다. 어플리케이션의 기본 틀: 스프링 컨테이너 공통 프로그래밍 모델: IoC/DI, 서비스 추상화, AOP 기술 API: Spring MVC, Sprign JDBC 한 마디로 스프링을 써서 웹 어플리케이션을 개발하면 기본틀 위에서 개발하기 때문에 효율적인 코드 작성이 가능하다는 소리 스프링이 없을 땐 웹 어플리케이션을 어떻게 개발하고 운영했을까?Java 환경에서 스프링이 없을 때는 아래와 같이 웹 어플리케이션 개발은 Java Servlet을 통해 개발을 했었다. Java Servlet Class 작성 (javax.servlet.http.HttpServlet을 상속받아 HTTP_METHOD별 처리 메소드를 만듬) web.xml 파일에 URI와 앞에서 만든 Servlet 클래스를 정의 war로 패키징 Tomcat의 webapp 폴더에 배포 Tomcat 실행 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;web-app xmlns=&quot;http:&#x2F;&#x2F;xmlns.jcp.org&#x2F;xml&#x2F;ns&#x2F;javaee&quot; xmlns:xsi=&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation=&quot;http:&#x2F;&#x2F;xmlns.jcp.org&#x2F;xml&#x2F;ns&#x2F;javaee http:&#x2F;&#x2F;xmlns.jcp.org&#x2F;xml&#x2F;ns&#x2F;javaee&#x2F;web-app_3_1.xsd&quot; version=&quot;3.1&quot;&gt; &lt;servlet&gt; &lt;servlet-name&gt;helloServlet&lt;&#x2F;servlet-name&gt; &lt;servlet-class&gt;com.skplanet.servlet.exercise.HelloServlet&lt;&#x2F;servlet-class&gt; &lt;&#x2F;servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;helloServlet&lt;&#x2F;servlet-name&gt; &lt;url-pattern&gt;&#x2F;&lt;&#x2F;url-pattern&gt; &lt;&#x2F;servlet-mapping&gt; &lt;&#x2F;web-app&gt; package com.skplanet.servlet.exercise; import javax.servlet.ServletException; import javax.servlet.ServletOutputStream; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; public class HelloServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { ServletOutputStream outputStream = resp.getOutputStream(); outputStream.write(&quot;Hello, world!&quot;.getBytes()); } @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { &#x2F;&#x2F; do something } @Override protected void doPut(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { &#x2F;&#x2F; do something } @Override protected void doDelete(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { &#x2F;&#x2F; do something } } TV 제어 API를 개발한다고 치자.&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;web-app xmlns=&quot;http:&#x2F;&#x2F;xmlns.jcp.org&#x2F;xml&#x2F;ns&#x2F;javaee&quot; xmlns:xsi=&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation=&quot;http:&#x2F;&#x2F;xmlns.jcp.org&#x2F;xml&#x2F;ns&#x2F;javaee http:&#x2F;&#x2F;xmlns.jcp.org&#x2F;xml&#x2F;ns&#x2F;javaee&#x2F;web-app_3_1.xsd&quot; version=&quot;3.1&quot;&gt; ... &lt;servlet&gt; &lt;servlet-name&gt;samsungTvServlet&lt;&#x2F;servlet-name&gt; &lt;servlet-class&gt;com.skplanet.servlet.exercise.SamsungTvServlet&lt;&#x2F;servlet-class&gt; &lt;&#x2F;servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;samsungTvServlet&lt;&#x2F;servlet-name&gt; &lt;url-pattern&gt;&#x2F;samsung-tv&lt;&#x2F;url-pattern&gt; &lt;&#x2F;servlet-mapping&gt; &lt;&#x2F;web-app&gt; public interface Tv { public void powerOn(); public void powerOff(); public void volumeUp(); public void volumeDown(); } class SamsungTv implements Tv { public void powerOn() { System.out.println(&quot;SamsungTV -- 전원켠다.&quot;); } public void powerOff() { System.out.println(&quot;SamsungTV -- 전원끈다.&quot;); } public void volumeUp() { System.out.println(&quot;SamsungTV -- 소리올린다.&quot;); } public void volumeDown() { System.out.println(&quot;SamsungTV -- 소리내린다.&quot;); } } class LgTv implements Tv { public void powerOn() { System.out.println(&quot;LgTV -- 전원켠다.&quot;); } public void powerOff() { System.out.println(&quot;LgTV -- 전원끈다.&quot;); } public void volumeUp() { System.out.println(&quot;LgTV -- 소리올린다.&quot;); } public void volumeDown() { System.out.println(&quot;LgTV -- 소리내린다.&quot;); } } public class SamsungTvServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { SamsungTv tv = new SamsungTv(); String action = req.getParameter(&quot;action&quot;); switch(action) { case &quot;POWER_ON&quot;: tv.powerOn(); break; case &quot;POWER_OFF&quot;: tv.powerOff(); break; case &quot;VOLUME_UP&quot;: tv.volumeUp(); break; case &quot;VOLUME_DOWN&quot;: tv.volumeDown(); break; } } } public class LgTvServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { LgTv tv = new LgTv(); String action = req.getParameter(&quot;action&quot;); switch(action) { case &quot;POWER_ON&quot;: tv.powerOn(); break; case &quot;POWER_OFF&quot;: tv.powerOff(); break; case &quot;VOLUME_UP&quot;: tv.volumeUp(); break; case &quot;VOLUME_DOWN&quot;: tv.volumeDown(); break; } } } 결합도를 낮추기 위해 디자인패턴을 적용해보자.TV가 S사, L사는 쓸 수 없고 다른 회사의 제품으로 교체해야 된다고 했을 때 각 서블릿마다 들어가서 고쳐야 되는 것인가? 요구사항에 좀 더 유연하게 대응하기 위해서 Factory Method 패턴을 적용하자. public class TvFactory { public Tv getTv(String tvName) { if (tvName.equals(&quot;samsung&quot;)) { return new SamsungTv(); } else if (tName.equals(&quot;lg&quot;)) { return new LgTv(); } return null; } } public class SamsungTvServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { TvFactory tvFactory = new TvFactory(); Tv tv = tvFactory.getTv(&quot;samsung&quot;); String action = req.getParameter(&quot;action&quot;); switch(action) { case &quot;POWER_ON&quot;: tv.powerOn(); break; case &quot;POWER_OFF&quot;: tv.powerOff(); break; case &quot;VOLUME_UP&quot;: tv.volumeUp(); break; case &quot;VOLUME_DOWN&quot;: tv.volumeDown(); break; } } } public class LgTvServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { TvFactory tvFactory = new TvFactory(); Tv tv = tvFactory.getTv(&quot;lg&quot;); String action = req.getParameter(&quot;action&quot;); switch(action) { case &quot;POWER_ON&quot;: tv.powerOn(); break; case &quot;POWER_OFF&quot;: tv.powerOff(); break; case &quot;VOLUME_UP&quot;: tv.volumeUp(); break; case &quot;VOLUME_DOWN&quot;: tv.volumeDown(); break; } } } IoC, Dependency InjectionIoCTv 인스턴스를 클라이언트(서블릿)에서 한게 아니라 Factory 클래스에게 요청하면 그 때서야 인스턴스를 반환하는 방식으로 변경이 되었는데,이걸 제어의 역전(Inversion of Control, IoC)라고 부른다. 스프링의 핵심 기술 중 하나가 IoC를 전문적으로 해주는 IoC 컨테이너를 제공한다는 것이다. public class SamsungTvServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { ApplicationContext factory = new GenericXmlApplicationContext(&quot;applicationContext.xml&quot;); Tv tv = (Tv) factory.getBean(&quot;samsung&quot;); String action = req.getParameter(&quot;action&quot;); switch(action) { case &quot;POWER_ON&quot;: tv.powerOn(); break; case &quot;POWER_OFF&quot;: tv.powerOff(); break; case &quot;VOLUME_UP&quot;: tv.volumeUp(); break; case &quot;VOLUME_DOWN&quot;: tv.volumeDown(); break; } } } &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi=&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation=&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd&quot;&gt; &lt;bean id=&quot;samsungTv&quot; class=&quot;com.skplanet.spring.plalab.SamsungTv&quot;&gt;&lt;&#x2F;bean&gt; &lt;bean id=&quot;lgTv&quot; class=&quot;com.skplanet.spring.plalab.LgTv&quot;&gt;&lt;&#x2F;bean&gt; &lt;&#x2F;beans&gt; Dependency Injection이번엔 스피커를 추가하여 Tv 볼륨을 제어해보자. public class SonySpeaker implements Speaker { public SonySpeaker() { System.out.println(&quot;===&gt; Sony Speaker 객체 생성&quot;); } public void volumeUp() { System.out.println(&quot;Sony Speaker -- 소리 올린다.&quot;); } public void volumeDown() { System.out.println(&quot;Sony Speaker -- 소리 내린다.&quot;); } } public class SamsungTv implements Tv { private Speaker speaker; public SamsungTv(Speaker speaker) { this.speaker = speaker; } public void powerOn() { System.out.println(&quot;SamsungTV -- 전원켠다.&quot;); } public void powerOff() { System.out.println(&quot;SamsungTV -- 전원끈다.&quot;); } public void volumeUp() { this.speaker.volumeUp(); } public void volumeDown() { this.speaker.volumeDown(); } } 예전 TvFactory를 사용한다면 Factory 클래스에서 인스턴스화 할 때 생성자로 넘겨(주입해)준다. public class TvFactory { public Tv getTv(String tvName) { if (tvName.equals(&quot;samsung&quot;)) { Speaker speaker = new SonySpeaker(); return new SamsungTv(speaker); } else if (tName.equals(&quot;lg&quot;)) { Speaker speaker = new SonySpeaker(); return new LgTv(speaker); } return null; } } 이와 같이 Tv에 의존관계(Dependency)가 있는 Speaker를 생성자로 주입(Injection)해 줬다고 해서 이를 Dependency Injection이라고 부른다. 이걸 스프링으로는 어떻게 할까?XML로 직접 연결하거나, 어노테이션(@Autowired, @Resource)를 사용하여 알아서 주입되게 한다. XML을 통해 직접 Dependency Injection 정의하기 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi=&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:context=&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context&quot; xsi:schemaLocation=&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context&#x2F;spring-context.xsd&quot;&gt; &lt;bean id=&quot;samsungTv&quot; class=&quot;com.skplanet.spring.plalab.SamsungTv&quot;&gt; &lt;property name=&quot;speaker&quot; ref=&quot;sonySpeaker&quot;&gt;&lt;&#x2F;property&gt; &lt;&#x2F;bean&gt; &lt;bean id=&quot;sonySpeaker&quot; class=&quot;com.skplanet.spring.plalab.SonySpeaker&quot;&gt; &lt;&#x2F;bean&gt; &lt;&#x2F;beans&gt; 자동으로 Dependency Injection 하기 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi=&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:context=&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context&quot; xsi:schemaLocation=&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context&#x2F;spring-context.xsd&quot;&gt; &lt;context:component-scan base-package=&quot;com.skplanet.spring.plalab&quot;&#x2F;&gt; &lt;&#x2F;beans&gt; @Component public class SonySpeaker implements Speaker { public SonySpeaker() { System.out.println(&quot;===&gt; Sony Speaker 객체 생성&quot;); } public void volumeUp() { System.out.println(&quot;Sony Speaker -- 소리 올린다.&quot;); } public void volumeDown() { System.out.println(&quot;Sony Speaker -- 소리 내린다.&quot;); } } @Component public class SamsungTv implements Tv { @Autowired private Speaker speaker; public void powerOn() { System.out.println(&quot;SamsungTV -- 전원켠다.&quot;); } public void powerOff() { System.out.println(&quot;SamsungTV -- 전원끈다.&quot;); } public void volumeUp() { this.speaker.volumeUp(); } public void volumeDown() { this.speaker.volumeDown(); } } 실습 Day 01Page 109 ~ 139","categories":[],"tags":[{"name":"JPA","slug":"JPA","permalink":"http://icednut.github.io/tags/JPA/"},{"name":"Spring","slug":"Spring","permalink":"http://icednut.github.io/tags/Spring/"}]},{"title":"웹페이지 실습 강의 노트","slug":"20170616-web-page-lecture","date":"2017-06-16T01:05:11.000Z","updated":"2018-11-27T06:40:43.297Z","comments":true,"path":"2017/06/16/20170616-web-page-lecture/","link":"","permalink":"http://icednut.github.io/2017/06/16/20170616-web-page-lecture/","excerpt":"","text":"HTML 마크업하기시작하기 전에.. html 문서 맨 첫줄에는 DTD가 위치 DTD는 Document Type Definition을 의미 &lt;!DOCTYPE html&gt;를 입력하면 hmtl5로 인식함 DTD는 대소문자를 구분하지 않는데 DTDTYPE만 대문자로 쓰고 나머지는 소문자 (대문자로 써도 되는데 관례상 소문자) html5에서는 header, footer, aside 같은 division 태그들이 더 추가됨 웹브라우저는 DTD가 없으면 예전 문서라고 인식함 -&gt; 브라우저가 렌더링할 때 예전 문서 렌더링 방식으로 진행 (쿽스 모드로 렌더링) -&gt; 브라우저마다 다르게 렌더링하는 이슈가 발생함 TIP: zen-coding, emmet을 사용하면 html 태그 작성이 편해짐 HTML Elementshtml html은 반드시 필요하며, html 엘리먼트는 html 파일 당 하나만 등장해야됨 엘리먼트에는 속성을 가질 수 있음 장애인차별금지법을 위해서 웹접근성 규칙을 지켜야됨 -&gt; html에는 lang 속성을 선언하자. -&gt; 이걸 선언하면 뭐가 좋을까? 구글에서 한국어 웹페이지만 검색할 때 참조할 수도 있을 것 같다. 웹페이지 화면 낭독기가 이 속성을 참조해서 낭독을 함 (lang=”ko”를 하면 한국어로 낭독) head head와 body 앨리먼트도 페이지 당 각각 하나씩만 위치할 수 있음 body 안쪽에 있는 코드만 뷰포트에 보이게 되며, head 앨리먼트 아래에는 meta, title이 위치할 수 있음 meta 태그 첫 번쨰는 인코딩이 들어감 &lt;meta charset=&quot;euc-kr&quot;&gt; 이렇게 하면 한국어만 다룸 -&gt; 이렇게 작성하면 최신 크롬에서는 깨짐. 크롬은 utf-8로 강제로 인코딩함 &lt;meta charset=&quot;utf-8&quot;&gt; 이렇게 하면 전세계 모든 문자를 표현할 수 있음 &lt;meta name=&quot;viewport&quot; content=&quot;initial-scale=1,minimum-scale=1,user-scalable=no&quot;&gt; 모바일 브라우저에서 줌인, 줌아웃을 못하게 함. 이걸 셋팅 안하면 데스크탑 페이지 같은 뷰포트보다 큰 페이지는 강제로 줌아웃을 함. -&gt; 모바일에서 보기에 불편함 -&gt; 해당 메타 태그를 추가하여 실제 크기로 뷰포트에 표시 &lt;meta name=&quot;viewport&quot; content=&quot;initial-scale=1,width=device-width&quot;&gt; 이 태그도 위와 같은 의미 한 가지 염두해둘 것이 있는데, iOS에서는 더 이상 위 메타태그를 지원하지 않음 (써도 소용없음, 그러므로 iOS는 줌인/줌아웃이 되며 막을 방법이 없음). 단 안드로이드는 그대로 위 태그가 유효하다고 함. meta 태그는 종료 태그가 없음 title 태그에는 문서의 제목이 위치함 검색엔진이 여기에 적힌 키워드를 가지고 검색 노출을 함 여길 잘 작성해야 웹 크롤링에 유리. &lt;title&gt;공지사항&lt;/title&gt; 모든 페이지가 이렇게 작성되어 있으면 검색엔진 수집에 이점이 없겠지? &lt;title&gt;공지사항 - 게시물 제목&lt;/title&gt; 이렇게 유니크하고 구체적으로 작성하자 웹페이지 낭독기가 제일 먼저 읽는게 이 title 태그 -&gt; 웹접근성을 위해서라도 꼭 작성해야 하며, 유니크하고 구체적으로 작성해야됨 meta 태그, title 태그 위치는 상관없으나 관례상 meta 태그를 먼저 쓴다 title 다음 쓰는게 link 태그 &lt;link href=&quot;default.css&quot; rel=&quot;stylesheet&quot;&gt; 이 방식을 external stylesheet라고 부름. 일반적으로 가장 많이 쓰이며, 다른 페이지에서도 쓸 때 사용 &lt;style&gt;&lt;/style&gt; 이렇게 쓰는게 embedded stylesheet라고 부름. 적용 범위가 이 페이지에 한정될 때 이 방식을 사용. 태그 안에 style 속성을 써서 CSS를 선언하는 방식을 inline style이라고 부름. 이 방식은 해당 엘리먼트에만 적용이 됨. (재사용이 불가) link 태그를 여러개 하면 http 요청이 많아져서 성능이 떨어짐. 최대 2개만 유지하자. css 빌드 기능을 써도 좋음. user agent stylesheet는 브라우저에 설정된 기본적인 스타일시트 아래 코드는 IE9 이하의 브라우저에서 html5 태그를 쓸 수 있게하는 polyfill js임&lt;!--[if lt IE 9]&gt; &lt;script src=&quot;https:&#x2F;&#x2F;cdnjs.cloudflare.com&#x2F;ajax&#x2F;libs&#x2F;html5shiv&#x2F;3.7.3&#x2F;html5shiv.min.js&quot;&gt;&lt;&#x2F;script&gt; &lt;script src=&quot;https:&#x2F;&#x2F;cdnjs.cloudflare.com&#x2F;ajax&#x2F;libs&#x2F;respond.js&#x2F;1.4.2&#x2F;respond.min.js&quot;&gt;&lt;&#x2F;script&gt; &lt;![endif]--&gt; 그 다음 script 태그가 위치하는데 이 태그는 head 혹은 body 엘리먼트 안에 위치해야 한다. (다른데 위치하면 안됨) pollfill.js를 입력하면 IE7, IE8에서 section 태그를 사용할 수 있음. 이 js는 head 안에 선언해야 됨. body div, span는 뭔가 표현할 때 블록 혹은 마크업하는데 딱히 떠오르는게 없을 때 사용. &lt;a href=&quot;#main&quot; class=&quot;skip&quot;&gt;메뉴 건너뛰기&lt;/a&gt; 이 태그가 있으면 웹페이지 낭독기에서 tab으로 선택 시 메뉴들을 건너뛰고 본문으로 갈 수 있도록 한다. (웹접근성 때문) header와 footer를 사용하여 사이트 상단 하단을 표현 h1 h1으로 사이트 로고를 표현 (h는 heading을 의미, heading contents라고 부름) 웹접근성 낭독기로 heading만 먼저 Sorting한 뒤 그걸 먼저 듣고 중요한지 판단하기 때문에 중요한 태그라 생각 block 레벨 엘리먼트는 flow contents, inline 레벨 엘리먼트는 phrasing contents라고 부르기도 함 &lt;span&gt;&lt;h1&gt;타이틀&lt;/h1&gt;&lt;/span&gt; span과 같은 프레이징 컨텐츠가 플로우 컨텐츠를 감쌀 수 없다. firefow &gt; html validator를 쓰면 현재 페이지의 html 문법 오류를 체크할 수 있음 html 문법을 좀 더 자세히 알고 싶으면 https://www.w3.org/TR/html5/Overview.html#contents를 참조하여 앨리먼트를 찾아서 쓰자 ex) p element 안쪽에 div를 쓸 수 있을지 검색해 볼 수 있다. (Content Model인 자식으로 올 수 있는 모델을 참조) -&gt; p 태그 안 쪽에는 div를 쓸 수 없다. button button 앨리먼트의 타입 속성이 button은 별 다른 기능을 하지 않는 버튼이 된다. type을 생략하면 기본적으로 submit으로 결정 nav 사이트의 네비게이션을 담당 그 사이트의 주된 탐색 섹션만 nav로 마크업 하자. 아무거나 다 링크들을 nav로 선언하면 안된다. nav는 sectioning contents라고 부름 sectioning contents는 section, article, nav, aside가 있다. sectioning contents를 쓸 경우에는 h 태그를 쓸 것을 강력히 권장한다. ul (unordered element) 순서가 없는 반복되는 목록을 표현할 때 ul 앨리먼트를 사용 반대는 ol (ordered element) input input 앨리먼트의 타입은 레퍼런스를 참조하자. required 속성은 value를 생략할 수 있다. (disabled, readonly도 마찬가지) disabled와 readonly의 차이: readonly는 값을 수정할 수 없지만 form을 통해 값 전송이 가능. 반면 disabled는 서버측으로 전송이 안됨 pattern이라는 속성도 있음. 여기에는 정규식을 넣을 수 있다. ex) pattern=&quot;[0-9]&quot; 숫자만 입력 가능 hr horizontal rule 내용과 내용 사이를 구분하고 싶을 때 사용 main 해당 페이지의 중요한 컨텐츠를 여기에 위치시키자. (ex: 뉴스기사 본분, 블로그 컨텐츠 본문) 화면을 수직으로 분할하고 싶을 때는 div로 한 번 wrapping해서 쓰자&lt;div&gt; &lt;main&gt;...&lt;&#x2F;main&gt; &lt;aside&gt;...&lt;&#x2F;aside&gt; &lt;&#x2F;div&gt; section 하나의 주제를 가진 블록 article과 비슷 article는 따로 떼서 다른 곳에 배포했을 때 그 내용이 이해가 되면 article, 아니면 section aside 주된 컨텐츠를 다 작성하고 나서 없어도 되는 컨텐츠를 여기에 표현 배너, 광고, 쇼핑몰에서 오른쪽에 따라 다니는 내가 본 컨텐츠 등을 여기에 표현 footer 저작권, 이 사이트의 주소를 여기에 표현 body 맨 마지막에는 자바스크립트 로딩 부분을 표현 그 밖에.. https://docs.google.com/presentation/d/1EDoo-_013DT0-oGbi6ubczmQYnJg-IwMuthU1EcPAmk/edit#slide=id.p https://docs.google.com/presentation/d/1Z_L7Jm1bTd9MmiVHWnX90HwyyP9xaDQ1g0w4_yM5sQo/edit#slide=id.p CSS 코딩해보기 class 속성으로 선언된 클래스에 styling 해보기 *은 공용 셀렉터로 html, body 등 모든 것을 다 선택한다. width 값에 border값과 padding값이 포함된 값으로 셋팅할 수는 없을까? box-sizing: content-box; 때문에 저렇게 동작하는 것인데 이 값을 border-box로 변경하면 원하는 대로 동작한다. box-sizing: border-box; 모든 DOM을 border-box로 하고 싶을 때는?*, :before, :after { box-sizing: border-box; } &#x2F;* 셀럭터에서 쉼표(,)는 and를 의미한다. *&#x2F; body:before {} 여기서 :before는 가상 선택자라고 하며, 실제로 DOM이 존재하지 않지만 브라우저가 DOM을 생성하게 해주는 것을 칭한다. :after도 있음 before와 after는 화면 낭독기가 읽어주지 않기 때문에 컨텐츠를 담으면 웹접근성 위반. 보통 before와 after에는 아이콘을 위치시킨다. body 앞에 가상 DOM을 생성해서 그 안에 hello world라고 출력하고 싶을때는?body:before { content: &#39;hello world&#39;; } 모바일용, 태블릿용, 데스크탑용 페이지 CSS를 어떻게 작성할까? 일단 하기 전에 global 스타일을 먼저 선언하고 local 스타일은 나중에 선언한다. (local 스타일이 덮어씌워지기 때문) 또, aside나 main 등 안변하는 앨리먼트의 스타일을 먼저 작성한다. 디바이스별 CSS는 media query를 사용한다. (http://naradesign.net/wp/2012/05/30/1823/ 여기를 참조) @media screen and (조건) 이렇게 쓰면 디바이스에서만 작동하는 미디어쿼리 이다. 화면 낭독기에서는 작동 안함 @media print and (조건) 프린트할 때 적용되는 스타일시트 @media all and (조건) all은 생략 가능 CSS 속성 - display, margin, position, floatdisplay block과 inline의 차이점은? block는 한 줄을 다 차지 inline은 표현된 영역만 차지 none은 화면에 표시 안됨 (javascript로 컨트롤 가능, 화면 낭독기는 읽지 않고 pass) inline-block은? inline과 비슷하지만, block 처럼 쓸 수도 있음. 이것의 장점은 height값이 적용이 됨 (inline으로 할 때는 height 값이 적용이 안됨) 왜? inline으로 선언했을 경우에는 브라우저가 텍스트로 인식하기 때문. 그래서 텍스트의 영역에는 height, width 값 설정이 안됨 이게 언제 필요할까? 네비게이션 메뉴를 행으로 위치할 때 수직 구분을 inline-block을 줘서 width 값을 준다. inline은 특징이 대략 4px 정도의 공백이 생김 (자간을 의미, 그래서 inline을 이용해서 행 구분을 하진 않음) (공백은 font-size에 따라 달라짐) 자간을 없애려면? inline을 랩핑한 앨리먼트를 선언해서 font-size: 0으로 적용 행 배치의 현존하는 가장 흔한 방법은 float를 사용 (ex: float: left) 이를 대체하기 위해 나온 것이 flex (Readme에 기고가 되어 있으며 궁금하면 읽어보자) flex-container, flex-item margin 박스 바깥 쪽을 나타내는 영역 block에 width를 주면 나머지 영역은 auto margin이 적용된다. auto margin 언제 필요할까? 중앙 정렬할 때 필요 (ex: margin: 0 auto;) 아래와 같은 경우 b 앨리먼트는 margin이 어떻게 동작할까? .a { background: red; color: #FFF; margin-bottom: 100px; } .b { background: blue; color: #FFF; margin-top: 100px; } a와 b의 마진이 겹친다. 이를 수직 마진 중첩이라고 부른다. 그럼 b의 margin-top을 200px로 하면 a와 b 사이는 300px이 될까? .a { background: red; color: #FFF; margin-bottom: 100px; } .b { background: blue; color: #FFF; margin-top: 200px; } 절대값이 작은 margin 값은 무시된다. 그럼 b의 margin-top을 -100px로 하면 어떻게 될까? .a { background: red; color: #FFF; margin-bottom: 100px; } .b { background: blue; color: #FFF; margin-top: -100px; } 이 때는 margin 값이 사라지게 된다. 그럼 a의 margin을 지우면 어떻게 될까? .a { background: red; color: #FFF; } .b { background: blue; color: #FFF; margin-top: -100px; } 이 때는 b가 a 위에 겹치게 된다. 아래와 같은 엘리먼트가 있을 때 margin은 어떻게 동작하게 될까? &lt;div class=&quot;c&quot;&gt; &lt;div class=&quot;a&quot;&gt;.a&lt;&#x2F;div&gt; &lt;div class=&quot;b&quot;&gt;.b&lt;&#x2F;div&gt; &lt;&#x2F;div&gt; .a { background: red; color: #FFF; margin-top: 100px; } .b { background: blue; color: #FFF; } .c { background: silver; color: #FFF; } c의 margin-top은 0 이므로 무시가 되고 a의 margin-top 값이 적용이 된다. c 박스 안에서 margin을 주고 싶을 떄는? overflow: hidden or padding: 1px or border: 1px solid #000 셋 중에 하나만 줘도 원하는대로 동작한다. inline 요소는 수직 마진이 적용되지 않는다. 단 수평 마진은 적용된다. .a, .b { width: 100px; height: 100px; display: inline; margin: 100px; } .a { background: red; color: #FFF; } .b { background: blue; color: #FFF; } .c { background: silver; color: #FFF; } position 위치를 제어하는 속성 absolute: 자기 위치를 결정할 때 보통 형제 노드들의 위치에 따라 결정이 되는데, 이 속성은 위치를 독립적으로 설정 가능 (top, bottom, left, right 사용) absolute로 하면 auto margin이 사라진다. absolute를 주면 z-index가 활성화 된다. fixed: 스크롤 해도 특정 위치에 계속 띄우고 싶을 때 사용 dim 레이어 띄울 때 쓰는데 이 때 스크롤이 먹힌다. 스크롤이 안먹히게 하려면 body에 overflow: hidden을 준다. 화면 중간에 띄우고 싶을 때는 아래와 같이 주면 된다. position: fixed; right: 0; bottom: 0; top: 0; left: 0; opacity: .5; margin: auto; relative: 이 속성을 줘도 z-index가 활성화 된다. float float를 주면 position: absolute를 준 것과 같이 비슷한 효과를 볼 수 있다. (z-index가 활성화 되고 width, height가 수축된다.) width, height 수축되는 것을 막으려면 overflow: hidden을 주면 된다. overflow: hidden을 주었을 때 box 바깥으로 넘칠 때 표시가 안되는 이슈가 있다. 결과적으로 float를 주면서 수축이 안되게 하려면 clear: both라는 스타일을 갖는 앨리먼트를 추가하면 된다. (:after를 사용해서)&lt;div class=&quot;c&quot;&gt; &lt;div class=&quot;a&quot;&gt;.a&lt;&#x2F;div&gt; &lt;div class=&quot;b&quot;&gt;.b&lt;&#x2F;div&gt; &lt;&#x2F;div&gt; .a, .b { width: 100px; height: 100px; float: right; } .a { background: red; color: #FFF; } .b { background: black; color: #FFF; } .c { background: silver; color: #FFF; } .c:after { display: block; content: &quot;&quot;; clear: both; } 그 밖에… https://docs.google.com/presentation/d/1JfsOBEep6Tc0y8HxIx9NqK8W6lXm5ih5TaPdqSl9jxY/edit#slide=id.p https://docs.google.com/presentation/d/1mDitto-cEbKoZGOCqxDWcoM91bSH0K5SIt0XJ09pc5o/edit#slide=id.p https://docs.google.com/presentation/d/1cI_96cUjOpRzrNGHHWaDCcsghUc_RG4JuqenNZm68h0/edit#slide=id.p http://naradesign.net/wp/2017/04/20/2363/ http://naradesign.net/wp/2017/04/24/2440/ http://naradesign.net/wp/2017/05/02/2467/","categories":[],"tags":[{"name":"html5","slug":"html5","permalink":"http://icednut.github.io/tags/html5/"},{"name":"css3","slug":"css3","permalink":"http://icednut.github.io/tags/css3/"}]},{"title":"스파크 강의 노트 Day 4","slug":"20170530-spark-lecture-day04","date":"2017-05-30T00:08:40.000Z","updated":"2018-11-27T06:40:43.295Z","comments":true,"path":"2017/05/30/20170530-spark-lecture-day04/","link":"","permalink":"http://icednut.github.io/2017/05/30/20170530-spark-lecture-day04/","excerpt":"","text":"Machine Learing With SparkK-Means 주어진 데이터를 K개의 클러스터로 묶는 알고리즘 (Clustering, unsupervised learning) Center 값을 기준으로 분포를 구분함 PIC, K-means 참조 ML 코딩 (RDD-based API) Setting SparkContext Load Data (ex: RDD[String] -&gt; RDD[Vector], CSV 파일을 읽어서 한 줄씩 Vector로 변환) Train Model ex)val model: KMeansModel = KMeans.train(parsedData, 2, 20) model.clusterCenters.foreach(println) Show Results Evaluate (평가) ex)val cost: Double = model.computeCost(parsedData) cost 값이 0에 수렴할수록 좋은 모델 Predict ex)val predictions1: Int = model.predict(Vectors.dense(0.5, 0.5, 0.5)) ML 코딩 순서 (DataFrame-based APIs) Setting SparkContext ex)val conf: SparkConf = ... val sc: SparkContext = new SparkContext(conf) val sqlContext: SQLContext = new SQLContext(sc) &#x2F;&#x2F; RDD 프로그래밍과 차이점 Load Data ex)val dataSet: DataFrame = sqlContext.createDataFrame(Seq( (1, Vectors.dense(0.0, 0.0, 0.0)), (2, Vectors.dense(0.1, 0.1, 0.1)) ).toDF(&quot;id&quot;, &quot;features&quot;) &#x2F;&#x2F; CSV 파일을 읽어서 String을 Vector로 변환해도 된다. Train Model ex)val model: KMeans = new KMeans() .setK(2) .setFeaturesCol(&quot;features&quot;) .setPredictionCol(&quot;prediction&quot;) val model: KMeansModel = kmeans.fit(dataSet) model.clusterCenters.foreach(println) Show Results Evaluate (평가) ex)val cost: Double = model.computeCost(dataSet) cost 값이 0에 수렴할수록 좋은 모델 Predict ex)val predictions1: Int = model.predict(Vectors.dense(0.5, 0.5, 0.5)) Logistic Regression 독립변수의 선형 결합을 이용하여 사건의 발생 가능성을 예측하는 분석 기법 Term Frequency: 단어 분포 파악 Classification Model: 모델 생성 Predict 모델을 PMML 파일로 디스크에 저장할 수 도 있다. Exercise https://github.com/sryza/spark-timeseries Spark GraphX: 네트워크 분석, 스팸필터 개발에 쓰임 PCA: 차원 축소 알고리즘 Scailing: 데이터를 평탄화하는 작업 Hyper Parameter SparkR, Sparklyr Sparklyr는 R코드를 분산해서 실행시킬 수 없다. DataFrame에서 DataSet으로 변환하는 방법: case class","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"http://icednut.github.io/tags/Spark/"}]},{"title":"스파크 강의 노트 Day 3","slug":"20170529-spark-lecture-day03","date":"2017-05-29T00:01:47.000Z","updated":"2018-11-27T06:40:43.295Z","comments":true,"path":"2017/05/29/20170529-spark-lecture-day03/","link":"","permalink":"http://icednut.github.io/2017/05/29/20170529-spark-lecture-day03/","excerpt":"","text":"Spark Intro Zeppelin &gt; Notebook &gt; 입력 패널 첫번쨰 줄에 %를 입력 후 사용할 언어 입력 (%는 인터프리터 지정을 의미) 실제 업무에서는 DataFrames를 많이씀. RDD를 할 때는 DataSets를 쓰는게 속도 향상을 볼 수 있음. DataFrames를 쓰면 Python으로 포팅하기도 쉬움. (DataFrames 추천) Spark DataFrames RDD와 DataFrame의 차이점? Catelog optimizer의 유무 (DataFrames에만 있음. RDD는 디시리얼라이제이션 때문에 Heap 사용량이 많아 성능 저하.) DataFrames는 테이블 형태로 데이터를 한정했기 때문에 SQL에 국한된 로직만 작성할 수 있는 단점이 있다. (DataFrames를 보완하기 위해 Datasets가 나왔음) ex)dataFrames.filter($&quot;weight&quot; &lt; 60) &#x2F;&#x2F; $&quot;weight&quot;와 같이 컬럼을 지정하여 필터링 할 수 있다. &#x2F;&#x2F; 컬럼($)으로 쓰면 해당 컬럼에 대한 오퍼레이션을 더 추가할 수 있다. (ex: cast) DataFrames를 쓰면 많이 쓰는 메소드: show, printSchema ex)val peopleRDD = spark.sparkContext.makeRDD(&quot;&quot;&quot;{&quot;name&quot;:&quot;Yin&quot;,&quot;address&quot;:{&quot;city&quot;:&quot;Columbus&quot;,&quot;state&quot;:&quot;Ohio&quot;}}&quot;&quot;&quot; :: Nil) val people = spark.read.json(peopleRDD) people.show() ex)val wikiDF = spark.read.json(&quot;&#x2F;sparklab&#x2F;dataset&#x2F;wikiticker-2015-09-12-sampled.json.gz&quot;) wikiDF.show() wikiDF.printSchema() DataFrames에서 explain 메소드를 쓰면 RDBMS와 같이 쿼리 수행 계획을 볼 수 있다. ex)wikiDF.select($&quot;page&quot;, $&quot;added&quot; + 1).explain(true) Shuffle Read, Shuffle Write를 염두해두자. (엄청크면 뭔가 문제가 있다는 신호. 조인을 잘못걸경우 커짐. shuffle은 노드간에 데이터를 파티셔닝 및 섞는 것을 의미) explain 볼 때 밑에서부터 위로 읽어나가자. JSON을 RDD로 만든 뒤 DataFrame로 변환해서 출력해보면 알아서 컬럼 타입을 지정해준다. ex)val cityRDD = spark.sparkContext.makeRDD( &quot;&quot;&quot;{&quot;cityName&quot;:&quot;Seoul&quot;,&quot;countryName&quot;:&quot;Republic of Korea&quot;,&quot;gdp&quot;:1321200}&quot;&quot;&quot; :: &quot;&quot;&quot;{&quot;cityName&quot;:&quot;Tokyo&quot;,&quot;countryName&quot;:&quot;Japan&quot;,&quot;gdp&quot;:4412600}&quot;&quot;&quot; :: &quot;&quot;&quot;{&quot;cityName&quot;:&quot;Moscow&quot;,&quot;countryName&quot;:&quot;Russia&quot;,&quot;gdp&quot;:113240}&quot;&quot;&quot; :: &quot;&quot;&quot;{&quot;cityName&quot;:&quot;London&quot;,&quot;countryName&quot;:&quot;United Kingdom&quot;,&quot;gdp&quot;:2760960}&quot;&quot;&quot; :: Nil) val cityDF = spark.read.json(cityRDD) cityDF.printSchema() cityDF.show agg는 org.apache.spark.sql.functions를 참조 DataFrame는 압축된 데이터 바이너리인 텅스텐으로 메모리에 저장됨 z는 제플린 컨텍스트라고 해서 제플린 관련 설정을 바꿀 때 사용 ex)val shufflePartitions = z.input(&quot;spark.sql.shuffle.partition&quot;, &quot;200&quot;) .asInstanceOf[String].toInt 일반적인 경우는 파티션의 크기를 10MB로 잡자. CPU가 많이 먹으면 파티션의 크기를 조정해야됨 parquet로 쓰면 컬럼 기반으로 데이터 구조가 잡혀있기 때문에 spark에서 읽을 때 오버헤드가 줄어든다. parquet를 쓰면 SQL From 절에 바로 써서 조회할 수 있다. parquet를 쓰면 컬럼 기반으로 조회(column pruning)를 해서 분석 프로세스를 더 빨리 진행할 수 있다. (FileScan step에서 이미 필터링을 진행) ex)val sqlDF = spark.sql(&quot;SELECT countryName, cityName, sum(gdp) FROM parquet.`&#x2F;sparklab&#x2F;tmp-output&#x2F;wiki_gdp` WHERE gdp &gt; 1321200 GROUP BY countryName, cityName&quot;) UDF (User Defined Function) 사용자가 만든 함수. 조인을 할 때 udf를 잘못 쓰면 옵티마이저가 안먹힐 수도 있다. ex)import org.apache.spark.sql.functions._ val coder: (Int =&gt; String) = (added: Int) =&gt; if (added &gt; 10) &quot;frequent&quot; else &quot;rare&quot; val sqlfunc = udf(coder) wikiDF.withColumn(&quot;Frequency&quot;, sqlfunc(col(&quot;added&quot;))).select($&quot;page&quot;, $&quot;added&quot;, $&quot;frequency&quot;).show() SQL로 만든것을 Spark DataFrame 메소드로 바꿔보기 연습 ex)wikiDF .select($&quot;countryName&quot;, $&quot;cityName&quot;, $&quot;comment&quot;, $&quot;added&quot;) .groupBy($&quot;countryName&quot;, $&quot;cityName&quot;) .agg(avg($&quot;added&quot;).alias(&quot;avg_added&quot;), max($&quot;added&quot;).alias(&quot;max_added&quot;)) .orderBy($&quot;avg_added&quot;.desc) .limit(10) .show &#x2F;&#x2F; select 컬럼에 내가 보고자 하는 컬럼을 추가해도 groupBy에 지정 안한 컬럼은 결과로 나오지 않음 JoinPivoting 데이터를 Row로 쫙 늘리는 것? Wikipedia 연습pageCountsDF.withColumn(&quot;masked_project&quot;, regexp_replace(regexp_replace(regexp_replace($&quot;project&quot;, &quot;[0-9]+&quot;, &quot;9&quot;), &quot;[A-Z]+&quot;, &quot;A&quot;), &quot;[a-z]+&quot;, &quot;a&quot;)) .filter($&quot;masked_project&quot; === &quot;a-a&quot; or $&quot;masked_project&quot; === &quot;a-a-a&quot; or $&quot;masked_project&quot; === &quot;a-a-a.a&quot;) &#x2F;&#x2F; &quot;masked_project = &#39;a-a&#39; or masked_project = &#39;a-a-a&#39;&quot; 이렇게도 쓸 수 있음 .groupBy($&quot;masked_project&quot;) .count .orderBy($&quot;count&quot;.desc) .show(100) Wikipedia 실습 spark.catalog.listTables().show(false) 메소드의 파라미터를 false로 주면 안짤리고 다 나옴 SKT에서 Spark 활용 사례 Flume, Kafka로 데이터를 메세지큐에 담음 -&gt; Batch 처리 or Streaming 처리에 Spark 사용 &gt; 저장소에 저장 (Cache, HDFS) 카프카는 최소 3대 이상으로 구축되어야 함. 카프카도 토픽에 데이터가 너무 많이 들어오면 repartition을 진행해야 한다. Streaming에서는 Transaction 처리가 힘듬. Data를 Write하는 것도 고려해야됨. &gt; 대량으로 write하기 위해서는 MQ를 중간에 사용하여 저장 처리 &gt; 그러나 중복이 발생할 수 있다? Catalog API가 뭘까? DataSet의 장점: Strong Type (Untyped API, Type API 모두 제공함) Shared Variable 사용 방법: Accumulator, Broadcast Variables Whole Stage CodeGen (실행 시점에 필요한 데이터만 필터링해서 데이터를 올림, Tungsten vetorization) Structured Streaming Streaming 처리를 할 때 unbounded table 형태로 데이터 전체를 사용할 수 있음 (structured stream outputMode: Append, Complete, Update 때문) 10분 단위로 트리거링해서 Result Table 생성할 수 있음 Structured Stream은 아직 알파버전","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"http://icednut.github.io/tags/Spark/"}]},{"title":"스파크 강의 노트 Day 2","slug":"20170526-spark-lecture-day02","date":"2017-05-26T00:06:19.000Z","updated":"2018-11-27T06:40:43.298Z","comments":true,"path":"2017/05/26/20170526-spark-lecture-day02/","link":"","permalink":"http://icednut.github.io/2017/05/26/20170526-spark-lecture-day02/","excerpt":"","text":"Local에 Spark 환경 구축하기 vm 띄우면 별다른 작업할거 없음 goo.gl/2nKkOZ Zeppelin download Spark 내장. 별도 설정 필요 없고 zeppelin을 띄우면 yarn과 hdfs가 자동으로 뜸 http://localhost:8080 zeppelin http://localhost:4040 spark dashboard =&gt; zeppelin만 있는 경우 driver만 뜸 https://www.zeppelinhub.com =&gt; 예제 노트북 받을 수 있는 곳 Spark Download spark-shell을 띄울 수 있음 http://13.92.190.120:8080 Stream Processing Spark으로도 수집을 할 수 있는데 잘 안씀. 플럼, 카프카를 이용 Storm은 MapReduce로 된 코드를 마이그레이션 하기 편함 Streaming Application은 따로 kill하지 않는 이상 끝나지 않고 계속 실행됨 모니터링은 카프카 다룰 때 한 번더 언급 windowing Production 환경에서는 checkpointing 관련 로직을 고려해야됨 Accumulator &amp; Broadcast shared 변수를 공유하고 싶을 때 사용, (ex: 데이터 모델을 공유하고 싶을 때) Broadcast는 read-only. 전체 노드가 다 공유하고 싶을 때 사용. (ex: 다른 데이터와 조인을 할 때 활용할 수도 있음) Accumulator는 update 가능 Streaming Using Kafka 카프카로 데이터가 들어오면 잠시 저장함. 데이터 유실이 없음 Spark SQL Spark SQL은 데이터프레임을 사용 Spark SQL은 내부적으로는 RDD를 사용하지만, Catalyst Optimizer가 SQL실행을 최적화 해줌 실습 진행 udf가 뭐지? Spark 2.0 Tungsten: 메모리 관리, CPU 사용 개선을 진행 Strunctured Streaming Spark Session을 쓰면 어떤 언어를 쓰던 ML 모델링을 할 수 있다. Catelog API Dataset Tungsten Whole-stage Codegen을 통해서 스파크 내부에서 코드 최적화를 진행함 Structured StreamingLambda ArchitectureMachine Learning Spark 진입장벽 Scala Spark API 사용방법 ML Spark.mllib는 RDD를 기반으로, Spark.ml는 DataFrame 기반으로 만들어짐. Data Types vector = array Local vector는? 분산이 아니라 싱글 머신(1 JVM)에 있는 Array dense vector: 일반적인 array sparse vector: array이긴 한데, 복잡한 array (ex: Verctors.sparse(10, Array(1, 2), Array(2, 3))) LabeledPoint: 레이블이 붙은 벡터 Matrix vector 모음 IndexedRowMatrix vector가 stack처럼 쌓여있는 것 CoordinateMatrix BlockMatrix ML 예제: https://goo.gl/ 어떤 ML 함수를 쓰느냐에 따라 vector나 matrix 써야됨","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"http://icednut.github.io/tags/Spark/"}]},{"title":"스파크 강의 노트 Day 1","slug":"20170525-spark-lecture-day01","date":"2017-05-25T00:02:31.000Z","updated":"2018-11-27T06:40:43.279Z","comments":true,"path":"2017/05/25/20170525-spark-lecture-day01/","link":"","permalink":"http://icednut.github.io/2017/05/25/20170525-spark-lecture-day01/","excerpt":"","text":"Scala 훑어보기 실습 (SparkIntro/0. Scala Programming) zeppelin을 통해 스칼라 코드를 간단하게 실행해보자. (스칼라 관련 예제 notebook을 import 하여 실행해봄) Tip. 실행 후 소스코드를 더블클릭 해보면 수정이 가능함 Spark Overview MapReduce 오버뷰, Spark와 MapReduce를 비교하여 뭐가 좋은지 Spark로 할 수 있는게 뭐가 있을까? ETL, Crawling, Statistics Spark로 할 수 없는건? 시각화, 데이터 수집 결국 Spark를 쓰는 목적은 데이터를 저장소에서 읽어서 가공 후 저장하는 것을 분산처리 방식으로 프레임워크화 된 기술을 쓰기위해서 쓰는 것 Spark 실행 환경 구축하기 Spark를 하려면 로컬 머신에서 개발용으로 할 것인지, 여러 머신에서 Clustering해서 분산 처리할 것인지에 따라 다르다. Local Machine 개발용으로 Spark 환경 구축하기 크게 두 가지로 나뉘는데, Zeppelin만 설치하거나 Spark-submit을 사용하면 되는데 Zeppelin을 설치하면 Spark &amp; UI, HDFS가 포함되어 있기 때문에 따로 설치할 필요가 없는 반면, Spark-submit을 쓰려면 저장소인 hdfs나 분산처리 매니징 기술인 YARN, 그리고 Spark 실행 모니터링을 하기 위한 Spark UI를 직접 설치해줘야 한다. Zeppelin 설치 Zeppelin 공식 사이트에서 제플린 다운로드 zeppelin을 로컬에서 실행하기 위한 설정 진행 (아래 설정파일 참고) $ZEPPELIN_HOME/bin/zeppelin.sh 실행#!&#x2F;bin&#x2F;bash ... export JAVA_HOME=&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_121.jdk&#x2F;Contents&#x2F;Home export HADOOP_HOME=&#x2F;Users&#x2F;1002371&#x2F;Dev&#x2F;hadoop-2.8.0 export SPARK_HOME=&#x2F;Users&#x2F;1002371&#x2F;Dev&#x2F;spark-2.1.1-bin-hadoop2.7 export HADOOP_CONF_DIR=${HADOOP_HOME}&#x2F;etc&#x2F;hadoop Hadoop(YARN) 설치 Hadoop 공식 사이트에서 하둡 다운로드 $HADOOP_HOME/etc/haddop/hdfs-site.xml 등등 설정파일에 HDFS 관련 설정 진행하기 (아래 설정 예시 참고) $HADOOP_HOME/bin/start-all.sh 실행 (YARN과 HDFS 실행됨)&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt; &lt;value&gt;hdfs:&#x2F;&#x2F;127.0.0.1:8020&#x2F;&lt;&#x2F;value&gt; &lt;description&gt;NameNode URI&lt;&#x2F;description&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.teamsk.groups&lt;&#x2F;name&gt; &lt;value&gt;*&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.teamsk.hosts&lt;&#x2F;name&gt; &lt;value&gt;*&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;&#x2F;configuration&gt; &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;?xml-stylesheet type=&quot;text&#x2F;xsl&quot; href=&quot;configuration.xsl&quot;?&gt; &lt;!-- Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http:&#x2F;&#x2F;www.apache.org&#x2F;licenses&#x2F;LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. See accompanying LICENSE file. --&gt; &lt;!-- Put site-specific property overrides in this file. --&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;&#x2F;name&gt; &lt;value&gt;file:&#x2F;&#x2F;&#x2F;home&#x2F;teamsk&#x2F;Sparklab&#x2F;hadoop-2.8.0&#x2F;data&#x2F;datanode&lt;&#x2F;value&gt; &lt;description&gt;Comma separated list of paths on the local filesystem of a DataNode where it should store its blocks&lt;&#x2F;description&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;&#x2F;name&gt; &lt;value&gt;1&lt;&#x2F;value&gt; &lt;description&gt;Default block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time.&lt;&#x2F;description&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;&#x2F;name&gt; &lt;value&gt;file:&#x2F;&#x2F;&#x2F;home&#x2F;teamsk&#x2F;Sparklab&#x2F;hadoop-2.8.0&#x2F;data&#x2F;namenode&lt;&#x2F;value&gt; &lt;description&gt;Path on the local filesystem where the NameNode stores the namespace and transaction logs persistently.&lt;&#x2F;description&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;&#x2F;name&gt; &lt;value&gt;true&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;&#x2F;configuration&gt; Spark 설치 Spark 공식 사이트에서 스파크 다운로드 Spark App 코드 작성 후 jar로 묶기 $SPARK_HOME/bin에서 spark-submit.sh 실행하는데 실행 파라미터로 앞에서 만든 JAR 파일 입력하면 스파크 구동됨#!&#x2F;usr&#x2F;bin&#x2F;env bash ... export HADOOP_CONF_DIR=&#x2F;Users&#x2F;1002371&#x2F;Dev&#x2F;hadoop-2.8.0&#x2F;etc&#x2F;hadoop Spark 실습 (SparkIntro/1. RDD Programming) SparkContext를 활용하여 word counting 등 간단한 실습 Spark’s Fault Tolerance: 파티션이 날라가면 계보를 따라 복구 후 다시 해당 파티션만 실행 deterministically recomputable operations -&gt; Lazy Evaluation 개념 (이게 되어야지 fault tolerance가 됨) Spark ArchitectureReview Two Types of Operations - transformation and action Transaformations are lazy Transformations are executed when an action is run. Persist and cache 동작 방식 (ETL 기반, 읽고 처리하고 저장) hdfs 읽기 -&gt; 필터링 -&gt; 파티션 조정 -&gt; 저장 coalesce(2) // 원하는 데이터만 뽑아낸 뒤 파티션을 정리할 때 사용 늘릴땐 repartition 메모리 이슈가 발생할 땐 job이 죽음 -&gt; 파티션 조정이 필요 Spark Job Job: RDD로 계산하는 가장 최소 단위 Stage: 코드가 실행된 파이프라인된 RDD 단위 Task: 스테이지에서 RDD 파티션에 따른 실행 단위 Shuffle Executor: 분산해서 실행시키는 주체 Spark Runtime Architecture 교육에서는 Spark Shell을 쓸 수도 있지만 Zeppelin을 쓴다. Zeppelin을 설치하면 스파크 관련 리소스가 생성됨 Spark Shell을 쓰면 SparkContext를 직접 생성해줘야 함 Spark을 클러스터링 하려면 Mesos, YARN을 써야됨 Driver Program, Cluster Manager, Worker Spark Context를 생성하면서 클러스터를 지정? Spark Deployment 분산환경에 Deploy할 때는 Mesos, Apahce YARN을 고려해야 됨 Cluster Manager: 자원을 할당하거나 작업실행을 관리 Spark-repl: spark shell을 띄우지 않아도 spark 코드를 실행시킬 수 있는 환경 Spark Shell 로컬에서 띄우기: 간단한걸 테스트할 때 로컬에서 실행시키는게 좋음 Spark 코드 작성 -&gt; Jar로 묶기 -&gt; 클러스터에 배포 (배포할 때 쓰는게 spark-submit) Spark 실행 관련 설정은 conf 파일로 쓰거나 spark-submit의 옵션, 코드로 new SparkConf()에 셋팅할 수 있다. StandAlone 모드: Master가 죽으면 안되기 때문에 Zookeeper를 사용하여 backup master가 실행할 수 있도록 해준다. (Mesos, YARN을 사용하여 클러스터링 할 때는 상관 없음) Yarn Mode: Resource Manager, Node Manager의 개념으로 동작 YARN Client Mode: 얀 밖에서 실행할 때 사용 (자원이 많지 않을 때 즉 Driver에서 많은 작업을 할 때 사용, Driver에서 많은 결과물을 전달해야 된다거나 등등..) YARN Cluster Mode: 클러스터 내에서 리소스 매니저를 지정 Dynamic Resource Allocation on YARN: Application의 Work node에 따라서 서버가 조정. ETL을 밤에 띄울 때 서버가 많이 필요할 시 서버를 동적으로 늘려서 실행하고 싶을 때 사용 RDD를 날리지 않고 재사용하기 위해 external shuffle plugin을 설치해야됨 executor의 min, max 갯수를 지정하면 work node 내에서 실행되는 스레드 갯수 지정? Mesos Mode: Mesos는 하둡진영 뿐 아니라 일반 어플리케이션 진영까지 자원관리 가능 Job Server: SparkContext를 Spark 어플리케이션을 실행할 때마다 생성하는게 아니라 Job Server에 SparkContext를 생성해서 공유해서 사용 (Production 환경에서 사용) Hardware sizing Storage: HDFS(추천) or local Local disk: raid 구성 안함, 한 노드당 디스크를 25TB 4-8개를 붙여서 씀? CPU: 객체 직렬화, 역직렬화 때문에 CPU를 많이 잡아먹음. 한 노드당 8-16 core를 추천 Network: 셔플링이 많을 경우 네트워크 고민 필요. 10GB Memory: 8GB to hundreds of gigabytes, allocating only at most 75% of the memory. Spark on cloud AWS 사용 사례 소개","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"http://icednut.github.io/tags/Spark/"}]},{"title":"스프링캠프 2017 둘째날 메모","slug":"20170423-spring-camp-day02","date":"2017-04-23T03:16:51.000Z","updated":"2018-11-27T06:40:43.281Z","comments":true,"path":"2017/04/23/20170423-spring-camp-day02/","link":"","permalink":"http://icednut.github.io/2017/04/23/20170423-spring-camp-day02/","excerpt":"","text":"들은 세션 목차 Keynote Reactive Spring ( Spring 5 &amp; Reactor ) 이벤트 소싱 (Event Sourcing) 소개 Implementing EventSourcing &amp; CQRS (구현부) Indroductory RxJava Spring Data Envers Keynote발표자료: http://benelog.github.io/docs/spring-camp-2017/ spring-composed? Reactive Spring: Spring 5 &amp; Reactor (발표자: 정윤진)발표자료: https://www.slideshare.net/PivotalKorea/reactive-spring5-springcamp2017-23th-of-april Spring 5가 어떤 모양으로 될지, Reactor가 어떻게 적용될지 소개 Ice Breaking http://www.slideshare.net/KevinMcEntee/netflix-incloudsmarch8-2011forwiki 데이터베이스의 장애가 서비스 전체 장애로 이어짐 -&gt; 서비스 분리가 안됨 Reactive로 분산된 서비스에 대한 요청 처리를 어떻게 할 수 있을지 소개 (Spring 5 reactor) Spring 5 JDK 9, HTTP/2, Reactive 차용 Project Reactor 왜 필요한가? 2000년대에 의존하는 기술이 많음 -&gt; 요청 처리에 대한 처리를 Thread별로 진행 (요청 지연이 각각 다름) -&gt; 요청이 더 많아지는 것을 처리하기 위해 Load Balancer를 앞에 둠(Are you dead?) -&gt; 어플리케이션이 통으로 하나가 되어 있는 경우라서 처리할 서버만 늘리는 꼴 이 구조를 탈피할순 없을까? Nonblocking Runtime -&gt; 요청 처리만큼 스레드를 만들지 말자라는 아이디어에서 출발 -&gt; 요청을 받을 때마다 가용한 스레드가 뭔지 알 필요없이 Pub/Sub으로 Worker Thread에게 요청처리를 알림 JVM을 위한 Reactive Streams Reactive Manifesto 응답성: 모든 요청에 대해 적시에 응답, 문제에 대해 빠르고 효율적으로 응답 탄력성: 시스템 부하, 자원 변경에도 응답성을 유지 회복성: 시스템이 장애에도 응답성을 유지 (Circuit Breaker, 응답 불가 상태를 감지하여 미리 지정한 응답으로 전달) 메세지 중심: 리액티브 시스템은 느슨한 결합을 사용, 컴포넌트들은 비동기 방법으로 메세지 드리븐으로 동작 Reactive System, Reactive Programming -&gt; 복수개의 서비스로 이루어진 분산 시스템에 대한 해법, Microservice가 지향하는 방향 Reactive Streams 인프라간의 상호 운용성에 집중 (웹서버, 데이터 저장소 드라이버, 프레임워크) NonBlocking Backpressure 지원 -&gt; 응답 못하면 다른 곳에서 처리할 수 있게 -&gt; 백프레셔는 응답을 처리하지 못하면 역류 RxJava, Project Reactor, Vert.x, Akka Subscriber가 처리를 못하면 Publisher가 큐에 담아놓고 Subscriber를 확보한다. 크게 Mono와 Flux를 보면 됨 docker run -p 127.0.0.1:27017:27017 mongo Reactive 디버깅은? 뭐 있었는데 못봄… Managing State with RxJava By Jake Wharton 이벤트 소싱 (Event Sourcing) 소개 (발표자: 이규원)발표자료: http://doc.co/fggswS 이벤트 소싱 이벤트 소싱하면 착각하는거? 이벤트 드리븐 아키텍쳐와 착각 -&gt; 이벤트 소싱은 이벤트를 저장하는 것에 대한 것이지 이벤트를 주고 받는다는 것이 아님 장비구니에 대한 상태는 마지막 것만 저장됨 -&gt; 넣었다가 뻈다가 하는 것에 대한 것은? 이걸 캐치해야지 추천이 가능하지 않을까? 이벤트는 도메인에 대한 사실을 기록하진 않음 이벤트 소싱은 변화를 나타내는 이벤트를 저장하고 이 이벤트를 재생해서 일련의 상태를 만들어냄? -&gt; 도메인에서 발생하는 모든 이벤트를 기록하는 일 -&gt; 외부에서 명령을 받으면 결과로 이벤트를 저장 (ex: 장바구니에 물건을 담았다라는 행위를 기록) -&gt; 상태는 영속 대상이 아니며 이벤트가 영속 대상, 상태는 추가될 뿐 이벤트 소싱의 예) AWS, GIT 데이터 영속 이벤트 저장소는 하나의 거대한 이벤트 스트림이 아님 -&gt; 이벤트 저장소는 수많은 이벤트 스트림으로 구성됨 -&gt; 도메인 오브젝트 하나 당 이벤트 스트림이 저장됨 커맨드와 이벤트는 하나의 데이터 명령(Cammand)는 유효한지 검증이 필요, 반면 이벤트는 이미 지나간 사실 그러므로 검증 대상이 아님 -&gt; 이벤트는 정책이 바뀌어도 실패라는게 없음 -&gt; 이벤트는 재생하면 항상 성공해야함 이벤트 소싱은 데이터베이스가 뭔지 상관없이 모두 구현 가능 -&gt; 임피던스 미스매치가 발생하지 않음 CompoundPrimary Key: ShoppingCartId (Object Id), Version | Value: EventType, Payload 백만개의 이벤트를 가지는 도메인 개체일 경우에는? 성능이 이슈가 될 수 있다. 스냅샷을 사용 -&gt; 특정 상황이 있을 떄마다 이벤트를 스냅샷으로 남긴다. 스냅샷 이후의 이벤트만 재생하기 때문에 성능 이슈가 나타나지 않음 Key: ObjectId | value: Version, payload Messaging 이벤트 소싱에서는 정확히 한 번 배달이 어렵다. 메세지 누락이 있을 수가 있어서 비지니스에서는 쓰기 어렵다? 메세지를 한 번 이상 보낼 수도 있다라는 것 때문에 멱등성 문제가 있을 수 있다. 이벤트 소싱은 정확히 한 번 배달은 어렵지만 최소 한 번 배달은 쉬울 수 있다. 이벤트 스트림은 순서를 보장 CQRS 재고가 10개 미만인 상품 조회 -&gt; 이벤트 스토어를 풀스캔하여 찾는다? 이벤트 스토어는 다양한 비지니스에 대한 조회를 충족할 수 없다. 그러므로 무조건 CQRS를 적용해야 함 Command Query Seperation: 질문은 대답을 변경하지 않는다. 질문에 대한 답만 하는 메서드, 저장은 하되 응답은 하지 않는 메서드 이렇게 둘로 나누는 기법 CQS를 DDD에 적용하다가 더 발전해서 Command Side / Query Side와 같이 시스템 자체를 나누는 CQRS로 발전 Command Side의 이벤트 스토어에 모두 저장 Query Side의 Materialized Store에 복사해서 사용 (정규화, 중복 데이터는 신경 안씀) 고려사항 익숙하지 않아 학습 곡선이 좀 있다. 비동기와 씨름해야 된다. https://github.com/Reacture/Khala.EventSourcing Implementing EventSourcing &amp; CQRS 구현부 (발표자: 심천보)발표자료: https://github.com/jaceshim/springcamp2017/blob/master/springcamp2017_implementing_es_cqrs.pdf예제소스: https://github.com/jaceshim/springcamp2017 이벤트 소싱은 데이터 저장 방식의 새로운 패턴! 스냅샷은 인메모리로 관리? 구현 소스: https://github.com/jaceshim/springcamp2017 데이터 변경 시 버전을 먼저 체크 Axon/Eventuate Framework Indroductory RxJava (발표자: 김인태) RxJava를 이해하려면… 비동기, Java 8 Lamda, High-order function 메인스레드에서 Sub 스레드 수행 시 Sub 스레드의 종료 로그가 안찍힘 왜? setDaemon(boolean) join() 블로킹 방식이기 때문에 notify를 사용 Java에서 스레드 생성 시 스택 공간을 잡음 (1MB) Multi-Thread를 직접할 때 문제가 될 수 있음 (without threadPool) Spring Data Envers (발표자: 김영한) 변경 이력을 어떻게 할 것인가? RevisionRepository를 다른 데이터베이스 서버의 DataSource를 쓸 순 없을까? 그 외이번 스프링캠프의 이벤트소싱 주제는 실로 충격이었다. 마이크로서비스, Reactive Programming, Spring Cloud Data Flow와 같은 것들이 이벤트 소싱을 하기 위한 발판 같아 보였다. (어쩌면 나의 오해일수도..^^;) 아무튼 내가 하고 있는 업무에 대해서는 규모가 커지면 터질게 분명했다. 개선은? 예전 방식과 비슷한 새로 개발이라는 어리석은 선택을 하지 않기 위해 미리 공부해 대비해놔야겠다. Thread의 이해 Reactive Programming (Project Reactor or RxJava) DDD Event Sourcing","categories":[],"tags":[{"name":"spring","slug":"spring","permalink":"http://icednut.github.io/tags/spring/"},{"name":"springcamp","slug":"springcamp","permalink":"http://icednut.github.io/tags/springcamp/"}]},{"title":"스프링캠프 2017 첫째날 메모","slug":"20170422-spring-camp-day01","date":"2017-04-22T03:14:08.000Z","updated":"2018-11-27T06:40:43.294Z","comments":true,"path":"2017/04/22/20170422-spring-camp-day01/","link":"","permalink":"http://icednut.github.io/2017/04/22/20170422-spring-camp-day01/","excerpt":"","text":"들은 세션 목차 Keynote 프로세스, 스레드, 리액티브 Aync@Spring Spring WebFlux Spring Cloud Data Flow 비동기 어플리케이션과 모니터링으로 밀당하기 그 외 Keynote 히든 피겨스(Hidden Figures) 프로세스, 스레드, 리액티브 (발표자: 부종민)발표자료: https://docs.google.com/presentation/d/1gIZP1DBTTXnGtIgU1KPD6TWxQlOqZAjFOpE2F_jrNiY/mobilepresent?slide=id.g35f391192_00 프로세스는 프로세스 별로 메모리 공간 관리 멀티프로세스는 컨텍스트 스위칭 시 L1, L2, L3 Cache를 비움 Java Internal I/O Blocking 관련된 비지니스는 스레드로 개발한 경우가 많음 Java Thread1: Thread Class + Runnable interface (Java Thread는 OS Thread를 사용) 코드의 실행 흐름을 알기 어렵다. Thread의 실행 결과물을 공유하기 어렵다. -&gt; Main Thread에서 Sub Thread의 결과를 받고 싶을땐 어떻게할까? Main Thread에서 HashMap을 만들고 Sub Thread에서 거기에 저장 동기화는? wait(), notify(), syncronized -&gt; 개발자의 실수가 많아짐 구현 Example Java Thread2: Future, Callable 비동기 작업의 결과를 받아오고 싶을 떈 Future Interface의 get()를 사용 구현 Example Executors.newSingleThreadExecutor() Future는 JDK 1.5에서 등장 Future만으로도 만족스럽긴 한데 thread를 직접 사용하는건 쉽지 않음 (지식 + 경험 필요), 스레드풀에 대한 지식도 필요 ThreadPool 사용 시 트래픽 폭주 시 큐에 스레드가 많이 쌓여서 오히려 속도가 더 안나오는 경우가 있음 newCacheThreadPool 사용 시 1 request 처리 시 7 thread가 필요한데 트래픽 폭주 시 스레드가 폭등 Java Thread3: CompletableFuture Future 사용 시 콜백 지옥에 빠질 수 있음 Future 시리즈 중 끝판왕 interface CompletionStage 구현 Example CompletableFuture는 JDK 1.8 부터 추가됨 Task간 순서와 조합을 CompletableFuture를 사용하여 Chaining 방식으로 해결할 수 있음 (CompletableFuture.thenApply(), CompletableFuture.thenCombine(), CompletableFuture.thenApplyAsync()) 좋긴한데 이것도 싱글 밸류에 콜백 형태이다. -&gt; Collection에 넣고 CompletableTure를 할 수 없을까? Java NIO 아직 풀지 못한 상황 ThreadPool Full Circuit Breaker를 하다가 NonBlocking으로 해볼 수 있지 않을까? NIO 이전: Native IO의 내용을 JVM Heap에 복사해서 IO NIO 이후: Native IO를 그대로 사용 Nonblocking I/O Servlet 3.0: AsyncServlet Servlet 3.1: Nonblocking I/O Event Programming: CF의 공통점 complete로 깨워서 thenApply에서 처리한다. -&gt; 이벤트 드리븐 프로그래밍 방식 아닌가? 이벤트가 발생한다는 전제를 깔고 프로그래밍 이벤트 세상에서 오히여 절차형으로 프로그래밍하는게 어렵다? -&gt; 이벤트 프로그래밍을 위해 잘 추상화된 API -&gt; Reactive Programming, JDK9 Flow 너무 공부할게 많다. -&gt; 범위를 좁혀보자. Java, Spring, Reactive -&gt; Reactive Stream 성능은? -&gt; backpressure valve (배압밸브?) -&gt; Circuit Breaker 패턴과 비슷 (Spring 5 MVC에 포함됨) http://github.com/boojongmin/presentation Aync@Spring (발표자: 이일민) Spring 3.2 ~ 4.3에서 비동기 개발을 어떻게 할 것인가? 스프링 비동기 개발 기본지식은 뭐가 필요할까? 자바 비동기 개발지식 (Java Thread …) 서블릿 비동기 개발 (Servlet 3.x …) 스프링 비동기 개발 (@Async, AsyncRestTemplate) 동기/비동기를 언급할 때는 뭐랑 뭐가 시간을 맞출 것인가를 기억하자. Sync, Async Blocking, Nonblocking 블로킹, 넌블로킹은 대상이 제한적임 (IO, Multi-Thread) 어떤 것에 대해 비동기 동기냐, 어떤 작업에 대해 블로킹, 넌블로킹이냐로 분리해서 생각해보자. @Async 사용 시 메소드 리턴타입이 String일 때는 null이 반환됨 -&gt; void, Future, ListenableFuture, CompletableFuture를 쓰자. -&gt; new AsyncResult()에 담아서 리턴하자. ListenableFuture: Spring 4.0 부터 추가됨 -&gt; 성공 결과와 오류(Exception) 결과를 따로 나눠서 받을 수 있음 CompletableFuture.CompletedFuture(result); @Async를 아무런 설정없이 쓴다면 SimpleAsyncTaskExecutor를 사용함 -&gt; 쓰레드풀이 아니며 실전에서는 사용하지 말자. (단점: @Async를 쓸 때마다 스레드를 새로 만듬, 불릴 떄마다 스레드가 생기므로 1000번 호출하면 스레드 1000개가 생성된다고 보면 됨) ThreadPoolExecutor는 처음엔 큐 사이즈만큼 스레드 실행을 대기하고 CoreSize 만큼 스레드를 생성한다. 비동기 Spring@MVC Servlet 3.0 + Spring MVC 비동기 처리 타임아웃이 필요한 API에는 리턴타입으로 WebAsyncTask을 사용하자. DeferredResult와 @Async를 결합한 것을 스프링이 만들어놓음 -&gt; 리턴타입을 그냥 ListenableFutre로 쓰면 똑같이 동작 -&gt; 콜백 지옥에 빠질 수 있음 CompletableFuture를 쓰자 -&gt; CompletionStage의 조합으로 콜백 체이닝으로 표현할 수 있음 AsyncRestTemplate (비동기 논블로킹 API 호출) RestTemplate는 API 호출 시 블로킹 됨 -&gt; 쓰레드를 하나 잡고 있는 동기 방식 AsyncRestTemplate는 비동기, 논블로킹 방식으로 API 호출 가능 톰캣은 스레드 200개 밖에 안되는데 ART로 100개의 API 호출하면 스레드 100개가 생성된다. 낭비 아닌가? Nonblocking IO를 사용하진 않는다는 뜻 논블로킹 IO를 사용하는 AsyncRestTemplate를 사용해야 함 -&gt; Netty Http Client Factory를 사용하자. (100번 API 호출해도 쓰레드 1개로 처리) 결론 스프링의 모든 비동기 기술에는 ExecutorService의 세밀한 설정이 가능 모르고 쓰면 안됨! 설명할 수 있어야 하고 증명할 수 있어야 한다. (잘 모르고 쓰면 이게 주는 혜택도 뭔지 모를 수 있다.) 디버깅이 좀 힘들 수 있다. Spring WebFlux (발표자: 이일민) Spring 5.0 WebFlux 소개와 개발 방법 스프링 리액티브 스택의 웹 파트 담당 왜 쓸까? 비동기-논블로킹 리액티브 개발에 사용 (CPU, 자원 낭비 없이 효율적인 고성능 웹앱 개발을 위해) @MVC 스타일로 개발할 수 있지만, Annotation이 없는 웹개발을 진행하게 되며, 서블릿 스택과 API에서 탈피 (서블릿이 지원하는 컨터이너에서 동작은 하지만 서블릿을 쓰는건 아님) 서블릿 스레드를 빨리 반환하게 하는 방식으로 개선 가능 WebFlux만으로는 성능이 좋아지지 않는다. 동기-블로킹 방식의 환경일 때는.. -&gt; 그럼 개선사항은? 데이터 액세스 리포지토리: JDK10 에서 AsyncJDBC를 지원할수도…, Spring Data JPA의 리턴타입을 @Async와 CompletableFuture로 사용, MongoDB, Cassandra, Redis를 사용하여 논블로킹 방식으로 데이터를 받아낼 수 있다. (DB부터 Web까지 논블로킹으로 동작하게 할 수 있다.) HTTP API 호출: WebClient를 사용하며, 처음 쓸 떄는 람다로 타입이 가려진채로 쓰지말고 명시적으로 타입이 나온 형태로 코드를 작성해보자. 혜택을 보려면… WebFlux + Reactive Repository, Reactive Remote API call + @Async Block IO을 지원해야 한다. Spring Cloud Data Flow (발표자: 정윤진) 데이터 마이크로서비스? Pipeline! Greenplum (http://greenplum.org/) https://github.com/melofred/FraudDetection-Microservices.git SpringOne 할인코드: S1P200_Jeong 비동기 어플리케이션과 모니터링으로 밀당하기 (발표자: 이건희) 비동기 어플리케이션 모니터링의 어려움과 어떻게 해결할지에 대해 얘기함 CPU는 그대로 응답시간이 올라가고 처리량이 떨어질떈? Restart -&gt; APM으로 성능 메트릭 &amp; 원인 찾기 BCI? Byte code instrumentation -&gt; premain(), ASM, Javassist 스레드 덤프를 뜨면 스레드 스택 트레이스의 시작 시간, 파라미터 정보를 보고 싶다. 어떻게? BCI 스레드의 이름을 바꿈 -&gt; 해당 스레드 이름으로 로그를 찾으면되지 않을까? MDC (Logging Framework) Block Multi-thread는 스레드덤프 이해하기가 쉽다. 그 반대는? asyncRestTemplate에 병목이 걸린 경우에는 스레드 덤프에도 안나옴 어떻게 해결? Netflix의 사례를 살펴보자. ThreadLocal을 통해 context 정보를 공유할 수 없음 -&gt; ThreadPool 같이 스레드 재사용 하는 환경에서는 쓸 수 없음 Runnable, Callable으로 해서 스레드 로컬로 this를 키값으로 저장 Lambda일 때는? 람다는 이너 클래스이긴 하지만 이너 클래스가 아니다. Lambda Proxy -&gt; 람다 바디는 private static method -&gt; 람다의 생성자는 어디며, this는 누구? LambdaMetaFactory! ByteBuddy를 통해 LambdaMetaFactory를 transfrom 한다. 그 외 인텔리제이 &gt; Key Promoter: 버튼이나 메뉴 누르면 단축키 보여주는 플러그인 마젤란홀에서만 있었는데 앞사람 머리 때문에 프리젠테이션이 잘 안보인다..","categories":[],"tags":[{"name":"spring","slug":"spring","permalink":"http://icednut.github.io/tags/spring/"},{"name":"springcamp","slug":"springcamp","permalink":"http://icednut.github.io/tags/springcamp/"}]},{"title":"Scala 강의 요약","slug":"20170419-scala-lecture-review","date":"2017-04-19T00:09:37.000Z","updated":"2018-11-27T06:40:43.286Z","comments":true,"path":"2017/04/19/20170419-scala-lecture-review/","link":"","permalink":"http://icednut.github.io/2017/04/19/20170419-scala-lecture-review/","excerpt":"","text":"목차 Scala 환경 구축하기 Scala 변수, 상수, 타입 함수와 메소드 Lab 1 제어구조 함수 정의 Lab 2 Arrays, Maps and Tuples Lab 3.1 Remove First Negative Lab 3.2 Word Count Lab 3.3 Grouping Lab 3.4 Partitions and Zips Classes and Objects Lab 4.1 Time Lab 4.2 Uniform Access Lab 4.3 Uniform Access (con’t) Lab 4.4 Operators Packages, Inheritnce, Traits Functional Programming 9.1 Function 9.2 Closures 9.3 Currying Pattern Matching Case Class 1. Scala 환경 구축 JDK 1.8 설치 SBT 설치 Scala 설치 IntelliJ 설치 (스칼라가 처음라면 Scala IDE for Eclise) 2. Scala 변수, 상수, 타입 변수는 var 상수는 val로 선언 Scala에서 데이터 타입의 종류 자바와 비슷 Byte, Short, Int, Long, Float, Double, Char, String, Char, Boolean 단 자바에서는 없는 Unit, Null 이라는 타입도 있음 object Lesson1 { val answer = 8 * 5 + 2 var greeting: String = &quot;Hello World&quot; } object Lesson2 { 1.to(10) &#x2F;&#x2F; 1 ~ 10까지 값을 갖고 있는 배열이 만들어짐 &quot;Hello&quot;.intersect(&quot;World&quot;) &#x2F;&#x2F; lo &quot;Hello&quot; intersect &quot;World&quot; 1.+(10) 1 + 10 var i = 0 &#x2F;&#x2F; i++ 이거는 안됨 i += 1 } 3. 함수와 메소드 파라미터 없는 함수 호출은 다음과 같다.&quot;hello&quot;.distinct 스트링에 아래와 같이 함수 이름 없이 호출하면 apply 함수가 실행 되는 것과 같음&quot;Hello&quot;.(4) &quot;Hello&quot;.apply(4) &quot;Hello&quot;(4) Lab 1object Lesson4 { import scala.math._ sqrt(10) 1.to(10).map(sqrt(_)) 6.*(7) } 4. 제어구조 if 표현식은 값을 반환할 수 있다.if (x &gt; 0) 1 else -1 if (x &gt; 0) &quot;positive&quot; else -1 &#x2F;&#x2F; Type is Any if (x &gt; 0) 1 &#x2F;&#x2F; Missing else... else일 때는 Unit을 반환 if (x &gt; 0) 1 else () &#x2F;&#x2F; 위 수식과 이 수식은 같음 변수나 상수 선언 시 아래와 같이 스코프 지정이 가능val distance = { import scala.math._ val dx = x - x0 val dy = y - y0 sqrt(dx * dx + dy * dy) } 기본적인 For Loopfor (i &lt;- 1 to n) for (ch &lt;- &quot;Hello&quot;) for (i &lt;- 1 to 3; j &lt;- 1 to 3) print((10 * i + j) + &quot; &quot;) &#x2F;&#x2F; multiple generator For Loop Guardfor (ch &lt;- &quot;Hello&quot;) &#x2F;&#x2F; 한 글자씩 Loop for (i &lt;- 1 to 3; j &lt;- 1 to 3 if i != j) print((10 * i + j) + &quot; &quot;) for (i &lt;- 1 to 10) yield i % 3 5. 함수 정의 함수 정의 시 함수 몸통 앞에 ‘=’를 붙이고 안붙이고 차이는 뭘까? 반환값이 있을 때 ‘=’를 붙인다. 반환값이 없을 때는 ‘=’를 붙이지 않는다. def abs(x: Double) = if (x &gt;= 0) x else -x def fac(n: Int): Int = { if (n &lt;= 0) 1 else n * fac(n - 1) } def box(s: String) { val border = &quot;-&quot; * s.length + &quot;--\\n&quot; println(border + &quot;|&quot; + s + &quot;|\\n&quot; + border) } 아래와 같이 반환값이 있는 함수를 작성하고 싶은데 =를 안붙이면 컴파일 오류가 발생한다. def fac(n: Int) { var r = 1 for (i &lt;- 1 to n) r = r * i r } Named argument def decorate(str: String, left: String = &quot;[&quot;, right: String = &quot;]&quot;) = left + str + right decorate(&quot;Hello&quot;, right = &quot;]&lt;&lt;&lt;&quot;) &#x2F;&#x2F; [Hello]&lt;&lt;&lt; 다항 파라미터는 파라미터 데이터타입 뒤에 *을 붙여준다. def sum(args: Int*) = { var result = 0 for (arg &lt;- args) result += arg result } 위 메소드의 파라미터에 Seq[Int]를 다항 파라미터로 변환하여 넣고 싶을 경우 아래와 같이 한다. val s = sum(1 to 5: _*) &#x2F;&#x2F; 1 to 5의 반환값은 Seq[Int] What is that _? _ is joker Lab 2. 함수 정의 연습하기계속… 6. Array, Maps and Tuples Array.sum ArrayBuffer.max ArrayBuffer.sorted Array.reverse Array.mkString() // Array의 내용물을 스트링으로 출력 (예쁘게) val c = Array(2,3,5,7,8,11) &#x2F;&#x2F;&gt; c : Array[Int] = Array(2, 3, 5, 7, 8, 11) val result = for (elem &lt;- c if elem % 2 != 0) yield 2 % elem &#x2F;&#x2F;&gt; result : Array[Int] = Array(2, 2, 2, 2) val mySong = ArrayBuffer(&quot;Mary&quot;, &quot;had&quot;, &quot;a&quot;, &quot;little&quot;, &quot;lamb&quot;) &#x2F;&#x2F;&gt; mySong : scala.collection.mutable.ArrayBuffer[String] = ArrayBuffer(Mary, h &#x2F;&#x2F;| ad, a, little, lamb) mySong.max &#x2F;&#x2F;&gt; res11: String = little mySong.sorted &#x2F;&#x2F;&gt; res12: scala.collection.mutable.ArrayBuffer[String] = ArrayBuffer(Mary, a, h &#x2F;&#x2F;| ad, lamb, little) Array(1,7,4,5).sorted &#x2F;&#x2F;&gt; res13: Array[Int] = Array(1, 4, 5, 7) Array(1,7,4,5).reverse &#x2F;&#x2F;&gt; res14: Array[Int] = Array(5, 4, 7, 1) Array(1,2,3).mkString(&quot;[&quot;, &quot;, &quot;, &quot;]&quot;) &#x2F;&#x2F;&gt; res15: String = [1, 2, 3] 6.1 Maps Map.getOrElse 메소드는 key에 해당하는 value를 못찾을 경우 기본 값을 반환한다. updating map을 하고 싶을 땐 그냥 Map(“Bob”) = 20 append와 remove는 연산자 메소드를 통해서 가능 (+=, -=) val scores = Map(&quot;Alice&quot; -&gt; 20, &quot;Bob&quot; -&gt; 10, &quot;Cindy&quot; -&gt; 8) &#x2F;&#x2F;&gt; scores : scala.collection.immutable.Map[String,Int] = Map(Alice -&gt; 20, Bob - &#x2F;&#x2F;| &gt; 10, Cindy -&gt; 8) scores(&quot;Alice&quot;) = 291 &#x2F;&#x2F; immutable map이라서 value 값을 바꿀 수 없음 val mscores = scala.collection.mutable.Map(&quot;Alice&quot; -&gt; 10) &#x2F;&#x2F;&gt; mscores : scala.collection.mutable.Map[String,Int] = Map(Alice -&gt; 10) val bobsScore = scores(&quot;Bob&quot;) &#x2F;&#x2F;&gt; bobsScore : Int = 10 val bogsScore = scores(&quot;Bog&quot;) &#x2F;&#x2F;&gt; java.util.NoSuchElementException: key not found: Bog &#x2F;&#x2F;| at scala.collection.MapLike$class.default(MapLike.scala:228) &#x2F;&#x2F;| at scala.collection.AbstractMap.default(Map.scala:59) &#x2F;&#x2F;| at scala.collection.MapLike$class.apply(MapLike.scala:141) &#x2F;&#x2F;| at scala.collection.AbstractMap.apply(Map.scala:59) &#x2F;&#x2F;| at Lesson5$$anonfun$main$1.apply$mcV$sp(Lesson5.scala:6) &#x2F;&#x2F;| at org.scalaide.worksheet.runtime.library.WorksheetSupport$$anonfun$$exe &#x2F;&#x2F;| cute$1.apply$mcV$sp(WorksheetSupport.scala:76) &#x2F;&#x2F;| at org.scalaide.worksheet.runtime.library.WorksheetSupport$.redirected(W &#x2F;&#x2F;| orksheetSupport.scala:65) &#x2F;&#x2F;| at org.scalaide.worksheet.runtime.library.WorksheetSupport$.$execute(Wor &#x2F;&#x2F;| ksheetSupport.scala:75) &#x2F;&#x2F;| at Lesson5$.main(Lesson5.scala:1) &#x2F;&#x2F;| at Lesson5.main(Lesson5.scala) val bogsDefaultScore = scores.getOrElse(&quot;Bog&quot;, 0) &#x2F;&#x2F;&gt; bogsDefaultScore : Int = 0 val mbogScore = mscores.contains(&quot;Bog&quot;) &#x2F;&#x2F;&gt; mbogScore : Boolean = false mscores(&quot;Alice&quot;) = 100 mscores &#x2F;&#x2F;&gt; res0: scala.collection.mutable.Map[String,Int] = Map(Alice -&gt; 100) val newScores2 = scores + (&quot;Fred&quot; -&gt; 91) &#x2F;&#x2F;&gt; newScores2 : scala.collection.immutable.Map[String,Int] = Map(Alice -&gt; 20, &#x2F;&#x2F;| Bob -&gt; 10, Cindy -&gt; 8, Fred -&gt; 91) val newScores3 = newScores2 - &quot;Alice&quot; &#x2F;&#x2F;&gt; newScores3 : scala.collection.immutable.Map[String,Int] = Map(Bob -&gt; 10, Ci &#x2F;&#x2F;| ndy -&gt; 8, Fred -&gt; 91) for ((k, v) &lt;- scores) println(k + &quot; has score &quot; + v) &#x2F;&#x2F;&gt; Alice has score 20 &#x2F;&#x2F;| Bob has score 10 &#x2F;&#x2F;| Cindy has score 8 for ((k, v) &lt;- scores) yield (v, k) &#x2F;&#x2F;&gt; res1: scala.collection.immutable.Map[Int,String] = Map(20 -&gt; Alice, 10 -&gt; Bo &#x2F;&#x2F;| b, 8 -&gt; Cindy) scores.keySet &#x2F;&#x2F;&gt; res2: scala.collection.immutable.Set[String] = Set(Alice, Bob, Cindy) scores.values &#x2F;&#x2F;&gt; res3: Iterable[Int] = MapLike(20, 10, 8) 6.2 Tuples Map과 비슷하지만 서로다른 자료형의 데이터를 묶을 수 있음val myTuples = (1, 3.14, &quot;Fred&quot;) val pie = myTuples._2 val (_, second, third) = t Lab 3.1 Remove First Negative ArrayBuffer가 주어졌을 때 양수 값은 모두 출력 &amp; 첫 번째 음수만 출력하고 나머지 음수들은 제거하는 함수 작성 val myArray = ArrayBuffer(3,6,7,3,-4,8,-3,-5,6,7,-2,9,-1) def myRmNeg(targetArray: ArrayBuffer[Int]): ArrayBuffer[Int] = { var index = 0 var limit = myArray.length var isNegativeFound: Boolean = false val newMyArray = ArrayBuffer[Int]() while(index &lt; limit) { val num = targetArray(index) if (num &lt; 0) { if (!isNegativeFound) { isNegativeFound = true newMyArray += num } } else newMyArray += num index += 1 } newMyArray } &#x2F;&#x2F;&gt; myRmNeg: (targetArray: scala.collection.mutable.ArrayBuffer[Int])scala.colle &#x2F;&#x2F;| ction.mutable.ArrayBuffer[Int] def myRmNeg2(targetArray: ArrayBuffer[Int]): ArrayBuffer[Int] = { val targetArraySize: Int = targetArray.length &#x2F;&#x2F; 음수를 가진 인덱스 번호만 끄집어 낸다. var negativeIndexArray = for (index &lt;- 0 until targetArraySize if targetArray(index) &lt; 0) yield index negativeIndexArray = negativeIndexArray.drop(1).reverse val filterdArray = for (index &lt;- 0 until targetArray.length if !negativeIndexArray.contains(index)) yield targetArray(index) ArrayBuffer[Int]() ++= filterdArray } &#x2F;&#x2F;&gt; myRmNeg2: (targetArray: scala.collection.mutable.ArrayBuffer[Int])scala.col &#x2F;&#x2F;| lection.mutable.ArrayBuffer[Int] Lab 3.2 Word Count 파일을 읽어서 특정 단어가 몇 번 나왔는지 세보는 코드 작성하기보def wordCount(filename: String): scala.collection.mutable.Map[String, Int] = { import scala.io.Source val count = scala.collection.mutable.Map[String, Int]() for (line &lt;- Source.fromFile(filename).getLines) { for (word &lt;- line.split(&quot; &quot;)) { count(word) = count.getOrElse(word, 0) + 1 } } count } &#x2F;&#x2F;&gt; wordCount: (filename: String)scala.collection.mutable.Map[String,Int] def wordCountWithImmutableMap(filename: String): scala.collection.immutable.Map[String, Int] = { import scala.io.Source var countMap = scala.collection.immutable.Map[String, Int]() for (line &lt;- Source.fromFile(filename).getLines) { for (word &lt;- line.split(&quot; &quot;)) { val wordCount = countMap.getOrElse(word, 0) + 1 countMap += (word -&gt; wordCount) } } countMap } &#x2F;&#x2F;&gt; wordCountWithImmutableMap: (filename: String)scala.collection.immutable.Map[ &#x2F;&#x2F;| String,Int] val filename = &quot;C:\\\\Users\\\\Zotac023\\\\Desktop\\\\SCALA\\\\alice.txt&quot; &#x2F;&#x2F;&gt; filename : String = C:\\Users\\Zotac023\\Desktop\\SCALA\\alice.txt val countMap = wordCount(filename) &#x2F;&#x2F;&gt; countMap : scala.collection.mutable.Map[String,Int] = Map(talk: -&gt; 1, passi &#x2F;&#x2F;| on, -&gt; 2, Visit -&gt; 1, etext92 -&gt; 1, follow -&gt; 1, OTHERWISE -&gt; 1, provisions &#x2F;&#x2F;| -&gt; 1, machines, -&gt; 1, sighing -&gt; 2, is--&quot;Oh, -&gt; 1, sister -&gt; 5, curled -&gt; 2, &#x2F;&#x2F;| digging -&gt; 2, absurd, -&gt; 1, mouths. -&gt; 1, `When -&gt; 3, rose-tree, -&gt; 2, plea &#x2F;&#x2F;| sant -&gt; 1, can--&#39; -&gt; 1, flapper -&gt; 1, dream. -&gt; 1, morning, -&gt; 2, requires - &#x2F;&#x2F;| &gt; 1, worm. -&gt; 1, `Well! -&gt; 2, lessons -&gt; 4, Files -&gt; 1, `Boots -&gt; 1, `we -&gt; &#x2F;&#x2F;| 3, expense -&gt; 1, Shakespeare, -&gt; 1, officers, -&gt; 1, Long -&gt; 1, RED -&gt; 1, shr &#x2F;&#x2F;| ink -&gt; 1, Caterpillar, -&gt; 2, nasty, -&gt; 1, intellectual -&gt; 1, hard -&gt; 8, [Ori &#x2F;&#x2F;| ginally -&gt; 1, welcome -&gt; 1, off.&#39; -&gt; 1, RIGHT -&gt; 1, Rabbit&#39;s -&gt; 3, carry -&gt; &#x2F;&#x2F;| 1, opening -&gt; 3, matter,&#39; -&gt; 1, (luckily -&gt; 1, chimney!&#39; -&gt; 1, `As -&gt; 3, jur &#x2F;&#x2F;| or -&gt; 1, [get -&gt; 1, grand, -&gt; 1, did!&#39; -&gt; 1, medium -&gt; 3, asking! -&gt; 1, gay &#x2F;&#x2F;| -&gt; 1, bawled -&gt; 1, advance -&gt; 2, `YOU&#39;D -&gt; 1, THAT -&gt; 6, Free -&gt; 1, thunders &#x2F;&#x2F;| torm. -&gt; 1, mustard-mine &#x2F;&#x2F;| Output exceeds cutoff limit. val countMap2 = wordCountWithImmutableMap(filename) &#x2F;&#x2F;&gt; countMap2 : scala.collection.immutable.Map[String,Int] = Map(herself. -&gt; 8, &#x2F;&#x2F;| Hatter -&gt; 24, sneezed -&gt; 1, forgotten -&gt; 6, of. -&gt; 1, Rabbit-Hole -&gt; 1, rat &#x2F;&#x2F;| e -&gt; 4, pepper -&gt; 5, submitted -&gt; 1, NOT!&#39; -&gt; 1, `Fifteenth,&#39; -&gt; 1, like!&#39; - &#x2F;&#x2F;| &gt; 1, remarked -&gt; 1, lost: -&gt; 1, croquet.&#39; -&gt; 2, est -&gt; 1, room!&#39; -&gt; 2, sighi &#x2F;&#x2F;| ng. -&gt; 1, Bill!&#39; -&gt; 1, prizes.&#39; -&gt; 1, (a -&gt; 1, accident -&gt; 1, Cat,&#39; -&gt; 1, be &#x2F;&#x2F;| !&#39; -&gt; 1, camomile -&gt; 1, ftp -&gt; 2, bats, -&gt; 1, conversations -&gt; 1, Down, -&gt; 2 &#x2F;&#x2F;| , `Why -&gt; 7, way? -&gt; 1, cakes,&#39; -&gt; 1, `Nonsense!&#39; -&gt; 1, used -&gt; 14, eye -&gt; 4 &#x2F;&#x2F;| , whisper.) -&gt; 1, PUNITIVE -&gt; 1, Owl -&gt; 2, pleased. -&gt; 1, up.&#39; -&gt; 2, then?&#39; &#x2F;&#x2F;| -&gt; 1, `Keep -&gt; 1, instance, -&gt; 4, READ -&gt; 1, `Dear, -&gt; 1, $4 -&gt; 1, IN -&gt; 2, &#x2F;&#x2F;| way?&#39;, -&gt; 1, II -&gt; 1, Still -&gt; 1, conversion -&gt; 1, Please -&gt; 2, At -&gt; 8, dee &#x2F;&#x2F;| ply. -&gt; 1, &quot;Let -&gt; 1, shelves -&gt; 1, locked; -&gt; 1, beautiful -&gt; 8, mustard-mi &#x2F;&#x2F;| ne -&gt; 1, leaders, -&gt; 1, `Don&#39;t -&gt; 4, does. -&gt; 1, timidly -&gt; 2, altogether -&gt; &#x2F;&#x2F;| 1, writing -&gt; 4, Duches &#x2F;&#x2F;| Output exceeds cutoff limit. Lab 3.3 Grouping 문자열 배열에서 길이가 같은 문자열끼리 묶는 코드 작성하기 val words = Array(&quot;Mary&quot;, &quot;had&quot;, &quot;a&quot;, &quot;little&quot;, &quot;lamb&quot;, &quot;its&quot;, &quot;fleece&quot;, &quot;was&quot;, &quot;white&quot;, &quot;as&quot;, &quot;snow&quot;, &quot;and&quot;, &quot;everywhere&quot;, &quot;that&quot;, &quot;Mary&quot;, &quot;went&quot;, &quot;the&quot;, &quot;lamb&quot;, &quot;was&quot;, &quot;sure&quot;, &quot;to&quot;, &quot;go&quot;) &#x2F;&#x2F;&gt; words : Array[String] = Array(Mary, had, a, little, lamb, its, fleece, was, &#x2F;&#x2F;| white, as, snow, and, everywhere, that, Mary, went, the, lamb, was, sure, t &#x2F;&#x2F;| o, go) words.groupBy(_.length()) &#x2F;&#x2F;&gt; res0: scala.collection.immutable.Map[Int,Array[String]] = Map(5 -&gt; Array(whi &#x2F;&#x2F;| te), 10 -&gt; Array(everywhere), 1 -&gt; Array(a), 6 -&gt; Array(little, fleece), 2 - &#x2F;&#x2F;| &gt; Array(as, to, go), 3 -&gt; Array(had, its, was, and, the, was), 4 -&gt; Array(Ma &#x2F;&#x2F;| ry, lamb, snow, that, Mary, went, lamb, sure)) Lab 3.4 Partitions and Zips Lab 3.1 문제를 Array의 partition 메소드를 사용해서 풀기 &quot;New York&quot;.partition(_.isUpper) &#x2F;&#x2F;&gt; res0: (String, String) = (NY,ew ork) val symbols = Array(&quot;&lt;&quot;, &quot;-&quot;, &quot;&gt;&quot;) &#x2F;&#x2F;&gt; symbols : Array[String] = Array(&lt;, -, &gt;) val counts = Array(2, 10, 2) &#x2F;&#x2F;&gt; counts : Array[Int] = Array(2, 10, 2) val pairs = symbols.zip(counts) &#x2F;&#x2F;&gt; pairs : Array[(String, Int)] = Array((&lt;,2), (-,10), (&gt;,2)) import scala.collection.mutable.ArrayBuffer val myArray = ArrayBuffer(3,6,7,3,-4,8,-3,-5,6,7,-2,9,-1) &#x2F;&#x2F;&gt; myArray : scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer(3, 6, 7, &#x2F;&#x2F;| 3, -4, 8, -3, -5, 6, 7, -2, 9, -1) val (positiveArray, negativeArray) = myArray.partition(_ &gt; 0) &#x2F;&#x2F;&gt; positiveArray : scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer(3, &#x2F;&#x2F;| 6, 7, 3, 8, 6, 7, 9) &#x2F;&#x2F;| negativeArray : scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer(-4, &#x2F;&#x2F;| -3, -5, -2, -1) val answer = positiveArray &#x2F;&#x2F;&gt; answer : scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer(3, 6, 7, 3 &#x2F;&#x2F;| , 8, 6, 7, 9) answer += negativeArray(0) &#x2F;&#x2F;&gt; res1: Lesson9.answer.type = ArrayBuffer(3, 6, 7, 3, 8, 6, 7, 9, -4) 7. Class, Object, Companion Object Class의 멤버 변수를 val로 선언하면 immutable, var로 선언하면 mutable val or var로 했느냐에 따라 getter, setter를 쓸 수 있음 class myString(val jString: String) { private var extraData = &quot;&quot; override def toString = f&quot;${jString}${extraData}&quot; } object myString { def apply(base: String, extras: String) = { val s = new myString(base) s.extraData = extras s } def apply(base: String) = new myString(base) } println(myString(&quot;hello&quot;, &quot;world&quot;)) &#x2F;&#x2F;&gt; helloworld println(myString(&quot;Goodbye&quot;)) &#x2F;&#x2F;&gt; Goodbye class Pizza(var crustSize: Int, var crustType: String) { def this(crustSize: Int) { this(crustSize, Pizza.DEFAULT_CRUST_TYPE) } def this(crustType: String) { this(Pizza.DEFAULT_CRUST_SIZE, crustType) } def this() { this(Pizza.DEFAULT_CRUST_SIZE, Pizza.DEFAULT_CRUST_TYPE) } override def toString = s&quot;A $crustSize inch pizza with a $crustType crust&quot; } object Pizza { val DEFAULT_CRUST_SIZE = 12 val DEFAULT_CRUST_TYPE = &quot;THIN&quot; } val pz1 = new Pizza(14, &quot;THICK&quot;) &#x2F;&#x2F;&gt; pz1 : Lesson10.Pizza = A 14 inch pizza with a THICK crust val pz2 = new Pizza(16) &#x2F;&#x2F;&gt; pz2 : Lesson10.Pizza = A 16 inch pizza with a THIN crust object Accounts { private var lastNumber = 0 def newUniqueNumber() = { lastNumber += 1 lastNumber } } Accounts &#x2F;&#x2F;&gt; res0: Lesson10.Accounts.type = Lesson10$$anonfun$main$1$Accounts$2$@68837a7 &#x2F;&#x2F;| 7 Accounts.newUniqueNumber() &#x2F;&#x2F;&gt; res1: Int = 1 Accounts.newUniqueNumber() &#x2F;&#x2F;&gt; res2: Int = 2 Accounts.newUniqueNumber() &#x2F;&#x2F;&gt; res3: Int = 3 Accounts.newUniqueNumber() &#x2F;&#x2F;&gt; res4: Int = 4 Accounts.newUniqueNumber() &#x2F;&#x2F;&gt; res5: Int = 5 Scala App 만들기 object HelloWorld extends App { println(&quot;Hello, world!&quot;) } Uniform Access Method 클래스에 멤버변수로 선언했지만 해당 멤버 변수와 동일한 메소드를 선언했을 경우 해당 메소드가 호출됨 class Point(...) { private val r = ... private val theta = ... def x = r * cos(theta) &#x2F;&#x2F; 여기서 x를 유니폼 엑세스 메소드 라고 부르며, 이 메소드는 인자가 없다. } scala에서 object 키워드가 붙은 코드는 싱글톤 객체를 말하며, 멤버 메소드는 static method이다. Companion Object란 class와 object의 이름이 같은 것을 말하며, 서로간에 private feature에 접근이 가능하다. apply 메소드를 Companion Object에 선언하기도 한다. Lab 4.1 Time 시간을 나타내는 클래스 작성하기 class Time(val hours: Int = 0, var minutes: Int = 0) { if (hours &lt; 0 || hours &gt;= 24 || minutes &lt; 0 || minutes &gt;= 60) { throw new IllegalArgumentException(&quot;hour or minute format incorrect&quot;) } def before(other: Time): Boolean = { val thisTimeMinutes = this.toMinutes() val otherTimeMinutes = other.toMinutes() thisTimeMinutes &lt; otherTimeMinutes } override def toString = f&quot;${hours}:${minutes}&quot; def toMinutes(): Int = this.hours * Time.ONE_HOUR_MINUTES + this.minutes } object Time { val ONE_HOUR_MINUTES = 60 def apply(hours: Int, minutes: Int) = new Time(hours, minutes) def apply(hours: Int) = new Time(hours) def apply(hours: Unit, minutes: Int) = new Time(0, minutes) } println(Time(12)) println(Time(11, 24).before(Time(16, 11))) val t1 = Time(12, 30) t1.minutes = -100 Lab 4.2 Uniform Access 시간 클래스의 멤버를 val로 선언한 뒤 해당 멤버 변수는 uniform access method로 접근하기 (class의 멤버 변수에 아무것도 안쓰면 자동으로 val로 선언됨) 이렇게 하면 getter 메소드를 정의한 것과 비슷한 효과를 볼 수 있다. 아래 코드와 같이 멤버 변수 uniform access method를 통해 값을 변경하는 것은 컴파일 오류가 발생한다. class Time2(h: Int, m: Int) { private val minutesSinceMidnight = h * 60 + m def hours = minutesSinceMidnight &#x2F; 60 def minutes = minutesSinceMidnight % 60 } object Time2 { } val t2 = new Time2(12, 45) &#x2F;&#x2F;&gt; t2 : Lesson12.Time2 = Lesson12$Time2@61e4705b &#x2F;&#x2F; t2.minutes = 100 t2.hours &#x2F;&#x2F;&gt; res0: Int = 12 t2.minutes &#x2F;&#x2F;&gt; res1: Int = 45 Lab 4.3 Uniform Access (con’t) 위 문제에서 uniform access method를 통해서 setter 구현해보기 아래 코드를 보면 메소드명 바로 뒤에 ‘_=’가 붙는 것을 볼 수가 있는데 이것은 ‘변수명 =’과 같은 효과를 발휘한다. 또한 setter uniform access method를 구현하려면 앞에서 작성했던 getter에 해당하는 uniform access method가 먼저 선언되어 있어야 한다. class Time3(h: Int, m: Int) { private var minutesSinceMidnight = h * 60 + m def hours = minutesSinceMidnight &#x2F; 60 def minutes = minutesSinceMidnight % 60 def hours_=(newHours: Int) { if (newHours &lt; 0 || newHours &gt;= 24) { throw new IllegalArgumentException(&quot;hours is invalid&quot;) } this.minutesSinceMidnight = newHours * 60 + this.minutes } def minutes_=(newMinutes: Int) { if (newMinutes &lt; 0 || newMinutes &gt;= 60) { throw new IllegalArgumentException(&quot;minutes is invalid&quot;) } this.minutesSinceMidnight = this.hours * 60 + newMinutes } } val t3 = new Time3(12, 45) t3.hours = 19 t3.minutes = 13 t3.hours t3.minutes Lab 4.4 Operatorsobject Time4 { def apply(hours: Int = 0, minutes: Int = 0) = new Time4(hours, minutes) } class Time4(h: Int = 0, m: Int = 0) { private var minutesSinceMidnight = h * 60 + m if (h &lt; 0 || h &gt; 23) throw new IllegalArgumentException(&quot;hours is invalid&quot;) if (m &lt; 0 || m &gt; 60) throw new IllegalArgumentException(&quot;minutes is invalid&quot;) def hours = this.minutesSinceMidnight &#x2F; 60 def minutes = this.minutesSinceMidnight % 60 def hours_=(newHours: Int) { if (newHours &lt; 0 || newHours &gt; 23) throw new IllegalArgumentException(&quot;hours is invalid&quot;) else this.minutesSinceMidnight = newHours * 60 + this.minutes } def minutes_=(newMinutes: Int) { if (newMinutes &lt; 0 || newMinutes &gt; 59) throw new IllegalArgumentException(&quot;minutes is invalid&quot;) else this.minutesSinceMidnight = this.hours * 60 + newMinutes } def &lt;(other: Time4): Boolean = this.minutesSinceMidnight &lt; other.minutesSinceMidnight override def toString() = f&quot;${this.hours}:${this.minutes}&quot; } val t4 = new Time4(12, 45) &#x2F;&#x2F;&gt; t4 : Lesson14.Time4 = 12:45 t4.hours = 17 t4.minutes = 23 t4 &#x2F;&#x2F;&gt; res0: Lesson14.Time4 = 17:23 t4.hours &#x2F;&#x2F;&gt; res1: Int = 17 t4.minutes &#x2F;&#x2F;&gt; res2: Int = 23 println(Time4(11, 24) &lt; Time4(16, 11)) &#x2F;&#x2F;&gt; true 9. Functional Programming9.1 Function Functions as value Anonymous Functions Functions with Function Parameters Functions that Produce Functions Parameter Inference Map, Filter, Reduce 9.2 Closures 양자가 얽힌 것 처럼 함수도 얽힐 수 있다. 클로저를 사용하면 함수가 필요한 정보를 어딘가에서 정의해서 받아 사용할 수 있다. package otherscope { class Foo { def exec(f: (String) =&gt; Unit, name: String) = { f(name) } } } object HelloWorld extends App { var hello = &quot;Hello&quot; def sayHello(name: String) = { println(s&quot;$hello, $name&quot;) } val foo = new otherscope.Foo() foo.exec(sayHello, &quot;Lee&quot;) hello = &quot;안녕하세요&quot; foo.exec(sayHello, &quot;Lee&quot;) } 위 코드를 보면 hello라는 변수가 다른 스코프에서 실행되더라도 hello 값을 참조하여 쓰고 있다. (런타임 시 클로저 변수가 참조됨) 9.3 Currying 함수의 반환값이 함수일 때 해당 함수 호출의 호출을 바로 하는 것def mul(x: Int, y: Int) = x * y &#x2F;&#x2F;&gt; mul: (x: Int, y: Int)Int def mulOneAtATime(x: Int) = (y: Int) =&gt; x * y &#x2F;&#x2F;&gt; mulOneAtATime: (x: Int)Int =&gt; Int &#x2F;&#x2F;def mulOneAtATime(x: Int)(y: Int) = x * y mulOneAtATime(10)(20) &#x2F;&#x2F;&gt; res0: Int = 200 10. Pattern Matching var.isInstanceOf[Type] 보단 패턴 매칭이 더 best! 주의: case의 변수명을 안쓰면 companion object를 지정하는 것처럼 보일 수 있음 val ch = &#39;-&#39; &#x2F;&#x2F;&gt; ch : Char = - val sign = ch match { case &#39;+&#39; =&gt; 1 case &#39;-&#39; =&gt; -1 case _ =&gt; 0 } &#x2F;&#x2F;&gt; sign : Int = -1 val pair = (0, 1) &#x2F;&#x2F;&gt; pair : (Int, Int) = (0,1) val st = pair match { case (0, _) =&gt; &quot;0 ...&quot; case (y, 0) =&gt; y + &quot;0&quot; case _ =&gt; &quot;neither is 0&quot; } &#x2F;&#x2F;&gt; st : String = 0 ... val arr = Array(9, 1, 1) &#x2F;&#x2F;&gt; arr : Array[Int] = Array(9, 1, 1) val out = arr match { case Array(0) =&gt; &quot;0&quot; case Array(x, y) =&gt; x + &quot; &quot; + y case Array(0, _*) =&gt; &quot;0 ...&quot; case _ =&gt; &quot;something else&quot; } &#x2F;&#x2F;&gt; out : String = something else 11. Case Class case class는 패턴매칭에 유용하게 쓰임 case class는 자동으로 companion object가 만들어지며, 멤버 변수들은 자동으로 val로 선언됨","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"http://icednut.github.io/tags/scala/"}]},{"title":"Spring Transaction의 이해 Part1 - Trasaction AOP 설정과 Java Configuration","slug":"20170220-spring-transaction-part1-overview","date":"2017-02-19T16:54:01.000Z","updated":"2018-11-27T06:40:43.289Z","comments":true,"path":"2017/02/20/20170220-spring-transaction-part1-overview/","link":"","permalink":"http://icednut.github.io/2017/02/20/20170220-spring-transaction-part1-overview/","excerpt":"","text":"얼마전에 스프링 관련 커뮤니티에서 Spring에서 XML로 설정된 Transaction Advice에 대해서 Java Configuration 방식으로 어떻게 바꾸는지 질문이 올라왔었다. 댓글을 보고 좀 더 구체적으로 알아보고 싶다는 욕심이 생겨서 해결방법을 찾아보기 시작했다. 구글이나 스택오버플로우에서 찾아보니 딱히 만족스러운 방법이 없었으나 스프링 레퍼런스에서 힌트를 찾을 수 있었다. 17.5.9 Using @Transactional with AspectJ (중략) To weave your applications with the AnnotationTransactionAspect you must either build your application with AspectJ (see the AspectJ Development Guide) or use load-time weaving. See Section 11.8.4, “Load-time weaving with AspectJ in the Spring Framework” for a discussion of load-time weaving with AspectJ. 출처: http://docs.spring.io/spring-framework/docs/current/spring-framework-reference/html/transaction.html#transaction-declarative-aspectj 결국 AspectJ를 Java config로 활성화 및 관련 PointCut 설정을 하고 Trasaction Advice를 사용자가 선언한 뒤 TransactionInterceptor에 사용자가 선언한 TxAdvice를 인식할 수 있는 인프라 빈을 주입하면 될 것 같다는 생각이 드는데, 막상 해보려고 하니 또 막막했다.","categories":[],"tags":[{"name":"spring","slug":"spring","permalink":"http://icednut.github.io/tags/spring/"},{"name":"transaction","slug":"transaction","permalink":"http://icednut.github.io/tags/transaction/"}]},{"title":"수식 쓰기 연습","slug":"20170209-math-test","date":"2017-02-08T15:14:59.000Z","updated":"2018-11-27T06:40:43.284Z","comments":true,"path":"2017/02/09/20170209-math-test/","link":"","permalink":"http://icednut.github.io/2017/02/09/20170209-math-test/","excerpt":"","text":"When a&#x2260;0 , there are two solutions to ax2 + bx + c = 0 and they are x = &#x2212; b &#x00B1; b2 &#x2212; 4ac 2a .","categories":[],"tags":[{"name":"수학","slug":"수학","permalink":"http://icednut.github.io/tags/수학/"}]},{"title":"Machine Learning Study 01 - 머신러닝의 정의 및 기초 용어 정리","slug":"20170201-machine_learning_study_day01","date":"2017-01-31T15:00:00.000Z","updated":"2018-11-27T06:40:43.297Z","comments":true,"path":"2017/02/01/20170201-machine_learning_study_day01/","link":"","permalink":"http://icednut.github.io/2017/02/01/20170201-machine_learning_study_day01/","excerpt":"","text":"머신러닝(Machine Learning)의 정의 및 용어 정리Tom Mitchell는 자신의 저서 머신러닝에서 러닝, 즉 학습의 정의를 다음과 같이 내렸다. 만약 컴퓨터 프로그램이 특정한 태스크 T를 수행할 때 성능 P만큼 개선되는 경험 E를 보이면 그 컴퓨터 프로그램은 태스크 T와 성능 P에 대해 경험 E를 학습했다라고 할 수 있다. example)컴퓨터에게 필기체를 인식하는 학습을 시킨다고 했을 때 태스크 T: 필기체를 인식하고 분류하는 것 성능 P: 필기체를 정확히 구분한 확률 학습 경험 E: 필기체와 정확한 글자를 표시한 데이터세트로 정의할 수 있다. Vector 머신(컴퓨터)가 학습하기 위해서는, 다시 말해 컴퓨터가 어떤 판단 규칙 만들기 위해서는 사람이 인지하는 데이터를 컴퓨터가 인지하기 위해 데이터의 사전 처리가 필요하다. 예를 들면, 텍스트로 된 사용자 행동로그 데이터 테이블, 자연어로 구성된 문장, 음성신호, 디지털 이미지, 동영상 등의 데이터는 계산 가능한 정량적인 단위로 변환 및 벡터나 행렬 형태로 가공이 필요하다. 입력 데이터를 벡터 형태로 표현하는 이유는 입력 데이터가 n개의 특성으로 정량화 됐다면 n차원 벡터 공간에 표현할 수 있어 데이터를 직관적으로 이해하고 수학적인 분류 모델을 만들기 쉽기 때문 머신러닝과 데이터 마이닝 머신러닝에서 사용하는 분류나 군집 같은 방법을 데이터 마이닝에서도 사용함 분류나 예측, 군집과 같은 기술, 모델, 알고리즘을 이용해 문제를 해결하는 것을 컴퓨터 과학 관점에서는 머신러닝이라고 하고, 통계학 관점에서는 데이터 마이닝이라고 한다. 머신러닝과 데이터 마이닝의 차이점을 굳이 설명하자면 데이터 마이닝은 가지고 있는 데이터에서 현상 및 특성을 발견하는 것이 목적, 반면 머신러닝은 기존 데이터를 통해 학습을 시킨 후 새로운 데이터에 대한 예측값을 알아내는 데 목적이 있다라고 할 수 있다. 용어 정리레이블(Label) 학습 데이터의 속성을 우리가 분석하고자 하는 관점에서 정의하는 것 예를 들어 사진에서 어떤 사물을 구별하는 태스크 T가 있다고 할 때 사진은 학습 데이터, 사진 속에 있는 사물 ‘컵’, ‘책상’, ‘자전거’, ‘고양이’라고 미리 정의해 놓는 것을 레이블이라고 한다. 지도(Supervised) 학습 &amp; 비지도(Unsupervised) 학습 레이블은 사람이 사진을 보고 정의한 것이기 때문에 그러한 레이블된 사진을 읽어서 학습하는 컴퓨터 입장에서는 사람으로부터 지도를 받는 것이라 하여 지도 학습 입력 데이터에 레이블이 없다면 컴퓨터가 사람으로부터 지도를 받은 것이 없기 때문에 비지도 학습이라 한다. 지도학습의 종류: 분류 모델(Classification), 예측 모델(Prediction) 비지도 학습의 종류: 군집 모델(Clustering) 분류 모델 (Classification) kNN (k nearest neighbor) 서포트 벡터 머신 (Support Vector Machine) 의사결정 트리 (Decision Tree) 분류 모델의 예를 들면, A,B,C 레이블로 구성된 데이터세트가 있다고 하면 분류모델의 결괏값은 A,B,C 셋 중에 하나가 나온다. 예측 모델 (Regression) 회귀(Regression)가 주된 방식이라 예측 모델은 회귀 모델이라고 하기도 함 회귀 모델은 레이블된 학습 데이터를 가지고 특성(Feature)과 레이블의 관계를 함수식으로 표현하는 것이 목적 회귀 모델은 A,B,C와 같이 유한 개의 결괏값이 나오지 않고 어떤 값이 나올지 예상하지 못하기 때문에 예측 모델이라고 한다. 주가 분석과 같이 연속적인 범위 내에 결괏값을 예측하는 문제에는 선형 회귀 모델(Linear Regression)을 사용 회귀 모델도 분류와 같이 몇 가지 범주형(Categorical) 결괏값을 예측하는 경우에는 로지스틱 회귀 모델(Logistic Regression)을 사용 Logistic Regression에서는 회귀 분석 시 로지스틱 함수 혹은 시그모이드 sigmoid 함수를 사용 특성(Feature) 입력 데이터(ex: 사용자 로그, 음성, 이미지 등)를 구별해낼 수 있는 특징들을 정량화한 것 통계학에서는 ‘설명변수’, ‘독립변수’, ‘예측변수’로 표현한다. 적절한 특성의 선정이 효과적인 머신러닝을 만드는데 중요함 상관 분석 (Correlation) 독립변수와 종속변수 간의 관계의 강도, 정도를 분석하는 것 (즉, 얼마만큼 밀접하게 관련되어 있는지 분석) 이 때 강도를 상관계수(r)라 부른다. 상관계수(r): 독립변수와 종속변수의 관계 정도를 -1과 1사이로 정량화한 것 회귀 분석 (Regression) 관측된 사건들을 정량화해서 여러 독립변수와 종속변수(목적변수라고도 함)의 관계를 함수식으로 설명하는 방법 종속변수: 우리가 알고 싶어하는 결괏값, 기댓값, 예상값 독립변수: 이러한 결괏값에 영향을 주는 입력값 예를 들어, 어떤 고등학교에 있는 학생들의 키와 몸무게의 상관관계를 기반으로 학생의 키가 주어졌을 때 그 학생의 몸무게를 예측할 때 키는 독립변수, 몸무게는 종속변수이다. 이 때 그 상관관계를 함수식으로 규명하는 것이 회귀 분석이며 이를 함수식으로 나타내면 다음과 같다. y = -141.24 + 1.185x, 결정계수(r^2) = 0.9331 결정계수(r^2): 독립변수를 가지고 얼마만큼 의미 있게 종속변수를 예측할 수 있는지를 판별할 때 사용. 일반적으로 r^2 &gt;= 0.65 이면 의미있는 회귀식이라 말한다. 선형 회귀 (Linear Regression) 선형: 독립변수가 1차항으로 돼 있다는 의미. 이를 기하학적으로 표현하면 독립변수와 종속변수의 관계가 2차원에서는 직선형태로, 3차원에서는 평면으로 나타난다. 선형회귀식을 구할 때는 일반적으로 최소제곱법을 이용 최소제곱법: 독립변수를 통해 임의의 함수로 예측한 결괏값과 실제 종속변수값의 차이(오차error, 잔차residual 라고도 함)를 제곱해서 모두 더한 값이 최소가 되는 함수식을 찾는 방법 로지스틱 회귀 (Logistic Regression) 종속변수가 예/아니오, 1/0, 클릭/넌클릭 같은 범주형(categorical)으로 표현될 때","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://icednut.github.io/tags/Machine-Learning/"}]},{"title":"머신러닝 소개 자료","slug":"20170120-introduce_machine_learning","date":"2017-01-19T15:00:00.000Z","updated":"2018-11-27T06:40:43.288Z","comments":true,"path":"2017/01/20/20170120-introduce_machine_learning/","link":"","permalink":"http://icednut.github.io/2017/01/20/20170120-introduce_machine_learning/","excerpt":"","text":"머신러닝 입문 강의 (생초보용) https://www.youtube.com/watch?v=j3za7nv7RfI Decision Tree의사결정트리 맛보기 (디시젼 트리가 뭐다 라고 설명한 뒤 나중에 파이썬으로 구현하는 것까지 보여줌) 1화: https://www.youtube.com/watch?v=n0p0120Gxqk 2화: https://www.youtube.com/watch?v=UPKugq0fK04 3화: https://www.youtube.com/watch?v=GE2P2DlIj9k Gradient Boosting Machine 소개 (with XGBoost) http://ishuca.tistory.com/entry/Introduction-to-Boosted-Trees 원문 링크: http://xgboost.readthedocs.io/en/latest/model.html Logistic Regression로지스틱 회귀 분석 맛보기 로지스틱 회귀 분석 개요: https://www.youtube.com/watch?v=kHLqMsN7yao 코스트 함수 &amp; Weight 구하기 설명: https://www.youtube.com/watch?v=XvB5u7YSeUk 더욱더 까다로운 알고리즘이 필요한 응용 프로그램이 요구될 때, 논문을 읽고, 좋은 생각을 끄집어내며, 실제 코드에서 프로그램을 실행하고, 이러한 작업을 반복할 수 있는 누군가가 옆에 있다면 유용할 것이다.","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://icednut.github.io/tags/Machine-Learning/"}]},{"title":"Java Generics","slug":"20161215-java_generics","date":"2016-12-14T15:00:00.000Z","updated":"2018-11-27T06:40:43.290Z","comments":true,"path":"2016/12/15/20161215-java_generics/","link":"","permalink":"http://icednut.github.io/2016/12/15/20161215-java_generics/","excerpt":"","text":"Type Parameter와 Type Argumentpublic class Generics { static class Hello&lt;T&gt; { // 여기서 T를 Type Variable 이라고도 한다. T is type parameter } static void print(String value) { System.out.println(value); } public static void main(String[] args) { new Hello&lt;String&gt;(); // type argument } } Intersection Typepublic class Generics { static &lt;T extends List &amp; Serializable &amp; Comparable &amp; Closeable&gt; void print(T t) { } public static void main(String[] args) { } } Bounded Type Parameterpublic class Generics { static long countGreaterThan(Integer[] arr, Integer elem) { return Arrays.stream(arr).filter(s -&gt; s &gt; elem).count(); } public static void main(String[] args) { Integer[] arr = new Integer[] {1,2,3,4,5,6,7}; System.out.println(countGreaterThan(arr, 4)); } } 스트링 용의 countGreaterThan을 만들고 싶을 땐?더 나아가서 일반적으로 만들고 싶을 때는? public class Generics { static &lt;T extends Comparable&lt;T&gt;&gt; long countGreaterThan(T[] arr, T elem) { return Arrays.stream(arr).filter(s -&gt; s.compareTo(elem) &lt; 0).count(); // s 에서는 erase type이라고 해서 정보를 다 날린다. } public static void main(String[] args) { String[] arr = new String[] {&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;}; System.out.println(countGreaterThan(arr, &quot;c&quot;)); } } 제네릭과 상속public class Generics { public static void main(String[] args) { Integer i = 10; Number n = i; // 가능 List&lt;Integer&gt; ints = new ArrayList&lt;&gt;(); List&lt;Number&gt; numbers = ints; // 1. compile error, 2. runtime error, 3. ... // Type parameter 사이에는 상속 관계를 컴파일 타임에 체크할 수 없다. 제네릭에는 상속관계에 영향을 줄 수 없다. ArrayList&lt;Integer&gt; arrs = new ArrayLIst&lt;&gt;(); Lister&lt;Integer&gt; ints2 = arrs; // 잘 됨 } } public class Generics { static class MyList&lt;E, P&gt; implements List&lt;E&gt; {...} public static void main(String[] args) { List&lt;String&gt; s1 = new MyList&lt;String, Integer&gt;(); List&lt;String&gt; s2 = new MyList&lt;String, String&gt;(); // 둘 다 컴파일 오류 없이 잘 됨 } } 타입 추론컴파일러가 추론해주는 일 public class Generics { static &lt;T&gt; void method(T t, List&lt;T&gt; list) {...} public static void main(String[] args) { method(1, Arrays.asList(1,2,3)); // 타입을 명시하지 않아도 메소드의 파라미터로 넘겨주는 로직이 컴파일 타임에 Integer로 추론되서 컴파일 된다. Generics.&lt;Integer&gt;method(1, Arrays.asList(1,2,3)); } } 빈 컬랙션이 타입 추론List c = Collections.emptyList(); static &lt;T extends Comparable&gt; void method(List&lt;T&gt; t) { } static void method(List&lt;? extends Comparable&gt; t) { // ? is wildcards } Wild CardList&lt;? extends Object&gt; list; 오브젝트의 기능이 담긴 타입의 객체를 사용하겠다는 의미 타입이 뭐가 있던지 간에 리스트의 기능에 집중하겠다는 의미 static void printList1(List&lt;Object&gt; list) { list.forEach(s -&gt; System.out.println(s)); } static void printList2(List&lt;?&gt; list) { list.forEach(s -&gt; System.out.println(s)); } 위 두 메소드의 차이점은 뭘까?printList1(Arrays.asList(1,2,3));printList2(Arrays.asList(1,2,3));둘 다 오류는 안남 그런데…List list = Arrays.asList(1,2,3);printList1(list); // 이 때는 컴파일 오류가 발생함. List는 List의 서브타입이 아니기 때문에..printList2(list); // 이거는 문제 없음 class A {} class B extends A {} List&lt;B&gt; lb = new ArrayList&lt;B&gt;(); List&lt;A&gt; la = lb; // 이거는 컴파일 오류가 발생함, List&lt;B&gt;는 List&lt;A&gt;의 서브타입이 아니기 떄문 List&lt;? extends A&gt; la = lb; // 이거는 가능 List&lt;? super A&gt; lc = lb; // 이거도 가능 List&lt;? super B&gt; ld = lb; // 이거는 불가 la.add(new A()); // 이거도 컴파일 오류 la.add(new B()); // 이거도 컴파일 오류 la.add(null); // 이거밖에 안됨","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://icednut.github.io/tags/java/"},{"name":"generics","slug":"generics","permalink":"http://icednut.github.io/tags/generics/"}]},{"title":"Angular 2 - 사례로 살펴보는 @Input과 @Output의 이해 2","slug":"20161209-about_angular2_input_output2","date":"2016-12-08T15:00:00.000Z","updated":"2018-11-27T06:40:43.285Z","comments":true,"path":"2016/12/09/20161209-about_angular2_input_output2/","link":"","permalink":"http://icednut.github.io/2016/12/09/20161209-about_angular2_input_output2/","excerpt":"","text":"문제. ├── first-tab │ ├── first-tab.component.css │ ├── first-tab.component.html │ └── first-tab.component.ts ├── second-tab │ ├── second-tab.component.css │ ├── second-tab.component.html │ └── second-tab.component.ts ├── tab-menu.component.css ├── tab-menu.component.html └── tab-menu.component.ts 스크린샷에 보이는 것 처럼 한 페이지에 Tab으로 구분된 Form이 구성되어 있다. 제출하기 버튼 클릭했을 때 모든 탭의 Form 데이터를 얻어오려면 어떻게 해야될까? 풀이 위 상황만 따지고 볼 때 핵심은 제출하기 버튼 클릭 시 모든 탭에 있는 Form 데이터를 가져오도록 코드를 작성하면 될 것 같다. 아래와 같이 Tab들은 자식 컴포넌트로 구성이 될텐데 부모 컴포넌트에서 자식 컴포넌트의 Form 데이터는 어떻게 가져올 것인가? &lt;div&gt; &lt;tabset class=&quot;container&quot;&gt; &lt;tab heading=&quot;1단계&quot;&gt; &lt;first-tab&gt;&lt;&#x2F;first-tab&gt; &lt;&#x2F;tab&gt; &lt;tab heading=&quot;2단계&quot;&gt; &lt;second-tab&gt;&lt;&#x2F;second-tab&gt; &lt;&#x2F;tab&gt; &lt;&#x2F;tabset&gt; &lt;&#x2F;div&gt; 문제의 핵심은 부모 컴포넌트(tab-menu.component)에서 자식 컴포넌트(first-tab.component &amp; second-tab.component)의 값을 언제 어떻게 가져올 것인가로 압축할 수 있다. 부모 컴포넌트에서 자식 컴포넌트의 값을 가져오는 방법 2가지 방법 1. 모델 공유 방법 2. 클로저 이벤트 사용 일단 위 2가지 방법이 그나마 효율적인 방법이라고 생각한다. (위 2가지 방법 말고도 다른 방법이 있겠지만…) 먼저 첫 번째 방법 부터 살펴보자. 방법 1. 모델 공유 - 부모 컴포넌트에 자식 컴포넌트들의 Form 모델을 선언하는 방법말 그대로 부모 컴포넌트에서 자식 컴포넌트들의 Form 데이터가 담긴 모델을 갖고 있도록 정의하는 방법이다. 코드로 살펴보면 다음과 같다. 1) 부모 컴포넌트(tab-menu.component.ts)에서 자식 컴포넌트의 데이터를 받을 모델 멤버변수를 선언한다. 여기서 firstTabForm과 secondTabForm에 대한 부모컴포넌트의 멤버 필드를 선언하고 인스턴스화 한다. 이렇게 인스턴스화 된 멤버들을 자식들에게 공유하는 방식이다. import { Component, OnInit } from &#39;@angular&#x2F;core&#39;; import { FirstTabForm } from &#39;.&#x2F;firstTabForm&#39;; import { SecondTabForm } from &#39;.&#x2F;secondTabForm&#39;; @Component({ selector: &#39;tab-menu&#39;, templateUrl: &#39;.&#x2F;tab-menu.component.html&#39;, styleUrls: [&#39;.&#x2F;tab-menu.component.css&#39;] }) export class TabMenuComponent implements OnInit { firstTabForm: FirstTabForm = new FirstTabForm(); secondTabForm: SecondTabForm = new SecondTabForm(); ngOnInit() { } } 2) 부모 컴포넌트의 멤버 변수를 자식 컴포넌트로 전달한다. 전달할 때는 아래와 같이 자식 컴포넌트의 @Input 멤버 필드에 전달한다. &lt;div&gt; &lt;tabset class=&quot;container&quot;&gt; &lt;tab heading=&quot;1단계&quot;&gt; &lt;first-tab [childForm]=&quot;firstTabForm&quot;&gt;&lt;&#x2F;first-tab&gt; &lt;&#x2F;tab&gt; &lt;tab heading=&quot;2단계&quot;&gt; &lt;second-tab [childForm]=&quot;secondTabForm&quot;&gt;&lt;&#x2F;second-tab&gt; &lt;&#x2F;tab&gt; &lt;&#x2F;tabset&gt; &lt;&#x2F;div&gt; import { Component, OnInit, Input } from &#39;@angular&#x2F;core&#39;; import { FirstTabForm } from &#39;..&#x2F;firstTabForm&#39;; @Component({ selector: &#39;first-tab&#39;, templateUrl: &#39;.&#x2F;first-tab.component.html&#39;, styleUrls: [&#39;.&#x2F;first-tab.component.css&#39;] }) export class FirstTabComponent implements OnInit { @Input() childForm: FirstTabForm; constructor() { } ngOnInit() { } } import { Component, OnInit, Input } from &#39;@angular&#x2F;core&#39;; import { SecondTabForm } from &#39;..&#x2F;secondTabForm&#39;; @Component({ selector: &#39;second-tab&#39;, templateUrl: &#39;.&#x2F;second-tab.component.html&#39;, styleUrls: [&#39;.&#x2F;second-tab.component.css&#39;] }) export class SecondTabComponent implements OnInit { @Input() childForm: SecondTabForm; constructor() { } ngOnInit() { } } 3) 자식 컴포넌트의 템플릿에 선언되어 있는 input, select 등 입출력을 담당하는 엘리먼트에 양방향 바인딩을 걸어준다. 사실 input 바인딩만 걸어줘도 되는데 추후 저장 후 수정과 같은 페이지를 만들 것을 대비하여 양방향 바인딩을 걸어준다. (이게 비효율적으로 보이면 단방향 바인딩만 해줘도 된다.) &lt;div class=&quot;form-group&quot;&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;이름(Name)&quot; [(ngModel)]=&quot;childForm.name&quot;&gt; &lt;&#x2F;div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;input type=&quot;email&quot; class=&quot;form-control&quot; placeholder=&quot;이메일(Email)&quot; [(ngModel)]=&quot;childForm.email&quot;&gt; &lt;&#x2F;div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;주소(Address)&quot; [(ngModel)]=&quot;childForm.address&quot;&gt; &lt;&#x2F;div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;personCount&quot;&gt;예약 인원&lt;&#x2F;label&gt; &lt;select class=&quot;form-control&quot; id=&quot;personCount&quot; [(ngModel)]=&quot;childForm.count&quot;&gt; &lt;option&gt;1&lt;&#x2F;option&gt; &lt;option&gt;2&lt;&#x2F;option&gt; &lt;option&gt;3&lt;&#x2F;option&gt; &lt;option&gt;4&lt;&#x2F;option&gt; &lt;option&gt;5&lt;&#x2F;option&gt; &lt;&#x2F;select&gt; &lt;&#x2F;div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;groupName&quot;&gt;모임명&lt;&#x2F;label&gt; &lt;input type=&quot;email&quot; class=&quot;form-control&quot; id=&quot;groupName&quot; [(ngModel)]=&quot;childForm.groupName&quot;&gt; &lt;&#x2F;div&gt; 4) 부모 컴포넌트로 데이터가 제대로 들어오는지 확인 부모 컴포넌트 쪽에서 데이터가 제대로 들어왔는지 디버깅을 해보자. &lt;div&gt; &lt;tabset class=&quot;container&quot;&gt; &lt;tab heading=&quot;1단계&quot;&gt; &lt;first-tab [childForm]=&quot;firstTabForm&quot;&gt;&lt;&#x2F;first-tab&gt; &lt;&#x2F;tab&gt; &lt;tab heading=&quot;2단계&quot;&gt; &lt;second-tab [childForm]=&quot;secondTabForm&quot;&gt;&lt;&#x2F;second-tab&gt; &lt;&#x2F;tab&gt; &lt;&#x2F;tabset&gt; &lt;div&gt; &lt;button class=&quot;btn btn-primary&quot; type=&quot;button&quot; style=&quot;width:140px;&quot; (click)=&quot;saveRequest()&quot;&gt;제출하기&lt;&#x2F;button&gt; &lt;button class=&quot;btn btn-info&quot; type=&quot;button&quot; style=&quot;width:140px;&quot;&gt;초기화&lt;&#x2F;button&gt; &lt;&#x2F;div&gt; &lt;&#x2F;div&gt; ... @Component({ selector: &#39;tab-menu&#39;, templateUrl: &#39;.&#x2F;tab-menu.component.html&#39;, styleUrls: [&#39;.&#x2F;tab-menu.component.css&#39;] }) export class TabMenuComponent implements OnInit { ... saveRequest() { console.log(`${this.firstTabForm.name} : ${this.firstTabForm.email} : ${this.firstTabForm.address}`); console.log(`${this.secondTabForm.count} : ${this.secondTabForm.groupName}`); } } 방법 1 전체 소스https://github.com/icednut/angular2-exercise/tree/master 2. 클로저 이벤트 사용 - 자식 컴포넌트에서 Form 데이터 셋팅 시 부모 컴포넌트에 이벤트 emit 시 Form 데이터 셋팅 클로저를 넘기는 방법부모 컴포넌트 페이지에서 제출하기버튼 클릭 시 자식 컴포넌트들에게 이벤트를 발생하는데 이 때 내보내는 이벤트 타입을 클로저로 지정하는 방법이다. 말로 들으면 이해가 안갈지도 모르는데 코드를 살펴보면 다음과 같다. 1) 제출하기 버튼 클릭 핸들러 추가&lt;div&gt; &lt;tabset class=&quot;container&quot;&gt; &lt;tab heading=&quot;1단계&quot;&gt; &lt;first-tab&gt;&lt;&#x2F;first-tab&gt; &lt;&#x2F;tab&gt; &lt;tab heading=&quot;2단계&quot;&gt; &lt;second-tab&gt;&lt;&#x2F;second-tab&gt; &lt;&#x2F;tab&gt; &lt;&#x2F;tabset&gt; &lt;div&gt; &lt;button class=&quot;btn btn-primary&quot; type=&quot;button&quot; (click)=&quot;saveRequest()&quot;&gt;제출하기&lt;&#x2F;button&gt; &lt;button class=&quot;btn btn-info&quot; type=&quot;button&quot;&gt;초기화&lt;&#x2F;button&gt; &lt;&#x2F;div&gt; &lt;&#x2F;div&gt; import { Component, OnInit } from &#39;@angular&#x2F;core&#39;; @Component({ selector: &#39;tab-menu&#39;, templateUrl: &#39;.&#x2F;tab-menu.component.html&#39;, styleUrls: [&#39;.&#x2F;tab-menu.component.css&#39;] }) export class TabMenuComponent implements OnInit { ... ngOnInit() { } saveRequest() { &#x2F;&#x2F; TODO 1: 여기서 first-tab 컴포넌트와 second-tab 컴포넌트에 Form 데이터를 가져올 이벤트를 발생(emit)한다. &#x2F;&#x2F; TODO 2: 자식 컴포넌트들(first-tab, second-tab)에서는 부모 컴포넌트(tab-menu)로 Form 데이터를 전달한다. } } 2) 부모 컴포넌트의 멤버 필드로 데이터를 셋팅하는 로직이 담긴 클로저 이벤트를 발생한다.import { Component, OnInit } from &#39;@angular&#x2F;core&#39;; import { FirstTabForm } from &#39;.&#x2F;firstTabForm&#39;; import { SecondTabForm } from &#39;.&#x2F;secondTabForm&#39;; @Component({ selector: &#39;tab-menu&#39;, templateUrl: &#39;.&#x2F;tab-menu.component.html&#39;, styleUrls: [&#39;.&#x2F;tab-menu.component.css&#39;] }) export class TabMenuComponent implements OnInit { ... firstTabForm: FirstForm; secondTabForm: SecondForm; firstTabFormSelectEvent: EventEmitter&lt;any&gt; = new EventEmitter&lt;any&gt;(); secondTabFormSelectEvent: EventEmitter&lt;any&gt; = new EventEmitter&lt;any&gt;(); ngOnInit() { } saveRequest() { &#x2F;&#x2F; TODO 1: 여기서 first-tab 컴포넌트와 second-tab 컴포넌트에 Form 데이터를 가져올 이벤트를 발생(emit)한다. this.firstTabFormSelectEvent.emit(it =&gt; { this.firstTabForm = it; console.log(`${this.firstTabForm.name} : ${this.firstTabForm.email} : ${this.firstTabForm.address}`); }); this.secondTabFormSelectEvent.emit(it =&gt; { this.secondTabForm = it; console.log(`${this.secondTabForm.count} : ${this.secondTabForm.groupName}`); }); &#x2F;&#x2F; emit의 파라미터를 자세히 살펴보면 클로저를 넘기고 있다. &#x2F;&#x2F; TODO 2: 자식 컴포넌트들(first-tab, second-tab)에서는 부모 컴포넌트(tab-menu)로 Form 데이터를 전달한다. } } 3) 이벤트를 자식컴포넌트에서 subscribe 하기 위해서 서비스 클래스(formService.ts)로 따로 뺀다.import { Component, OnInit, Output, EventEmitter } from &#39;@angular&#x2F;core&#39;; import { FirstTabForm } from &#39;.&#x2F;firstTabForm&#39;; import { SecondTabForm } from &#39;.&#x2F;secondTabForm&#39;; import { FormService } from &#39;.&#x2F;formService&#39;; @Component({ selector: &#39;tab-menu&#39;, templateUrl: &#39;.&#x2F;tab-menu.component.html&#39;, styleUrls: [&#39;.&#x2F;tab-menu.component.css&#39;] }) export class TabMenuComponent implements OnInit { firstTabForm: FirstTabForm; secondTabForm: SecondTabForm; constructor( private formService: FormService ) { } ngOnInit() { } saveRequest() { this.formService.selectFirstForm(it =&gt; { this.firstTabForm = it; console.log(`${this.firstTabForm.name} : ${this.firstTabForm.email} : ${this.firstTabForm.address}`); }); this.formService.selectSecondForm(it =&gt; { this.secondTabForm = it; console.log(`${this.secondTabForm.count} : ${this.secondTabForm.groupName}`); }); } } import { Injectable, EventEmitter } from &#39;@angular&#x2F;core&#39;; @Injectable() export class FormService { firstTabFormSelectEvent: EventEmitter&lt;any&gt; = new EventEmitter&lt;any&gt;(); secondTabFormSelectEvent: EventEmitter&lt;any&gt; = new EventEmitter&lt;any&gt;(); selectFirstForm(event: any) { this.firstTabFormSelectEvent.emit(event); } selectSecondForm(event: any) { this.secondTabFormSelectEvent.emit(event); } } 4) 자식 컴포넌트에서는 해당 이벤트를 subscribe 하는데 이 때 자식 컴포넌트의 데이터를 넘기기 위해 받은 이벤트를 실행한다.import { Component, OnInit, Input } from &#39;@angular&#x2F;core&#39;; import { FirstTabForm } from &#39;..&#x2F;firstTabForm&#39;; import { FormService } from &#39;..&#x2F;formService&#39;; @Component({ selector: &#39;first-tab&#39;, templateUrl: &#39;.&#x2F;first-tab.component.html&#39;, styleUrls: [&#39;.&#x2F;first-tab.component.css&#39;] }) export class FirstTabComponent implements OnInit { @Input() childForm: FirstTabForm = new FirstTabForm(); constructor(private formService: FormService) { } ngOnInit() { this.formService.onSelectFirstForm(eventBody =&gt; { eventBody(this.childForm); }); } } import { Injectable, EventEmitter } from &#39;@angular&#x2F;core&#39;; @Injectable() export class FormService { firstTabFormSelectEvent: EventEmitter&lt;any&gt; = new EventEmitter&lt;any&gt;(); secondTabFormSelectEvent: EventEmitter&lt;any&gt; = new EventEmitter&lt;any&gt;(); selectFirstForm(event: any) { this.firstTabFormSelectEvent.emit(event); } selectSecondForm(event: any) { this.secondTabFormSelectEvent.emit(event); } onSelectFirstForm(subscribeFunc: any) { this.firstTabFormSelectEvent.subscribe(subscribeFunc); } onSelectSecondForm(subscribeFunc: any) { this.secondTabFormSelectEvent.subscribe(subscribeFunc); } } 방법 2 전체 소스https://github.com/icednut/angular2-exercise/tree/closure_event 방법1, 방법2 말고도 더 좋은 방법이 있겠지만 이번 포스트는 여기서 마무리!","categories":[],"tags":[{"name":"angular2","slug":"angular2","permalink":"http://icednut.github.io/tags/angular2/"},{"name":"input","slug":"input","permalink":"http://icednut.github.io/tags/input/"},{"name":"output","slug":"output","permalink":"http://icednut.github.io/tags/output/"}]},{"title":"Angular 2 - 사례로 살펴보는 @Input과 @Output의 이해 1","slug":"20161209-about_angular2_input_output","date":"2016-12-08T15:00:00.000Z","updated":"2018-11-27T06:40:43.301Z","comments":true,"path":"2016/12/09/20161209-about_angular2_input_output/","link":"","permalink":"http://icednut.github.io/2016/12/09/20161209-about_angular2_input_output/","excerpt":"","text":"문제&lt;my-toolbar&gt;&lt;&#x2F;my-toolbar&gt; &lt;div style=&quot;padding:10px;&quot;&gt; &lt;router-outlet&gt;&lt;&#x2F;router-outlet&gt; &lt;&#x2F;div&gt; Angular 2 기반의 프로젝트에서 위와 같은 컴포넌트 구성일 경우 메뉴1, 2를 클릭할 때마다 빨간색 네모 영역에 메뉴의 서브타이틀을 표시하고 싶을 경우 Angular 2에서는 어떻게 풀 수 있을까?화면에 보이는 바와 같이 상단에 툴바가 있고, router를 통해 각 메뉴에 해당하는 내용이 출력되는 상황이다. 프로젝트 파일 구조는 다음과 같다. . ├── ... ├── package.json ├── src │ ├── app │ │ ├── app.component.css │ │ ├── app.component.html │ │ ├── app.component.spec.ts │ │ ├── app.component.ts │ │ ├── app.module.ts │ │ ├── index.ts │ │ ├── menu1 │ │ │ ├── menu1.component.css │ │ │ ├── menu1.component.html │ │ │ ├── menu1.component.spec.ts │ │ │ └── menu1.component.ts │ │ ├── menu2 │ │ │ ├── menu2.component.css │ │ │ ├── menu2.component.html │ │ │ ├── menu2.component.spec.ts │ │ │ └── menu2.component.ts │ │ └── my-toolbar │ │ ├── my-toolbar.component.css │ │ ├── my-toolbar.component.html │ │ ├── my-toolbar.component.spec.ts │ │ └── my-toolbar.component.ts │ ├── ... │ ├── index.html │ ├── main.ts │ ├── styles.css │ └── ... └── ... 문제 풀이단순하게 생각하면 메뉴가 바뀔 때마다 my-toolbar 컴포넌트에 서브타이틀 문자열을 넘겨주고 my-toolbar는 넘겨받은 서브타이틀 문자열을 출력하면 될 것 같다.그런데 서브타이틀을 어떻게 넘겨줄 것인가? 이 때 사용하는 것이 Data Binding 이다. 여러가지 방법이 있겠지만 일단 지금의 컴포넌트 구성을 깨지 않고 진행을 해보자. 1. 먼저 my-toolbar에서 서브타이틀을 넘겨 받을 수 있게 Input 데이터 바인딩을 해준다.&lt;my-toolbar [currentMenuSubTitle]=&quot;menuSubTitle&quot;&gt;&lt;&#x2F;my-toolbar&gt; &lt;div style=&quot;padding:10px;&quot;&gt; &lt;router-outlet&gt;&lt;&#x2F;router-outlet&gt; &lt;&#x2F;div&gt; my-toolbar 앨리먼트에 쓰여진 어트리뷰트를 살펴보면 currentMenuSubTitle에 대괄호가 둘러쌓여져 있는데 이는 my-toolbar 컴포넌트의 Input 필드를 의미한다.위의 상황으로 보면 app.component의 menuSubTitle 이라는 필드를 my-toolbar 컴포넌트의 currentMenuSubTitle 이라는 필드로 데이터 바인딩을 하겠다는 것을의미한다. 2. 데이터 바인딩이 잘 될 수 있도록 my-toolbar 컴포넌트에도 동일한 이름의 @Input이 붙은 필드를 선언해준다.import {Input, Component, OnInit} from &#39;@angular&#x2F;core&#39;; @Component({ selector: &#39;my-toolbar&#39;, templateUrl: &#39;.&#x2F;my-toolbar.component.html&#39;, styleUrls: [&#39;.&#x2F;my-toolbar.component.css&#39;] }) export class MyToolbarComponent implements OnInit { @Input() currentMenuSubTitle: string; constructor() { } ngOnInit() { } } 3. app.component에도 menuSubTitle 라는 필드를 선언하고 문자열을 넣어본다.import { Component } from &#39;@angular&#x2F;core&#39;; @Component({ selector: &#39;app-root&#39;, templateUrl: &#39;.&#x2F;app.component.html&#39;, styleUrls: [&#39;.&#x2F;app.component.css&#39;] }) export class AppComponent { menuSubTitle = &#39;Hello, world!!&#39;; } 이렇게 하면 아래와 같이 서브타이틀이 표시되는 것을 볼 수 있다. 자, 그럼 Menu1Component와 Menu2Component가 AppComponent의 menuSubTitle 필드로 데이터를 넣어줄 것인가?여러가지 방법이 있겠지만 service 클래스를 사용하여 문제 해결을 진행해보자. 4. 서브타이틀 문자열의 변화를 감지할 옵저버를 선언한다.여기서는 Service 클래스를 사용하여 옵저버 역할을 하게 한다. import { Injectable, EventEmitter } from &#39;@angular&#x2F;core&#39;; @Injectable() export class MyToolbarService { subTitleChangeEvent: EventEmitter&lt;string&gt; = new EventEmitter&lt;string&gt;(); constructor() { } setSubTitle(subTitle: string) { this.subTitleChangeEvent.emit(subTitle); } onChangeSubTitle(handler: any) { this.subTitleChangeEvent.subscribe(handler); } } 5. AppComponent에서는 subTitle의 변화가 있을 때 자신의 menuSubTitle 필드에 데이터를 바인딩한다.이렇게 서브타이틀 변화에 대한 핸들러를 생성자에서 선언해준다. 이 핸들러에서는 서브타이틀 변화가 있을 때 마다 menuSubTitle 필드에 데이터를 바인딩하는 로직이 담겨 있다.실수하지 말아야 할 부분이 있는데 providers에 서브타이틀 이벤트 처리가 담긴 MyToolbarService 클래스를 선언해줘야지 정상적으로 이벤트 핸들링을 할 수 있게 된다. import { Component, OnInit } from &#39;@angular&#x2F;core&#39;; import {MyToolbarService} from &#39;.&#x2F;my-toolbar.service&#39;; @Component({ selector: &#39;app-root&#39;, templateUrl: &#39;.&#x2F;app.component.html&#39;, styleUrls: [&#39;.&#x2F;app.component.css&#39;], providers: [MyToolbarService] }) export class AppComponent { menuSubTitle; constructor(private myToolbarService: MyToolbarService) { this.myToolbarService.onChangeSubTitle(newMenuSubTitle =&gt; { this.menuSubTitle = newMenuSubTitle; }); } } 6. Menu1Comopnent와 Menu2Component에서는 서브타이틀 변경 이벤트 발생 로직을 작성한다.Menu1Component에서는 아래와 같이 서브타이틀 값을 변경하면 앞에 선언한 서비스 코드에 나와 있다시피 서브타이틀 변경 이벤트가발생하게 된다. 그러면 AppComponent에서 이를 감지하여 AppComponent.menuSubTitle 필드에 변경된 값을 할당하게 될 것이고,AppComponent.menuSubTitle는 my-toolbar의 인풋 필드와 바인딩이 되어 있기 때문에 Menu1Component와 Menu2Component의 ngOnInit에서setSubTitle 메소드를 실행하여 서브타이틀 값을 변경하면 툴바의 서브타이틀 부분이 갱신되게 된다. import {Output, Component, OnInit, EventEmitter} from &#39;@angular&#x2F;core&#39;; import {MyToolbarService} from &#39;..&#x2F;my-toolbar.service&#39;; @Component({ selector: &#39;app-menu1&#39;, templateUrl: &#39;.&#x2F;menu1.component.html&#39;, styleUrls: [&#39;.&#x2F;menu1.component.css&#39;] }) export class Menu1Component implements OnInit { constructor(private myToolbarService: MyToolbarService) { } ngOnInit() { this.myToolbarService.setSubTitle(&quot;menu1&#39;s subtitle&quot;); } } 전체 결과 소스코드https://github.com/icednut/angular2-exercise 위 방법이 정답이라 생각하지 않고 또 다른 효율적인 방법이 있을 것이라 생각한다. 일단 router-outlet 밑에서 동작하는 컴포넌트들에 대해AppComponent와 연결할 수 있는 마땅한 방법이 떠오르지 않아 서비스 클래스를 사용했지만, 좀 더 코드도 줄이면서 데이터 바인딩도 잘 될 수 있는효율적인 방법을 찾는 것에 대해 계속 노력해야겠다.","categories":[],"tags":[{"name":"angular2","slug":"angular2","permalink":"http://icednut.github.io/tags/angular2/"},{"name":"input","slug":"input","permalink":"http://icednut.github.io/tags/input/"},{"name":"output","slug":"output","permalink":"http://icednut.github.io/tags/output/"}]},{"title":"D3로 Table과 Bar Chart 표현하기","slug":"20161209-d3_table_and_barchart","date":"2016-12-08T15:00:00.000Z","updated":"2018-11-27T06:40:43.291Z","comments":true,"path":"2016/12/09/20161209-d3_table_and_barchart/","link":"","permalink":"http://icednut.github.io/2016/12/09/20161209-d3_table_and_barchart/","excerpt":"","text":"Table http://bl.ocks.org/gka/17ee676dc59aa752b4e6 http://bl.ocks.org/jfreels/6734025 Bar Chart http://bl.ocks.org/juan-cb/faf62e91e3c70a99a306 http://bl.ocks.org/kiranml1/6872226","categories":[],"tags":[{"name":"d3","slug":"d3","permalink":"http://icednut.github.io/tags/d3/"},{"name":"table","slug":"table","permalink":"http://icednut.github.io/tags/table/"},{"name":"bar_chart","slug":"bar-chart","permalink":"http://icednut.github.io/tags/bar-chart/"}]},{"title":"개인적으로 마음에 드는 웹 테마들","slug":"20161201-front_end_themes","date":"2016-11-30T15:00:00.000Z","updated":"2018-11-27T06:40:43.296Z","comments":true,"path":"2016/12/01/20161201-front_end_themes/","link":"","permalink":"http://icednut.github.io/2016/12/01/20161201-front_end_themes/","excerpt":"","text":"Angualr &amp; Bootstrap를 사용한 마음에 드는 테마들 https://www.bootstrapzero.com/ https://www.bootstrapzero.com/bootstrap-template/material-kit http://www.responsivemiracle.com/best-angular-2-material-design-theme/ http://www.creative-tim.com/product/light-bootstrap-dashboard-pro/?affiliate_id=85444","categories":[],"tags":[{"name":"angualr","slug":"angualr","permalink":"http://icednut.github.io/tags/angualr/"},{"name":"bootstrap","slug":"bootstrap","permalink":"http://icednut.github.io/tags/bootstrap/"},{"name":"theme","slug":"theme","permalink":"http://icednut.github.io/tags/theme/"}]},{"title":"Deadlock이 뭐지? (Java Thread와 Deadlock에 대한 고찰)","slug":"20160806-about_deadlock","date":"2016-08-05T15:00:00.000Z","updated":"2018-11-27T06:40:43.289Z","comments":true,"path":"2016/08/06/20160806-about_deadlock/","link":"","permalink":"http://icednut.github.io/2016/08/06/20160806-about_deadlock/","excerpt":"","text":"들어가기 전에최근에 Deadlock이 뭔지 고민해보는 시간이 있었다. 뭐 요즘 들어서 Reactor다 Akka다 뭐다 해서 비동기 프로그래밍을 손쉽게 할 수 있는 프레임워크나 라이브러리가 있어서 Deadlock에 대해 신경을 안쓰고 살고 있어 대답이 선뜻 나오질 못했다. Deadlock이 뭔가요에 대한 질문에 그냥 막연히 다수의 Thread가 서로의 Lock을 기다리는 상황이라고만 대답했는데, 이참에 좀 더 구체적으로 Deadlock이 뭐고 원인, 해결에는 뭐가 있는지 알아봐야 겠다. 정리 하는김에 Java Fork &amp; Join, ThreadLocal, stream parallel에 대해서도 살펴봐야겠다. Deadlock의 원인 데드락은 예전부터 식사하는 철학자 dining philosophers 문제로 널리 알려져 왔다. 다섯 명의 철학자가 중국 음식점에 저녁 식사를 하러 가서 둥그런 테이블에 앉았다. 테이블에는 다섯 개의 젓가락(다섯 쌍이 아닌 다섯 개)이 개인별 접시 사이에 하나씩 놓여있다. 철학자는 ‘먹는’ 동작과 ‘생각하는’ 동작을 차례대로 반복한다. 먹는 동안에는 접시 양쪽에 있는 젓가락 두 개를 모아 한 쌍을 만들어야 자신의 접시에 놓인 음식을 먹을 수 있고, 음식을 먹은 이후에는 젓가락을 다시 양쪽에 하나씩 내려 놓고 생각을 시작한다. (중략) 모든 철학자가 각자 자기 왼쪽에 있는 젓가락을 집은 다음 오른쪽 젓가락을 사용할 수 있을 때까지 기다렸다가 오른쪽 젓가락을 집어서 식사를 한다면, 모든 철학자가 더 이상 먹지 못하는 상황에 다다를 수 있다. 철학자 모두가 먹지 못하는 상황은 음식을 먹는 데 필요한 자원을 모두 다른 곳에서 확보하고 놓지 않기 때문에 모두가 서로 상대방이 자원을 놓기만을 기다리는, 이른바 데드락이 걸린다.자바 병렬 프로그래밍 P.305 식사하는 철학자의 문제를 Java Thread에 접목하여 Deadlock이 생기는 과정을 살펴보면 다음과 같다. // 데드락 위험이 있는 코드 public class LeftRightDeadlock { private final Object left = new Object(); private final Object right = new Object(); public void leftRight() { synchronized (left) { synchronized (right) { doSomething(); } } } public void rightLeft() { synchronized (right) { synchronized (left) { doSomethingElse(); } } } } 스레드 A가 락 left을 확보한 상태에서 락 right을 확보하려 대기 스레드 B가 락 right을 확보한 상태에서 락 left을 확보하려고 대기 양쪽 스레드 A, B는 서로가 락을 풀기를 영원히 기다리게 됨 위와 같이 Java Thread에서도 스레드 하나가 특정 락(Lock)을 놓지 않고 계속 잡고 있으면 그 락을 확보하려는 다른 스레드는 락이 풀릴 때까지 기다리는 수 밖에 없다. Deadlock은 Thread가 두 개의 락을 획득하려 하는 코드에서 나타난다. 학교에서 배울 때는 이 정도 수준에서 멈추는 경우가 많은데 데드락은 상용 서비스를 시작하고 나서 시스템에 부하가 걸리는 경우와 같이 최악의 상황에서 그 모습을 드러내곤 한다. 더군다나 아주 심도있는 방법으로 부하 테스트(load-testing)을 진행했다 하더라도 발생 가능한 데드락 모두 찾아낼 수는 없다. JVM에서는 데이터베이스 서버와 같이 데드락 상태 추적 기능이 없기 때문에 Java Application에서 데드락이 발생했을 때 정상으로 되돌리려 한다면 애플리케이션을 종료하고 다시 실행하는 것밖에 없다. Deadlock 예방하기방법 1. Lock이 발생하는 순서를 정해놓는다. 프로그램 내부의 모든 스레드에서 필요한 락을 모두 같은 순서로만 사용한다면, 락 순서에 의한 데드락은 발생하지 않는다.자바 병렬 프로그래밍 P.307 // 해결 전: 데드락 위험이 있는 코드 public void transferMoney (Account fromAccount, Account toAccount, DollarAmount amount) { synchronized (fromAccount) { synchronized (toAccount) { if (fromAccount.getBalance().compareTo(amount) &lt; 0) { throw new InsufficientFundsException(); } else { fromAccount.debit(amount); toAccount.credit(amount); } } } } 위 코드를 얼핏보면 경합이 일어나지 않을 코드 같다. 하지만 파라미터 fromAccount와 toAccount에 순서만 달리해서 동시 호출이 일어난다면 데드락이 걸릴 확률이 증가하게 된다. // 해결 후: Lock이 발생하는 순서를 제어한 경우 private static final Object tieLock = new Object(); public void transferMoney(final Account fromAccount, final Account toAccount, final DollarAmount amount) { class Helper { public void transfer() { if (fromAccount.getBalance().compareTo(acmount) &lt; 0) { throw new InsufficientFuncsException(); } else { fromAccount.debit(amount); toAccount.credit(ammount); } } } int fromHash = System.identityHashCode(fromAccount); int toHash = System.identityHashCode(toAccount); if (fromHash &lt; toHash) { synchronized(fromAccount) { synchronized(toAccount) { new Helper().transfer(); } } } else if (fromHash &gt; toHash) { synchronized(toAccount) { synchronized(fromAccount) { new Helper().transfer(); } } } else { synchronized (tieLock) { synchronized(fromAccount) { synchronized(toAccount) { new Helper().transfer(); } } } } } 방법 2. 오픈 호출메소드 호출이라는 것은 그 너머에 어떤 일이 일어나는지 모르게 막아주는 추상화 방법이다. 하지만 호출한 메소드 내부에서 어떤 일이 일어나는지 알지 못하기 때문에 특정 락을 확보한 상태에서 다른 메소드를 호출한다는 것은 파급 효과를 분석하기가 어렵고 위험한 일이다. 이에 따라 락을 전혀 확보하지 않은 상태에서 메소드를 호출하는 것이 좋은데 이것을 오픈 호출이라고 한다. (스레드 안정성을 확보하기 위해 캡슐화 기법encapsulation을 사용하는 것과 비슷) 락을 확보하지 않은 상태에서 메소드를 호출하는게 관건! 방법 3. 락의 시간 제한암묵적인 락 synchronized 말고 락 시간을 제한할 있는 Lock 클래스의 tryLock 메소드를 사용한다. 암묵적인 락은 락을 확보할 때까지 영원히 기다리지만, Lock 클래스 등의 명시적인 락은 일정 시간을 정해두고 그 시간 동안 락을 확보하지 못한다면 tryLock 메소드가 오류를 발생시키도록 할 수 있다. 스레드 덤프를 활용한 Deadlock 분석하기스레드 덤프 분석이라면 여기 훌륭한 글이 이미 있다.http://d2.naver.com/helloworld/10963","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://icednut.github.io/tags/java/"},{"name":"Thread","slug":"Thread","permalink":"http://icednut.github.io/tags/Thread/"},{"name":"Deadlock","slug":"Deadlock","permalink":"http://icednut.github.io/tags/Deadlock/"}]},{"title":"나만의 책속 한 줄 -  책 'DDD Start!'를 읽으면서...","slug":"20160803-ddd_reading_memo","date":"2016-08-02T15:00:00.000Z","updated":"2018-11-27T06:40:43.285Z","comments":true,"path":"2016/08/03/20160803-ddd_reading_memo/","link":"","permalink":"http://icednut.github.io/2016/08/03/20160803-ddd_reading_memo/","excerpt":"","text":"예를 들어, 게시글 데이터를 ARTICLE 테이블과 ARTICLE_CONTENT 테이블로 나눠서 저장한다고 하자. (중략) [그림4.5]만 보면 ARTICLE_CONTENT 테이블의 ID 칼럼이 식별자이므로 ARTICLE_CONTENT와 맵핑되는 ArticleContent를 엔티티로 생각할 수 있는데, 이것 때문에 Article과 ArticleContent를 두 엔티티 간의 일대일 연관으로 매핑하는 실수를 할 수 있다. 책을 읽다말고 ‘아니 이게 왜 실수인가?’ 라는 생각이 퍼뜩 들었다. 왜냐하면 평소에도 Article과 ArticleContent는 각각 엔티티로 만들어서 연관관계를 맺어줘야 한다고 생각했기 때문이다. 그런데 그 다음을 읽자 내가 생각없이 코딩하고 있었다는 것이 여실히 들어나게 되는 순간을 맞이하게 되었다. ArticleContent를 엔티티로 생각할 수 있지만 ArticleContent는 Article의 내용을 담고 있는 밸류로 생각하는 것이 맞다. ARTICLE_CONTENT의 ID는 식별자이기는 하지만 이 식별자를 사용하는 이유는 ARTICLE 테이블의 데이터와 연결하기 위함이지 ARTICLE_CONTENT를 위한 별도 식별자가 필요하기 때문은 아니다. 즉, 이는 게시글의 특정 프로퍼티를 별도 테이블에 보관한 것으로 접근해야 한다. 아…그 동안 엔티티를 생각없이 무분별하게 남용해왔다는 것을 느꼈다. 여지껏 Article, ArticleContent와 비슷한 상황을 자주 경험하곤 했는데 그 때마다 1대1 연관관계를 맺어서 데이터를 조회해왔던 것이 생각이 났다. 이 책에서 Aggregate, Domain 등에 대해서 얘기하고 있는데 정작 나는 이런 개념들을 모른채 그저 생각없이 JPA를 써왔던 것 같다. ArticleContent를 밸류로 인식하기 위해서는 @Embaddable 대신 @SecondaryTable를 사용하는 것으로 책에는 설명을 하고 있다. import javax.persistence.*; @Entity @Table(name = &quot;article&quot;) @SecondaryTable( name = &quot;article_content&quot;, pkJoinColumns = @PrimaryKeyJoinColumn(name = &quot;id&quot;) ) public class Article { @Id private Long id; private String title; @AttributeOverrides({ @AttributeOverride(name = &quot;content&quot;, column = @Column(table = &quot;article_content&quot;)), @AttributeOverride(name = &quot;contentType&quot;, column = @Column(table = &quot;article_content&quot;)) }) private ArticleContent content; } &#x2F;&#x2F; @SecondaryTable로 매핑된 article_content 테이블을 조인 Article article = entityManager.find(Article.class, 1L); 여기서 굳이 @SecondaryTable나 @AttributeOverrides와 같은 어노테이션을 소개하려고 이 글을 쓰려했던 것은 아니다. 엔티티와 밸류를 어떻게 취급하느냐에 대해 주목해야 될 것 같다. 4장에서 애그리거트에서 엔티티와 밸류를 어떻게 다뤄야 되는지에 대한 주옥같은 방법과 설명들이 있는데 그동안 JPA를 생각없이 썼던 나에겐 굉장한 충격이었다. 책을 좀 더 읽고 애그리거트와 엔티티를 어떻게 나눌지 고민하면서 코딩을 해야겠다.","categories":[],"tags":[{"name":"JPA","slug":"JPA","permalink":"http://icednut.github.io/tags/JPA/"},{"name":"DDD","slug":"DDD","permalink":"http://icednut.github.io/tags/DDD/"},{"name":"나만의_책속_한줄","slug":"나만의-책속-한줄","permalink":"http://icednut.github.io/tags/나만의-책속-한줄/"}]},{"title":"Logback & SLF4J를 쓰면서 만났던 문제","slug":"20160715-logback_and_slf4j","date":"2016-07-14T15:00:00.000Z","updated":"2018-11-27T06:40:43.299Z","comments":true,"path":"2016/07/15/20160715-logback_and_slf4j/","link":"","permalink":"http://icednut.github.io/2016/07/15/20160715-logback_and_slf4j/","excerpt":"","text":"최근 Oozie에서 RabbitMQ로 메세지를 전송하는 Common Action 개발을 맡았다. 여기서 Action은 Spring Boot 기반으로 개발하고 있었는데 문제는 Spring Boot가 실행되면서 Logging 관련 라이브러리가 말썽을 일으켜 Spring Boot가 아예 실행조차 되질 않는 상황이 발생했다. 상황을 자세히 설명하자면 다음과 같다. 상황 Oozie에서 Executable Jar를 실행하는 Action이 하나 있었다. 그런데 이 Jar파일은 Spring Boot Application 이었고, Jar 파일 안에는 관련 있는 디펜던시 라이브러리들이 모두 한데 묶여 포함되어 있었다. (한마디로 Fat Jar) 디펜던시 중에는 Logback-core-1.1.3, Logback-classic-1.1.3, Slf4j-api-7.1.13이 있었고, 하필 Oozie 클러스터에 Slf4j-log4j2가 존재하고 있었다.// TODO: 간략한 Dependency Tree 표기할 것 다시 Spring Boot로 초점을 맞춰보면, Spring Boot가 Bootstraping 하면서 여러 Spring Event를 발생시키게 되는데 그 중에 하나가 org.springframework.boot.logging.LoggingApplicationListener이다. 여기서 LoggingApplicationListener가 ApplicationStartedEvent를 핸들링 할 때 발생하는데, ApplicationStartedEvent를 받으면 LoggingSystem의 구현체를 결정하고 그 구현체를 초기화하는 로직이 실행되게 된다.private void onApplicationStartedEvent(ApplicationStartedEvent event) { this.loggingSystem = LoggingSystem.get(event.getSpringApplication().getClassLoader()); this.loggingSystem.beforeInitialize(); } 문제는 LoggingSystem의 구현체를 결정할 때(LoggingSystem.get 메소드를 호출할 때) 현재 디펜던시 상황에 따라 LogbackLoggingSystem이 결정되고 초기화가 진행되는데 초기화 진행 중 StaticLoggerBinder에게 LoggerContext를 요청한 뒤 요청 결과물을 LoggerContext로 캐스팅을 진행할 때 결과물이 Log4jLoggerFactory라고 인식이 되어 캐스팅 불가능하게 되어 예외가 발생하며 시스템이 실행되질 않는다.private LoggerContext getLoggerContext() { ILoggerFactory factory = StaticLoggerBinder.getSingleton().getLoggerFactory(); Assert.isInstanceOf(LoggerContext.class, factory, String.format( \"LoggerFactory is not a Logback LoggerContext but Logback is on \" + \"the classpath. Either remove Logback or the competing \" + \"implementation (%s loaded from %s). If you are using \" + \"WebLogic you will need to add 'org.slf4j' to \" + \"prefer-application-packages in WEB-INF/weblogic.xml\", factory.getClass(), getLocation(factory))); return (LoggerContext) factory; } 뭔소리인지 소스코드와 함께 다시 설명하자면 StaticLoggerBinder.getSingleton().getLoggerFactory()의 결과물이 Logback의 LoggerContext가 아니라 Slf4j-log4j2의 Log4jLoggerFactory가 반환된다는 소리이다. 왜 이런 문제가 발생하는 것일까?앞에서도 이미 말했지만 Logback과 Slf4j-log4j2에 각각 존재하는 StaticLoggerFactory의 구현체가 서로 다르기 때문에 발생하는 문제이다. 사실 java의 Logging 라이브러리를 조금 유심히 살펴본 사람이라면 금방 알아차릴 수 있는 문제이긴 하지만, 모르더라도 Logback과 Slf4j의 소스코드를 살펴보면 구현체가 뭐가 다른지를 알 수 있다. 그럼 어떻게 해결해야 될까? 위 문제의 원인을 요약하자면 다음과 같다. Oozie 클러스터에 있는 slf4j-log4j2 라이브러리 때문에 Spring boot에서 Logback과 오류를 일으킨다. 문제는 Logback이 아니라 Spring boot에서 logback과 slf4j-log4j2를 같이 쓰면 오류를 발생시키는게 문제이다. 해결 spring boot를 안쓰거나 (LoggingApplicationListener만 등록 안하게 하는 것도 방법일 것 같다.) logback을 안쓰거나 (Logback을 안쓰고 Slf4j-log4j2를 쓰게 만드는 전략) slf4j-log4j2의 LoggerFactory가 인식되기 전에 logback-classic의 LoggerFactory가 인식되게 해야 한다. (아니면 StaticLoggerBinder가 강제로 Logback의 것으로 하게 한다던가..) 일단 가장 간단한 해결 방법은 Logback을 안쓰는 방법이다. 그런데 그렇게하면 더 이상 파일이나 Standard Output (System.out)으로 로그를 볼 수 없다.그럼 로그도 정상적으로 출력되면서 라이브러리 충돌도 안일으키게 하려면 어떻게 해야될까? 그 외 앞으로 할 일…이번 문제가 어느 정도 해결이 되고 나면 Java의 Logging 라이브러리를 좀 더 연구해봐야 겠다. Logback과 Slf4j의 공식 사이트가서 영어 까막눈이 레퍼런스를 들여다봐도 장님 코끼리 더듬는 느낌이다…","categories":[],"tags":[{"name":"Logback","slug":"Logback","permalink":"http://icednut.github.io/tags/Logback/"},{"name":"SLF4J","slug":"SLF4J","permalink":"http://icednut.github.io/tags/SLF4J/"},{"name":"oozie","slug":"oozie","permalink":"http://icednut.github.io/tags/oozie/"}]},{"title":"Hello World","slug":"20160711-hello_world","date":"2016-07-11T11:11:00.000Z","updated":"2018-11-27T06:40:43.282Z","comments":true,"path":"2016/07/11/20160711-hello_world/","link":"","permalink":"http://icednut.github.io/2016/07/11/20160711-hello_world/","excerpt":"","text":"안녕하세요! 여긴 저의 개인적인 낙서장이자, 놀이터, 지식 저장소 입니다.다람쥐가 도토리, 밤을 집에 모아놓듯이 저도 일이나 공부하면서 얻은 지식과 경험을 여기에 차곡차곡 모을 생각 입니다.","categories":[],"tags":[{"name":"HelloWorld","slug":"HelloWorld","permalink":"http://icednut.github.io/tags/HelloWorld/"}]}]}