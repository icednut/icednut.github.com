{"data":{"site":{"siteMetadata":{"title":"Icednut's Notes","author":"Will Lee","siteUrl":"https://icednut.github.io"}},"markdownRemark":{"id":"81ca4113-e863-535e-998d-e445ee210f45","excerpt":"Scala 훑어보기 실습 (SparkIntro/0. Scala Programming)zeppelin을 통해 스칼라 코드를 간단하게 실행해보자. (스칼라 관련 예제 notebook을 import 하여 실행해봄)Tip. 실행 후 소스코드를 더블클릭 해보면 수정이 가능함Spark…","html":"<h2>Scala 훑어보기 실습 (SparkIntro/0. Scala Programming)</h2>\n<ul>\n<li>\n<p>zeppelin을 통해 스칼라 코드를 간단하게 실행해보자. (스칼라 관련 예제 notebook을 import 하여 실행해봄)</p>\n<ul>\n<li>Tip. 실행 후 소스코드를 더블클릭 해보면 수정이 가능함</li>\n</ul>\n</li>\n</ul>\n<h2>Spark Overview</h2>\n<ul>\n<li>MapReduce 오버뷰, Spark와 MapReduce를 비교하여 뭐가 좋은지 </li>\n<li>Spark로 할 수 있는게 뭐가 있을까? ETL, Crawling, Statistics</li>\n<li>Spark로 할 수 없는건? 시각화, 데이터 수집</li>\n<li>결국 Spark를 쓰는 목적은 데이터를 저장소에서 읽어서 가공 후 저장하는 것을 분산처리 방식으로 프레임워크화 된 기술을 쓰기위해서 쓰는 것</li>\n</ul>\n<h2>Spark 실행 환경 구축하기</h2>\n<ul>\n<li>\n<p>Spark를 하려면 로컬 머신에서 개발용으로 할 것인지, 여러 머신에서 Clustering해서 분산 처리할 것인지에 따라 다르다.</p>\n</li>\n<li>\n<p>Local Machine 개발용으로 Spark 환경 구축하기</p>\n<ul>\n<li>크게 두 가지로 나뉘는데, Zeppelin만 설치하거나 Spark-submit을 사용하면 되는데 Zeppelin을 설치하면 Spark &#x26; UI, HDFS가 포함되어 있기 때문에 따로 설치할 필요가 없는 반면, Spark-submit을 쓰려면 저장소인 hdfs나 분산처리 매니징 기술인 YARN, 그리고 Spark 실행 모니터링을 하기 위한 Spark UI를 직접 설치해줘야 한다.</li>\n<li>Zeppelin 설치</li>\n<li>Zeppelin 공식 사이트에서 제플린 다운로드</li>\n<li>zeppelin을 로컬에서 실행하기 위한 설정 진행 (아래 설정파일 참고)</li>\n<li>$ZEPPELIN_HOME/bin/zeppelin.sh 실행</li>\n</ul>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-bash line-numbers\"><code class=\"language-bash\"><span class=\"token comment\"># $ZEPPELIN_HOME/conf/zeppelin-env.sh</span>\n<span class=\"token comment\">#!/bin/bash</span>\n<span class=\"token punctuation\">..</span>.\n\n<span class=\"token function\">export</span> JAVA_HOME<span class=\"token operator\">=</span>/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home\n<span class=\"token function\">export</span> HADOOP_HOME<span class=\"token operator\">=</span>/Users/1002371/Dev/hadoop-2.8.0\n<span class=\"token function\">export</span> SPARK_HOME<span class=\"token operator\">=</span>/Users/1002371/Dev/spark-2.1.1-bin-hadoop2.7\n<span class=\"token function\">export</span> HADOOP_CONF_DIR<span class=\"token operator\">=</span><span class=\"token variable\">${HADOOP_HOME}</span>/etc/hadoop</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<ol start=\"2\">\n<li>\n<p>Hadoop(YARN) 설치</p>\n<ul>\n<li>Hadoop 공식 사이트에서 하둡 다운로드</li>\n<li>$HADOOP_HOME/etc/haddop/hdfs-site.xml 등등 설정파일에 HDFS 관련 설정 진행하기 (아래 설정 예시 참고)</li>\n<li>$HADOOP_HOME/bin/start-all.sh 실행 (YARN과 HDFS 실행됨)</li>\n</ul>\n</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"xml\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-xml line-numbers\"><code class=\"language-xml\">// $HADDOP_HOME/etc/hadoop/core-site.xml\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>configuration</span><span class=\"token punctuation\">></span></span>\n <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>fs.defaultFS<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>hdfs://127.0.0.1:8020/<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>description</span><span class=\"token punctuation\">></span></span>NameNode URI<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>description</span><span class=\"token punctuation\">></span></span>\n <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>hadoop.proxyuser.teamsk.groups<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>*<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>hadoop.proxyuser.teamsk.hosts<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>*<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>configuration</span><span class=\"token punctuation\">></span></span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"xml\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-xml line-numbers\"><code class=\"language-xml\">// $HADDOP_HOME/etc/hadoop/hdfs-site.xml\n<span class=\"token prolog\">&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?></span>\n<span class=\"token prolog\">&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?></span>\n<span class=\"token comment\">&lt;!--\n  Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License. See accompanying LICENSE file.\n--></span>\n\n<span class=\"token comment\">&lt;!-- Put site-specific property overrides in this file. --></span>\n\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>configuration</span><span class=\"token punctuation\">></span></span>\n <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>dfs.datanode.data.dir<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>file:///home/teamsk/Sparklab/hadoop-2.8.0/data/datanode<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>description</span><span class=\"token punctuation\">></span></span>Comma separated list of paths on the local filesystem of a DataNode where it should store its blocks<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>description</span><span class=\"token punctuation\">></span></span>\n <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>dfs.replication<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>1<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>description</span><span class=\"token punctuation\">></span></span>Default block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time.<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>description</span><span class=\"token punctuation\">></span></span>\n <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>dfs.namenode.name.dir<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>file:///home/teamsk/Sparklab/hadoop-2.8.0/data/namenode<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>description</span><span class=\"token punctuation\">></span></span>Path on the local filesystem where the NameNode stores the namespace and transaction logs persistently.<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>description</span><span class=\"token punctuation\">></span></span>\n <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>dfs.webhdfs.enabled<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>true<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>configuration</span><span class=\"token punctuation\">></span></span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<ol start=\"3\">\n<li>\n<p>Spark 설치</p>\n<ul>\n<li>Spark 공식 사이트에서 스파크 다운로드</li>\n<li>Spark App 코드 작성 후 jar로 묶기</li>\n<li>$SPARK_HOME/bin에서 spark-submit.sh 실행하는데 실행 파라미터로 앞에서 만든 JAR 파일 입력하면 스파크 구동됨</li>\n</ul>\n</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-bash line-numbers\"><code class=\"language-bash\"><span class=\"token comment\"># $SPARK_HOME/conf/spark-env.sh</span>\n<span class=\"token comment\">#!/usr/bin/env bash</span>\n<span class=\"token punctuation\">..</span>.\n<span class=\"token function\">export</span> HADOOP_CONF_DIR<span class=\"token operator\">=</span>/Users/1002371/Dev/hadoop-2.8.0/etc/hadoop</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span></span></pre></div>\n<h2>Spark 실습 (SparkIntro/1. RDD Programming)</h2>\n<ul>\n<li>SparkContext를 활용하여 word counting 등 간단한 실습</li>\n<li>Spark’s Fault Tolerance: 파티션이 날라가면 계보를 따라 복구 후 다시 해당 파티션만 실행</li>\n<li>deterministically recomputable operations -> Lazy Evaluation 개념 (이게 되어야지 fault tolerance가 됨)</li>\n</ul>\n<h1>Spark Architecture</h1>\n<h2>Review</h2>\n<ul>\n<li>Two Types of Operations - transformation and action</li>\n<li>Transaformations are lazy</li>\n<li>Transformations are executed when an action is run.</li>\n<li>Persist and cache</li>\n</ul>\n<h2>동작 방식 (ETL 기반, 읽고 처리하고 저장)</h2>\n<ul>\n<li>hdfs 읽기 -> 필터링 -> 파티션 조정 -> 저장</li>\n<li>coalesce(2) // 원하는 데이터만 뽑아낸 뒤 파티션을 정리할 때 사용</li>\n<li>늘릴땐 repartition </li>\n<li>메모리 이슈가 발생할 땐 job이 죽음 -> 파티션 조정이 필요</li>\n</ul>\n<h2>Spark Job</h2>\n<ul>\n<li>Job: RDD로 계산하는 가장 최소 단위</li>\n<li>Stage: 코드가 실행된 파이프라인된 RDD 단위</li>\n<li>Task: 스테이지에서 RDD 파티션에 따른 실행 단위</li>\n<li>Shuffle</li>\n<li>Executor: 분산해서 실행시키는 주체</li>\n</ul>\n<h2>Spark Runtime Architecture</h2>\n<ul>\n<li>교육에서는 Spark Shell을 쓸 수도 있지만 Zeppelin을 쓴다.</li>\n<li>Zeppelin을 설치하면 스파크 관련 리소스가 생성됨</li>\n<li>Spark Shell을 쓰면 SparkContext를 직접 생성해줘야 함</li>\n<li>Spark을 클러스터링 하려면 Mesos, YARN을 써야됨</li>\n<li>Driver Program, Cluster Manager, Worker</li>\n<li>Spark Context를 생성하면서 클러스터를 지정?</li>\n</ul>\n<h2>Spark Deployment</h2>\n<ul>\n<li>분산환경에 Deploy할 때는 Mesos, Apahce YARN을 고려해야 됨</li>\n<li>Cluster Manager: 자원을 할당하거나 작업실행을 관리</li>\n<li>Spark-repl: spark shell을 띄우지 않아도 spark 코드를 실행시킬 수 있는 환경</li>\n<li>Spark Shell 로컬에서 띄우기: 간단한걸 테스트할 때 로컬에서 실행시키는게 좋음</li>\n<li>\n<p>Spark 코드 작성 -> Jar로 묶기 -> 클러스터에 배포 (배포할 때 쓰는게 spark-submit)</p>\n<ul>\n<li>Spark 실행 관련 설정은 conf 파일로 쓰거나 spark-submit의 옵션, 코드로 new SparkConf()에 셋팅할 수 있다.</li>\n</ul>\n</li>\n<li>StandAlone 모드: Master가 죽으면 안되기 때문에 Zookeeper를 사용하여 backup master가 실행할 수 있도록 해준다. (Mesos, YARN을 사용하여 클러스터링 할 때는 상관 없음)</li>\n<li>\n<p>Yarn Mode: Resource Manager, Node Manager의 개념으로 동작</p>\n<ul>\n<li>YARN Client Mode: 얀 밖에서 실행할 때 사용 (자원이 많지 않을 때 즉 Driver에서 많은 작업을 할 때 사용, Driver에서 많은 결과물을 전달해야 된다거나 등등..)</li>\n<li>YARN Cluster Mode: 클러스터 내에서 리소스 매니저를 지정</li>\n</ul>\n</li>\n<li>\n<p>Dynamic Resource Allocation on YARN: Application의 Work node에 따라서 서버가 조정. ETL을 밤에 띄울 때 서버가 많이 필요할 시 서버를 동적으로 늘려서 실행하고 싶을 때 사용</p>\n<ul>\n<li>RDD를 날리지 않고 재사용하기 위해 external shuffle plugin을 설치해야됨</li>\n<li>executor의 min, max 갯수를 지정하면 work node 내에서 실행되는 스레드 갯수 지정?</li>\n</ul>\n</li>\n<li>Mesos Mode: Mesos는 하둡진영 뿐 아니라 일반 어플리케이션 진영까지 자원관리 가능</li>\n<li>Job Server: SparkContext를 Spark 어플리케이션을 실행할 때마다 생성하는게 아니라 Job Server에 SparkContext를 생성해서 공유해서 사용 (Production 환경에서 사용)</li>\n<li>\n<p>Hardware sizing</p>\n<ul>\n<li>Storage: HDFS(추천) or local</li>\n<li>Local disk: raid 구성 안함, 한 노드당 디스크를 25TB 4-8개를 붙여서 씀?</li>\n<li>CPU: 객체 직렬화, 역직렬화 때문에 CPU를 많이 잡아먹음. 한 노드당 8-16 core를 추천</li>\n<li>Network: 셔플링이 많을 경우 네트워크 고민 필요. 10GB</li>\n<li>Memory: 8GB to hundreds of gigabytes, allocating only at most 75% of the memory.</li>\n</ul>\n</li>\n</ul>\n<h2>Spark on cloud</h2>\n<ul>\n<li>AWS 사용 사례 소개</li>\n</ul>","frontmatter":{"title":"스파크 강의 노트 Day 1","date":"2017-05-25 09:02:31","tags":["Spark"]}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/2017/20170525-spark-lecture-day01/","previous":{"fields":{"slug":"/2017/20170423-spring-camp-day02/"},"frontmatter":{"title":"스프링캠프 2017 둘째날 메모"}},"next":{"fields":{"slug":"/2017/20170526-spark-lecture-day02/"},"frontmatter":{"title":"스파크 강의 노트 Day 2"}}}}