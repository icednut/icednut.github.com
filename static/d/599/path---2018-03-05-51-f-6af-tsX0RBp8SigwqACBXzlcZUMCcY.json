{"data":{"site":{"siteMetadata":{"title":"Icednut's Notes","author":"Will Lee","siteUrl":"https://icednut.github.io"}},"markdownRemark":{"id":"7486a8f2-4871-5e3f-b7af-8ae539d73400","excerpt":"Druid란 무엇인가?Druid is a system built to allow fast (“real-time”) access to large sets of seldom-changing data.Druid is an open-source data store designed for sub…","html":"<h3>Druid란 무엇인가?</h3>\n<blockquote>\n<ul>\n<li>Druid is a system built to allow fast (“real-time”) access to large sets of seldom-changing data.</li>\n<li>Druid is an open-source data store designed for sub-second queries on real-time and historical data. It is primarily used for business intelligence (OLAP) queries on event data.</li>\n<li>Druid is a good fit for products that require real-time data ingestion of a single, large data stream. Especially if you are targeting no-downtime operation and are building your product on top of a time-oriented summarization of the incoming data stream. </li>\n<li>with Druid it is entirely within the realm of possibility (we have done it) to achieve queries that run in less than a second across trillions of rows of data.\n<br/></li>\n<li>드루이드는 변하지 않는 대규모 데이터셋에 빠르게 (실시간으로) 액세스하기 위해 만들어진 시스템이다.</li>\n<li>드루이드는 실시간과 시계열 데이터에서 1초 미만의 쿼리를 위해 설계된 오픈소스 데이터 저장소이다. 주로 이벤트 데이터에 대한 BI쿼리(OLAP)에 사용된다.</li>\n<li>드루이드는 싱글 혹은 대규모 데이터 스트림에서 실시간 데이터 입수(ingestion)이 필요한 제품에 적합하다. 특히 무중단 운영과 데이터 스트림 입수에서 시간 기반 요약을 제공하는 제품을 개발할 때 특히 그렇다.</li>\n<li>드루이드를 사용하면 수십억 데이터 행에서 1초 이내에 쿼리를 실행할 수 있게 된다.\n<br/>\n출처: Druid 공식 사이트 (<a href=\"http://druid.io/docs/0.11.0/design/design.html\">http://druid.io/docs/0.11.0/design/design.html</a>)</li>\n</ul>\n</blockquote>\n<p>드루이드 공식 사이트에 소개된 드루이드 소개글을 보면 대용량의 시계열 데이터를 실시간으로 빠르게 분석하고 싶을 때 사용하는 데이터 저장소라고 소개하고 있다. 다른 여러 저장소도 있지만 오픈소스 진영에서는 드루이드가 주목 받고 있는 것 같다. (<a href=\"http://xyz.insightdataengineering.com/blog/pipeline_map/\">http://xyz.insightdataengineering.com/blog/pipeline_map/</a> 여기에도 Druid를 소개하고 있음)</p>\n<h4>여기서 잠깐! OLAP(On-Line Analytical Processing)가 뭐지?</h4>\n<blockquote>\n<ul>\n<li>Online analytical processing, or OLAP, is an approach to answering multi-dimensional analytical (MDA) queries swiftly in computing.</li>\n<li>OLAP is part of the broader category of business intelligence, which also encompasses relational database, report writing and data mining. Typical applications of OLAP include business reporting for sales, marketing, management reporting, business process management (BPM), budgeting and forecasting, financial reporting and similar areas, with new applications coming up, such as agriculture.</li>\n<li>At the core of any OLAP system is an OLAP cube (also called a ‘multidimensional cube’ or a hypercube).\n<br/></li>\n<li>OLAP (Online Analytical Processing, 온라인 분석 처리)는 다차원 컬럼 분석(MDA, Multi-dimensional analytical) 쿼리에 신속하게 응답하는 방법이다.</li>\n<li>OLAP는 관계형 데이터베이스, 리포트 작성 및 데이터 마이닝을 포함하는 비지니스 인텔리전스의 광범위한 카테고리 중 한 부분이다. 일반적인 OLAP 어플리케이션으로는 영업, 마케팅, 리포팅 관리, 비지니스 프로세스 관리, 예산 및 예측, 예산 보고 등과 같은 영역이 포함되며 농업과 같은 분야에서도 쓰일 수 있다.</li>\n<li>OLAP 시스템의 핵심은 OLAP 큐브(다른 말로 다차원 큐브 혹은 하이퍼큐브)이다.</li>\n</ul>\n<p><img src=\"./2018/03/05/20180305-start-druid/OLAP_Cube.svg\" alt=\"OLAP 큐브의 예시\">\n<br/>\n출처: <a href=\"https://en.wikipedia.org/wiki/Online_analytical_processing#cite_note-22\">https://en.wikipedia.org/wiki/Online<em>analytical</em>processing#cite_note-22</a></p>\n</blockquote>\n<p>OLAP는 최종 사용자가 다차원 정보에 직접 접근하여 대화식으로 정보를 분석 및 활용하는 과정으로 정의 할 수 있다. OLAP에서는 다음과 같이 대화식 질문들에 대한 답을 빠르게 해결하는 것이 목적이다.</p>\n<ul>\n<li>35세 이상의 고객들은 작년에 얼마나 지출했고 시간에 따라 어떻게 변했는가?</li>\n<li>각 연령 집단의 경우 제품 범주별 수익 내역(차익금 비율, 전체 수익 모두)은 어떠한가?</li>\n</ul>\n<p>BI 분야에서는 단순히 ‘이번 달 매출액이 얼마인가?’ 이렇게 물어보지 않고 여러 각도로 정보를 구성하여 원하는 정보를 추출하기를 원한다. OLAP는 결과 산출을 빠르게 하기 위해 다양한 차원들에 대해 선계산 값을 미리 산출하여 OLAP 큐브라는 데이터 구조로 측정값을 저장한다. 즉, 큐브는 시간, 지역, 제품군 등 여러 차원(Dimension)을 판매량, 재고량과 같은 측정값(Measure)으로 요약한 데이터이다.\n<br/></p>\n<p>[OLAP Cube example 1]\n<img src=\"./2018/03/05/20180305-start-druid/olap_cube.png\" alt=\"OLAP 큐브의 예시\">\n<br/></p>\n<p>[OLAP Cube example 2]\n<img src=\"./2018/03/05/20180305-start-druid/olap_cube_2.jpg\" alt=\"OLAP 큐브의 예시\"></p>\n<p>위와 같은 OLAP 큐브가 구축되어 있다면 다음과 같은 쿼리를 처리할 수 있게 된다.</p>\n<ul>\n<li>올해 가장 매출이 저조한 대리점과 저조한 상품 품목은?</li>\n<li>서울지역에서 가장 매출이 높은 상품과 순이익이 가장 높은 상품은?</li>\n<li>지역별로 전월 대비 매출이 가장 높은 상품은?\n<br/></li>\n</ul>\n<p>OLAP을 하기 위해서는 OLTP(On-Line Transaction Processing)이 선행되어야 한다.\n<img src=\"./2018/03/05/20180305-start-druid/oltp-olap.png\" alt=\"OLTP와 OLAP의 차이\">\n<img src=\"./2018/03/05/20180305-start-druid/dt_wh.png\" alt=\"OLTP와 OLAP의 차이\">\nOLAP 큐브를 만들기 위해서는 여러 관계형 데이터들을 집약한 Data Warehouse가 필요하다. 관계형 데이터는 OLTP라는 영역에서 데이터를 수집한다.</p>\n<ul>\n<li>\n<p>OLTP (OnLine Transaction Processing)\nBatch 와 반대되는 개념으로 실시간으로 db의 데이터를 트랜잭션 단위로 갱신/조회하는 처리방식. 은행, 증권사 등에서 씀. 기존과 달리 다수의 client가 거의 동시에 이용할수 있도록 송수신자료를 트랜잭션단위로 압축한것이 특징.</p>\n</li>\n<li>\n<p>DW (Data Warehouse)\nOLTP에서 발생한 데이터를 모아서 주제별로 합쳐 분석하기 편한 형태로 통합한 데이터 시스템</p>\n</li>\n</ul>\n<p>OLAP의 더 자세한 내용에 대해서는 다음 링크들을 참조하자.</p>\n<ul>\n<li><a href=\"http://12bme.tistory.com/144\">http://12bme.tistory.com/144</a></li>\n<li><a href=\"http://egloos.zum.com/carrpediem/v/2459408\">http://egloos.zum.com/carrpediem/v/2459408</a></li>\n<li><a href=\"http://118k.tistory.com/66\">http://118k.tistory.com/66</a></li>\n<li><a href=\"http://olap.com/olap-definition/\">http://olap.com/olap-definition/</a></li>\n<li><a href=\"http://i-bada.blogspot.kr/2014/01/olap-online-analytical-processing.html\">http://i-bada.blogspot.kr/2014/01/olap-online-analytical-processing.html</a></li>\n<li><a href=\"https://galaktikasoft.com/blog/olap-glossary.html\">https://galaktikasoft.com/blog/olap-glossary.html</a></li>\n<li><a href=\"https://support.office.com/ko-kr/article/olap-online-analytical-processing-%EA%B0%9C%EC%9A%94-15d2cdde-f70b-4277-b009-ed732b75fdd6\">https://support.office.com/ko-kr/article/olap-online-analytical-processing-%EA%B0%9C%EC%9A%94-15d2cdde-f70b-4277-b009-ed732b75fdd6</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/OLAP_cube\">https://en.wikipedia.org/wiki/OLAP_cube</a></li>\n</ul>\n<h4>Druid의 Key Features</h4>\n<ul>\n<li>1초 미만의 OLAP 쿼리 가능 (Sub-second OLAP Queries): 드루이드는 신속한 다차원 필터링, 임시 어트리뷰트 그룹핑 및 매우 빠른 집계(Aggregation)가 가능하다.</li>\n<li>실시간 스트리밍 집계 (Real-time Streaming Ingestion): 드루이드는 락(Lock)없는 실시간 수집을 사용하여 대량의 데이터를 받음과 동시에 쿼리 실행이 가능하다.</li>\n<li>강력한 분석 도구 (Power Analytic Applications): 드루이드는 수천 명의 동시 사용자가 사용할 수 있도록 설계된 강력한 사용자 지향 분석 어플리케이션이다.</li>\n<li>효율적인 비용 (Cost Effective)</li>\n<li>높은 가용성 (Highly Available)</li>\n<li>확장성 (Scalable)</li>\n</ul>\n<h4>Druid는 언제 써야할까?</h4>\n<p>드루이드는 다음과 같은 요구사항에 적합하다.</p>\n<ul>\n<li>빠른 집계 및 OLAP 쿼리가 필요한 응용 프로그램을 개발할 때</li>\n<li>실시간 분석을 원하면서 굉장히 많은 데이터를 다룰 때 (조 단위의 이벤트 로우 수, 페타 바이트의 데이터)</li>\n<li>실패 없이 항상 사용할 수 있는 데이터 저장소가 필요할 때</li>\n</ul>\n<p>현재 드루이드 공식 사이트에서 소개하고 있는 <a href=\"http://www.marketwired.com/press-release/metamarkets-clients-analyzing-100-billion-programmatic-events-daily-on-track-surpass-2061596.htm\">프로덕션 드루이드 클러스터 성공 사례</a>의 규모는 다음과 같다고 한다.</p>\n<ul>\n<li>3+ trillion events/month (3조 이벤트/1개월)</li>\n<li>3M+ events/sec through Druid’s real-time ingestion (초당 3백만 이벤트를 드루이드에 실시간 입수)</li>\n<li>100+ PB of raw data (100 페타 바이트의 로우 데이터)</li>\n<li>50+ trillion events (50조 이벤트)</li>\n<li>Thousands of queries per second for applications used by thousands of users (수천명 유저에 의한 초당 수천 쿼리 실행)</li>\n<li>Tens of thousands of cores (수만 개의 코어)</li>\n</ul>\n<p>다만 주의할 점은 드루이드는 현재 Dremel 및 PowerDrill과 유사한 방식으로 싱글 테이블 쿼리만 허용하며 테이블 간 JOIN은 할 수 없다. 하지만 아래와 같은 장점이 추가되었다.</p>\n<ol>\n<li>중첩된 데이터 구조를 가지는 컬럼 기반의 스토리지 포멧</li>\n<li>중간 정리가 있는 계층적인 쿼리 분산</li>\n<li>빠른 필터링을 위한 인덱싱</li>\n<li>실시간 집계 (집계된 데이터는 즉시 쿼리가 가능함)</li>\n<li>내장애성을 지닌 데이터 손실염려가 없는 분산 구조\n<br/></li>\n</ol>\n<h3>Druid Architecture</h3>\n<p>드루이드는 각기 다른 역할을 가진 서비스로 구성되어 있다. 각 서비스는 작은 일을 잘 처리하도록 설계되어 있다.</p>\n<p><img src=\"./2018/03/05/20180305-start-druid/druid-dataflow-3.png\" alt=\"Druid Architecture\"></p>\n<h5>Historical Nodes</h5>\n<p>히스토리컬 노드는 드루이드 클러스터의 핵심이다. 히스토리컬 노드는 딥 스토리지에서 세그먼트를 다운로드하고 이러한 세그먼트에 대한 브로커 노드의 쿼리 실행을 하여 결과를 브로커 노드에 반환한다. 히스토리컬 노드는 데이터를 공유하지 않으며 Zookeeper를 통하여 세그먼트 로드, 세그먼트 삭제를 모니터링한다.</p>\n<h5>Broker Nodes</h5>\n<p>브로커 노드를 통해 쿼리를 받고 데이터를 제공한다. 브로커 노드는 쿼리 분산 실행 및 결과 수집, 병합을 담당한다. 브로커 노드도 쿼리 실행을 위해 Real-time 노드와 히스토리컬 노드가 어떤 것인지를 판단할 때 Zookeeper를 사용한다.</p>\n<h5>Coordinator Nodes</h5>\n<p>코디네이터 노드는 드루이드 클러스터의 히스토리컬 노드에 있는 세그먼트를 관리한다. 코디네이터 노드는 히스토리컬 노드에 새로운 세그먼트를 로드, 이전 세그먼트 삭제 및 균형을 맞추기 위한 세그먼트 이동을 지시한다. (히스토리컬 노드에 지시하기 위해 Zookeeper를 사용)</p>\n<h5>Realtime Nodes</h5>\n<p>드루이드에서 실시간 처리는 독립형 실시간 노드를 사용하거나 인덱싱 서비스로 할 수 있다. 실시간 처리 로직은 두 서비스가 동일하다. 실시간 처리는 데이터 수집, 데이터 인덱싱 (세그먼트 작성) 및 세그먼트를 히스토리컬 노드에 전달한다. 실시간 처리 로직에 의해 집계된 데이터는 즉시 질의가 가능하다.</p>\n<p>그 외 드루이드는 3가지 외부 디펜던시가 포함된다.</p>\n<ol>\n<li>Zookeeper: 클러스터 내부에서의 서비스 디스커버리 및 데이터 토폴로지의 운영</li>\n<li>Metadata storage instance: 세그먼트에 대한 메타데이터를 관리하기 위한 메타 데이터 저장소</li>\n<li>Deep Storage LOB store/file system: 세그먼트를 저장하기 위한 딥 스토리지 LOB 저장소/파일 시스템</li>\n</ol>\n<p><img src=\"./2018/03/05/20180305-start-druid/druid-manage-1.png\" alt=\"Druid Architecture\"></p>\n<h4>여기서 잠깐! 세그먼트가 뭐지? (세그먼트와 딥 스토리지)</h4>\n<p>드루이드로 데이터가 입수(Batch Ingestion or Streaming Ingestion)되면 인덱싱 처리가 진행된다. 여기서 인덱싱 작업이란 다음과 같다.</p>\n<ul>\n<li>데이터를 컬럼 기반 포멧의 형태로 변경</li>\n<li>비트맵 인덱스를 활용한 데이터 색인 작업</li>\n<li>다양한 알고리즘을 이용한 데이터 압축</li>\n</ul>\n<p>이러한 인덱싱 작업을 거친 결과물을 드루이드에서는 <code class=\"language-text\">세그먼트(Segment)</code>라고 부른다. 세그먼트는 드루이드에서 데이터를 저장하는 기본 구조인 것이다. 세그먼트는 컬럼 기반으로 저장된 여러 개의 차원(Dimension)과 측정값(Metrics)를 포함하며 각 컬럼별로 인덱싱이 되어 있다.\n<br/>\n세그먼트는 딥 스토리지(Deep Storage)라는 LOB / 파일 시스템에 저장된다. 그 후 데이터는 히스토리컬 노드의 로컬에 다운로드 되고 쿼리 실행하기 전에 메모리에 로딩된다. 히스토리컬 노드 하나가 죽어도 딥 스토리지에는 세그먼트가 있기 때문에 다른 히스토리컬 노드에서 쿼리 서비스를 제공한다.\n<br/></p>\n<h3>Batch Ingestion in Druid</h3>\n<p>먼저 아래와 같은 이벤트 데이터가 있다고 가정하자.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-text line-numbers\"><code class=\"language-text\">timestamp             publisher          advertiser  gender  country  click  price\n2011-01-01T01:01:35Z  bieberfever.com    google.com  Male    USA      0      0.65\n2011-01-01T01:03:63Z  bieberfever.com    google.com  Male    USA      0      0.62\n2011-01-01T01:04:51Z  bieberfever.com    google.com  Male    USA      1      0.45\n2011-01-01T01:00:00Z  ultratrimfast.com  google.com  Female  UK       0      0.87\n2011-01-01T02:00:00Z  ultratrimfast.com  google.com  Female  UK       0      0.99\n2011-01-01T02:00:00Z  ultratrimfast.com  google.com  Female  UK       1      1.53</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>드루이드는 이 데이터의 구조를 세 가지 요소로 분류한다.</p>\n<ul>\n<li>Timestamp columns</li>\n<li>Dimension columns</li>\n<li>Metric columns</li>\n</ul>\n<p>Timestamp 컬럼은 말 그대로 시간이 저장된 컬럼을 말하며 Dimension은 이벤트에서 각각의 컬럼을 말하며 필터링에 사용된다. 위 예에서 Dimension은 publisher, advertiser, gender, country를 말한다. Metric은 결합(Aggregation)과 계산(Computation)에서 사용되는 컬럼이다. 위 예에서는 click, price가 해당된다. Metric은 보통 count, sum, mean을 계산할 수 있는 숫자 타입이다. 드루이드는 기본적으로 데이터를 세그먼트 단위로 샤딩하며 샤딩 기준은 시간이다. (데이터 파편화에 대해서는 추후 다시 설명)</p>\n<h4>Roll-up</h4>\n<p>예제 데이터가 하루에 조 단위로 들어온다면 우리가 원하는 분석 결과를 빠르게 얻어서 인사이트를 찾아낼 수 있을까? 이러한 이벤트 데이터의 분석을 좀 더 빠르게 하기 위해 요약하는 작업을 <code class=\"language-text\">Roll-up</code>이라고 부른다.\n드루이드에서 아래와 같이 롤업 규칙을 정하면 규칙에 따라 요약 데이터가 생성된다. (여기서 아래 규칙은 수도코드임)</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-text line-numbers\"><code class=\"language-text\">GROUP BY timestamp, publisher, advertiser, gender, country\n  :: impressions = COUNT(1),  clicks = SUM(click),  revenue = SUM(price)</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span></span></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-text line-numbers\"><code class=\"language-text\">timestamp             publisher          advertiser  gender country impressions clicks revenue\n2011-01-01T01:00:00Z  ultratrimfast.com  google.com  Male   USA     1800        25     15.70\n2011-01-01T01:00:00Z  bieberfever.com    google.com  Male   USA     2912        42     29.18\n2011-01-01T02:00:00Z  ultratrimfast.com  google.com  Male   UK      1953        17     17.31\n2011-01-01T02:00:00Z  bieberfever.com    google.com  Male   UK      3194        170    34.01</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>이렇게 데이터를 롤업하면 데이터의 크기를 줄일 수 있다. 롤업 시간기준은 최대 밀리 초까지 지원한다고 한다.\n<br/></p>\n<h4>Batch Ingestion Example</h4>\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\"><span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"type\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"index_hadoop\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"spec\"</span> <span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"ioConfig\"</span> <span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"type\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"hadoop\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"inputSpec\"</span> <span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"type\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"granularity\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"dataGranularity\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"day\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"inputPath\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"/path/to/hdfs/hive_table\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"filePattern\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\".+\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"pathFormat\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"'time'=yyyyMMdd'00'\"</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"dataSchema\"</span> <span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"dataSource\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"hive_table_druid_data_source\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"granularitySpec\"</span> <span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"type\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"uniform\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"rollup\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"false\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"segmentGranularity\"</span> <span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"period\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"period\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"P1D\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"timeZone\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Asia/Seoul\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"queryGranularity\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"none\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"intervals\"</span> <span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"2017-11-26/2018-02-26\"</span><span class=\"token punctuation\">]</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"parser\"</span> <span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"type\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"hadoopyString\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"parseSpec\"</span> <span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"format\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"tsv\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"listDelimiter\"</span><span class=\"token operator\">:</span><span class=\"token string\">\",\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"columns\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n            <span class=\"token string\">\"user_id\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"col001\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"col002\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"col003\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"col004\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"col005\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"col006\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"col007\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"col008\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"col009\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"col010\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"product_id\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"log_time\"</span>\n          <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"dimensionsSpec\"</span> <span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">\"dimensions\"</span> <span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n              <span class=\"token string\">\"user_id\"</span><span class=\"token punctuation\">,</span>\n              <span class=\"token string\">\"col004\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"col005\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"col009\"</span><span class=\"token punctuation\">,</span>\n              <span class=\"token string\">\"product_id\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"log_time\"</span>\n            <span class=\"token punctuation\">]</span>\n          <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"timestampSpec\"</span> <span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">\"format\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"yyyyMMddHH\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token property\">\"column\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"log_time\"</span>\n          <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"metricsSpec\"</span> <span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"longSum\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"name\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"audience_count\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"fieldName\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"user_id\"</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"tuningConfig\"</span> <span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"type\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"hadoop\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"partitionsSpec\"</span> <span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"type\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"hashed\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"targetPartitionSize\"</span> <span class=\"token operator\">:</span> <span class=\"token number\">100000</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"jobProperties\"</span> <span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"mapreduce.user.classpath.first\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"true\"</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<br/>\n<h3>Druid Querying</h3>\n<p>드루이드에서는 먼저 브로커에서 쿼리 실행을 받으면 세그먼트에 따라 쿼리를 재작성하여 히스토리컬 노드 혹은 리얼타임 노드에게 쿼리 실행을 위임한다. 브로커 노드는 결국 결과를 모으로 머지하여 최종 결과를 반환한다. Druid에서 할 수 있는 쿼리는 다음과 같다.</p>\n<h4>Aggregation Queries</h4>\n<ul>\n<li>Timeseries</li>\n<li>TopN</li>\n<li>GroupBy</li>\n</ul>\n<h4>Metadata Queries</h4>\n<ul>\n<li>Time Boundary</li>\n<li>Segment Metadata</li>\n<li>Datasource Metadata</li>\n</ul>\n<h4>Search Queries</h4>\n<ul>\n<li>Search\n<br/></li>\n</ul>\n<h3>참고 자료</h3>\n<ul>\n<li><a href=\"http://12bme.tistory.com/144\">http://12bme.tistory.com/144</a></li>\n<li><a href=\"http://egloos.zum.com/carrpediem/v/2459408\">http://egloos.zum.com/carrpediem/v/2459408</a></li>\n<li><a href=\"http://118k.tistory.com/66\">http://118k.tistory.com/66</a></li>\n<li><a href=\"http://olap.com/olap-definition/\">http://olap.com/olap-definition/</a></li>\n<li><a href=\"http://i-bada.blogspot.kr/2014/01/olap-online-analytical-processing.html\">http://i-bada.blogspot.kr/2014/01/olap-online-analytical-processing.html</a></li>\n<li><a href=\"https://galaktikasoft.com/blog/olap-glossary.html\">https://galaktikasoft.com/blog/olap-glossary.html</a></li>\n<li><a href=\"https://support.office.com/ko-kr/article/olap-online-analytical-processing-%EA%B0%9C%EC%9A%94-15d2cdde-f70b-4277-b009-ed732b75fdd6\">https://support.office.com/ko-kr/article/olap-online-analytical-processing-%EA%B0%9C%EC%9A%94-15d2cdde-f70b-4277-b009-ed732b75fdd6</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/OLAP_cube-\">https://en.wikipedia.org/wiki/OLAP_cube-</a> <a href=\"http://egloos.zum.com/carrpediem/v/2459408\">http://egloos.zum.com/carrpediem/v/2459408</a></li>\n<li><a href=\"http://druid.io\">http://druid.io</a></li>\n<li><a href=\"https://github.com/druid-io/druid\">https://github.com/druid-io/druid</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Online_analytical_processing\">https://en.wikipedia.org/wiki/Online<em>analytical</em>processing</a></li>\n<li><a href=\"http://www.popit.kr/time-series-olap-druid-%EC%9E%85%EB%AC%B8/\">http://www.popit.kr/time-series-olap-druid-%EC%9E%85%EB%AC%B8/</a></li>\n</ul>","frontmatter":{"title":"Druid 파헤치기 - 입문","date":"2018-03-05 14:47:15","tags":["druid","olap"]}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/2018/03/05/","previous":{"fields":{"slug":"/2017/09/04/20170904-java-web-develop-with-spring/"},"frontmatter":{"title":"Java Web 개발 살펴보기 (Model 1 부터 Spring Web 까지)"}},"next":{"fields":{"slug":"/2018/03/25/20180325-about-java-garbage-collection/"},"frontmatter":{"title":"Java Garbage Collector 이해하기 Part 1 (with G1GC, Garbage First GC)"}}}}