{"data":{"site":{"siteMetadata":{"title":"Icednut's Notes","author":"Will Lee","siteUrl":"https://icednut.github.io"}},"markdownRemark":{"id":"4f33fd6e-e167-5ca7-880a-f647a8290dbd","excerpt":"Local에 Spark 환경 구축하기vm 띄우면 별다른 작업할거 없음goo.gl/2nKkOZZeppelin downloadSpark 내장. 별도 설정 필요 없고zeppelin을 띄우면 yarn과 hdfs가 자동으로 뜸http://localhost:8080 zeppelinhttp…","html":"<h2>Local에 Spark 환경 구축하기</h2>\n<ol start=\"0\">\n<li>vm 띄우면 별다른 작업할거 없음</li>\n<li>goo.gl/2nKkOZ</li>\n<li>Zeppelin download</li>\n<li>Spark 내장. 별도 설정 필요 없고</li>\n<li>zeppelin을 띄우면 yarn과 hdfs가 자동으로 뜸</li>\n<li><a href=\"http://localhost:8080\">http://localhost:8080</a> zeppelin</li>\n<li><a href=\"http://localhost:4040\">http://localhost:4040</a> spark dashboard => zeppelin만 있는 경우 driver만 뜸</li>\n<li><a href=\"https://www.zeppelinhub.com\">https://www.zeppelinhub.com</a> => 예제 노트북 받을 수 있는 곳</li>\n<li>Spark Download</li>\n<li>spark-shell을 띄울 수 있음</li>\n<li><a href=\"http://13.92.190.120:8080\">http://13.92.190.120:8080</a></li>\n</ol>\n<h2>Stream Processing</h2>\n<ul>\n<li>Spark으로도 수집을 할 수 있는데 잘 안씀. 플럼, 카프카를 이용</li>\n<li>Storm은 MapReduce로 된 코드를 마이그레이션 하기 편함</li>\n<li>Streaming Application은 따로 kill하지 않는 이상 끝나지 않고 계속 실행됨</li>\n<li>모니터링은 카프카 다룰 때 한 번더 언급</li>\n<li>windowing</li>\n<li>Production 환경에서는 checkpointing 관련 로직을 고려해야됨</li>\n</ul>\n<h2>Accumulator &#x26; Broadcast</h2>\n<ul>\n<li>shared 변수를 공유하고 싶을 때 사용, (ex: 데이터 모델을 공유하고 싶을 때)</li>\n<li>Broadcast는 read-only. 전체 노드가 다 공유하고 싶을 때 사용. (ex: 다른 데이터와 조인을 할 때 활용할 수도 있음)</li>\n<li>Accumulator는 update 가능</li>\n</ul>\n<h2>Streaming Using Kafka</h2>\n<ul>\n<li>카프카로 데이터가 들어오면 잠시 저장함. 데이터 유실이 없음</li>\n</ul>\n<h2>Spark SQL</h2>\n<ul>\n<li>Spark SQL은 데이터프레임을 사용</li>\n<li>Spark SQL은 내부적으로는 RDD를 사용하지만, Catalyst Optimizer가 SQL실행을 최적화 해줌</li>\n<li>\n<p>실습 진행</p>\n<ul>\n<li>udf가 뭐지?</li>\n</ul>\n</li>\n</ul>\n<h2>Spark 2.0</h2>\n<ul>\n<li>Tungsten: 메모리 관리, CPU 사용 개선을 진행</li>\n<li>Strunctured Streaming</li>\n<li>Spark Session을 쓰면 어떤 언어를 쓰던 ML 모델링을 할 수 있다.</li>\n<li>Catelog API</li>\n<li>Dataset</li>\n</ul>\n<h3>Tungsten</h3>\n<ul>\n<li>Whole-stage Codegen을 통해서 스파크 내부에서 코드 최적화를 진행함</li>\n</ul>\n<h3>Structured Streaming</h3>\n<h3>Lambda Architecture</h3>\n<h2>Machine Learning</h2>\n<ul>\n<li>\n<p>Spark 진입장벽</p>\n<ul>\n<li>Scala</li>\n<li>Spark API 사용방법</li>\n<li>ML</li>\n</ul>\n</li>\n<li>Spark.mllib는 RDD를 기반으로, Spark.ml는 DataFrame 기반으로 만들어짐.</li>\n</ul>\n<h3>Data Types</h3>\n<ul>\n<li>\n<p>vector = array</p>\n<ul>\n<li>Local vector는? 분산이 아니라 싱글 머신(1 JVM)에 있는 Array</li>\n<li>dense vector: 일반적인 array</li>\n<li>sparse vector: array이긴 한데, 복잡한 array (ex: Verctors.sparse(10, Array(1, 2), Array(2, 3)))</li>\n</ul>\n</li>\n<li>LabeledPoint: 레이블이 붙은 벡터</li>\n<li>\n<p>Matrix</p>\n<ul>\n<li>vector 모음</li>\n</ul>\n</li>\n<li>\n<p>IndexedRowMatrix</p>\n<ul>\n<li>vector가 stack처럼 쌓여있는 것</li>\n</ul>\n</li>\n<li>CoordinateMatrix</li>\n<li>BlockMatrix</li>\n<li>ML 예제: <a href=\"https://goo.gl/\">https://goo.gl/</a></li>\n<li>어떤 ML 함수를 쓰느냐에 따라 vector나 matrix 써야됨</li>\n</ul>","frontmatter":{"title":"스파크 강의 노트 Day 2","date":"2017-05-26 09:06:19","tags":["Spark"]}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/2017/05/26/","previous":{"fields":{"slug":"/2017/05/25/20170525-spark-lecture-day01/"},"frontmatter":{"title":"스파크 강의 노트 Day 1"}},"next":{"fields":{"slug":"/2017/05/29/20170529-spark-lecture-day03/"},"frontmatter":{"title":"스파크 강의 노트 Day 3"}}}}